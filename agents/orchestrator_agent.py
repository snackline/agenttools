# agents/orchestrator_agent.pyï¼ˆä¿®å¤åçš„å®Œæ•´ç‰ˆæœ¬ï¼‰
"""
OrchestratorAgent - å¤šè¯­è¨€Bugä¿®å¤ç³»ç»Ÿçš„æ€»åè°ƒå™¨
"""
import sys
import os
from typing import Dict, Any, List
import time

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from .base_agent import BaseAgent
from .scanner_agent import ScannerAgent
from .analyzer_agent import AnalyzerAgent
from .fixer_agent import FixerAgent
from .verifier_agent import VerifierAgent


class OrchestratorAgent(BaseAgent):
    """æ€»åè°ƒå™¨Agent - åè°ƒå¤šè¯­è¨€Bugä¿®å¤æµç¨‹"""

    def __init__(self, config: Dict[str, Any] = None):
        super().__init__("OrchestratorAgent", config or {})

        # åˆå§‹åŒ–å­Agent
        self.scanner = ScannerAgent(config.get("scanner", {}) if config else {})
        self.analyzer = AnalyzerAgent(config.get("analyzer", {}) if config else {})
        self.fixer = FixerAgent(config.get("fixer", {}) if config else {})
        self.verifier = VerifierAgent(config.get("verifier", {}) if config else {})

        self.workflow_state = {}

    def perceive(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ„ŸçŸ¥é˜¶æ®µï¼šæ¥æ”¶ç”¨æˆ·è¾“å…¥"""
        files = input_data.get("files", [])
        user_request = input_data.get("user_request", "")
        test_cases = input_data.get("test_cases", [])

        self.log("=" * 80)
        self.log("ğŸš€ å¤šè¯­è¨€Bugæ£€æµ‹ä¸ä¿®å¤ç³»ç»Ÿå¯åŠ¨")
        self.log("=" * 80)
        self.log(f"\nğŸ“‚ æ”¶åˆ°æ–‡ä»¶: {len(files)} ä¸ª")
        for f in files[:20]:  # åªæ˜¾ç¤ºå‰20ä¸ª
            self.log(f"   - {f.get('file', 'unknown')}")
        if len(files) > 20:
            self.log(f"   ... è¿˜æœ‰ {len(files) - 20} ä¸ªæ–‡ä»¶")

        if user_request:
            self.log(f"\nğŸ“ ç”¨æˆ·éœ€æ±‚: {user_request}")

        if test_cases:
            self.log(f"\nğŸ§ª æµ‹è¯•ç”¨ä¾‹: {len(test_cases)} ä¸ª")

        return {
            "files": files,
            "user_request": user_request,
            "test_cases": test_cases,
            "enable_scanner": self.config.get("enable_scanner", True),
            "enable_analyzer": self.config.get("enable_analyzer", True),
            "enable_fixer": self.config.get("enable_fixer", True),
            "enable_verifier": self.config.get("enable_verifier", True),
        }

    def decide(self, perception: Dict[str, Any]) -> Dict[str, Any]:
        """å†³ç­–é˜¶æ®µï¼šåˆ¶å®šæ‰§è¡Œè®¡åˆ’"""
        strategy = {
            "workflow": [],
            "enable_agents": {}
        }

        # æ„å»ºå·¥ä½œæµ
        if perception.get("enable_scanner", True):
            strategy["workflow"].append("scan")
            strategy["enable_agents"]["scanner"] = True

        if perception.get("enable_analyzer", True):
            strategy["workflow"].append("analyze")
            strategy["enable_agents"]["analyzer"] = True

        if perception.get("enable_fixer", True):
            strategy["workflow"].append("fix")
            strategy["enable_agents"]["fixer"] = True

        if perception.get("enable_verifier", True):
            strategy["workflow"].append("verify")
            strategy["enable_agents"]["verifier"] = True

        self.log(f"\nğŸ“‹ æ‰§è¡Œè®¡åˆ’ï¼š{' -> '.join(strategy['workflow'])}")

        return strategy

    def execute(self, decision: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œé˜¶æ®µï¼šåè°ƒå„Agentæ‰§è¡Œ"""
        workflow = decision.get("workflow", [])
        enable_agents = decision.get("enable_agents", {})

        # åˆå§‹åŒ–ç»“æœ
        pipeline_results = {
            "scan_results": None,
            "analysis": None,
            "fix_results": None,
            "verification": None,
            "execution_time": {},
            "success": False
        }

        files = decision.get("files", [])
        user_request = decision.get("user_request", "")
        test_cases = decision.get("test_cases", [])

        try:
            # 1. æ‰«æé˜¶æ®µ
            if "scan" in workflow and enable_agents.get("scanner"):
                self.log(f"\n{'=' * 80}")
                self.log("ğŸ” é˜¶æ®µ 1/4ï¼šä»£ç æ‰«æ")
                self.log("=" * 80)

                start_time = time.time()

                # âœ… ä¿®å¤ï¼šåˆå¹¶æ•°æ®
                scan_input = {"files": files}
                scan_perception = self.scanner.perceive(scan_input)
                scan_decision = self.scanner.decide(scan_perception)

                # âœ… å…³é”®ä¿®å¤ï¼šå°† files æ•°æ®åˆå¹¶åˆ° decision ä¸­
                scan_decision.update(scan_perception)  # åŒ…å« files

                scan_results = self.scanner.execute(scan_decision)

                pipeline_results["scan_results"] = scan_results
                pipeline_results["execution_time"]["scan"] = time.time() - start_time

                self.log(f"\nâ±ï¸ æ‰«æè€—æ—¶: {pipeline_results['execution_time']['scan']:.2f}ç§’")

            # 2. åˆ†æé˜¶æ®µ
            if "analyze" in workflow and enable_agents.get("analyzer") and pipeline_results["scan_results"]:
                self.log(f"\n{'=' * 80}")
                self.log("ğŸ“Š é˜¶æ®µ 2/4ï¼šé—®é¢˜åˆ†æ")
                self.log("=" * 80)

                start_time = time.time()

                analyze_input = {
                    "scan_results": pipeline_results["scan_results"],
                    "files": files
                }
                analyze_perception = self.analyzer.perceive(analyze_input)
                analyze_decision = self.analyzer.decide(analyze_perception)

                # âœ… åˆå¹¶æ•°æ®
                analyze_decision.update(analyze_perception)

                analysis = self.analyzer.execute(analyze_decision)

                pipeline_results["analysis"] = analysis
                pipeline_results["execution_time"]["analyze"] = time.time() - start_time

                self.log(f"\nâ±ï¸ åˆ†æè€—æ—¶: {pipeline_results['execution_time']['analyze']:.2f}ç§’")

            # 3. ä¿®å¤é˜¶æ®µ
            if "fix" in workflow and enable_agents.get("fixer") and pipeline_results["analysis"]:
                self.log(f"\n{'=' * 80}")
                self.log("ğŸ”§ é˜¶æ®µ 3/4ï¼šä»£ç ä¿®å¤")
                self.log("=" * 80)

                start_time = time.time()

                fix_input = {
                    "analysis": pipeline_results["analysis"],
                    "files": files,
                    "user_request": user_request
                }
                fix_perception = self.fixer.perceive(fix_input)
                fix_decision = self.fixer.decide(fix_perception)

                # âœ… åˆå¹¶æ•°æ®
                fix_decision.update(fix_perception)

                fix_results = self.fixer.execute(fix_decision)

                pipeline_results["fix_results"] = fix_results
                pipeline_results["execution_time"]["fix"] = time.time() - start_time

                self.log(f"\nâ±ï¸ ä¿®å¤è€—æ—¶: {pipeline_results['execution_time']['fix']:.2f}ç§’")

            # 4. éªŒè¯é˜¶æ®µ
            if "verify" in workflow and enable_agents.get("verifier") and pipeline_results["fix_results"]:
                self.log(f"\n{'=' * 80}")
                self.log("âœ… é˜¶æ®µ 4/4ï¼šä¿®å¤éªŒè¯")
                self.log("=" * 80)

                start_time = time.time()

                verify_input = {
                    "fix_results": pipeline_results["fix_results"],
                    "original_files": files,
                    "original_analysis": pipeline_results["analysis"],
                    "test_cases": test_cases
                }
                verify_perception = self.verifier.perceive(verify_input)
                verify_decision = self.verifier.decide(verify_perception)

                # âœ… åˆå¹¶æ•°æ®
                verify_decision.update(verify_perception)

                verification = self.verifier.execute(verify_decision)

                pipeline_results["verification"] = verification
                pipeline_results["execution_time"]["verify"] = time.time() - start_time

                self.log(f"\nâ±ï¸ éªŒè¯è€—æ—¶: {pipeline_results['execution_time']['verify']:.2f}ç§’")

            pipeline_results["success"] = True

        except Exception as e:
            self.log(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            import traceback
            error_trace = traceback.format_exc()
            self.log(f"\né”™è¯¯è¯¦æƒ…:\n{error_trace}")
            pipeline_results["error"] = str(e)
            pipeline_results["success"] = False

        # ç”Ÿæˆæ€»ç»“
        self._generate_summary(pipeline_results)

        return pipeline_results

    def _generate_summary(self, results: Dict[str, Any]):
        """ç”Ÿæˆæ‰§è¡Œæ€»ç»“"""
        exec_time = results.get("execution_time", {})
        total_time = sum(exec_time.values())

        self.log("")
        self.log("=" * 80)
        self.log("ğŸ“Š æ‰§è¡Œæ€»ç»“")
        self.log("=" * 80)

        self.log("")
        self.log(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")

        # âœ… ä¿®å¤é™¤é›¶é”™è¯¯
        if total_time > 0:
            for stage, duration in exec_time.items():
                percentage = (duration / total_time * 100)
                self.log(f"   - {stage}: {duration:.2f}ç§’ ({percentage:.1f}%)")
        else:
            # å¦‚æœæ€»è€—æ—¶ä¸º0ï¼Œåªæ˜¾ç¤ºè€—æ—¶ï¼Œä¸æ˜¾ç¤ºç™¾åˆ†æ¯”
            for stage, duration in exec_time.items():
                self.log(f"   - {stage}: {duration:.2f}ç§’")

        # æ‰«æç»“æœ
        scan_results = results.get("scan_results", {})
        scan_summary = scan_results.get("summary", {})

        self.log("")
        self.log("ğŸ” æ‰«æç»“æœ:")
        self.log(f"   - å‘ç°é—®é¢˜: {scan_summary.get('total_defects', 0)} ä¸ª")

        by_severity = scan_summary.get("by_severity", {})
        self.log(f"   - é«˜å±: {by_severity.get('HIGH', 0)} ä¸ª")
        self.log(f"   - ä¸­å±: {by_severity.get('MEDIUM', 0)} ä¸ª")
        self.log(f"   - ä½å±: {by_severity.get('LOW', 0)} ä¸ª")

        # ä¿®å¤ç»“æœ
        fix_results = results.get("fix_results", {})
        fix_summary = fix_results.get("summary", {})

        self.log("")
        self.log("ğŸ”§ ä¿®å¤ç»“æœ:")
        self.log(f"   - å¤„ç†æ–‡ä»¶: {fix_summary.get('total_files', 0)} ä¸ª")
        self.log(f"   - æˆåŠŸä¿®å¤: {fix_summary.get('successfully_fixed', 0)} ä¸ª")
        self.log(f"   - ä¿®å¤å¤±è´¥: {fix_summary.get('failed', 0)} ä¸ª")
        self.log(f"   - æ€»ä¿®å¤æ•°: {fix_summary.get('total_fixes', 0)} å¤„")

        # éªŒè¯ç»“æœ
        verification = results.get("verification", {})
        verify_summary = verification.get("summary", {})

        self.log("")
        self.log("âœ… éªŒè¯ç»“æœ:")
        self.log(f"   - éªŒè¯æ–‡ä»¶: {verify_summary.get('total_files', 0)} ä¸ª")
        self.log(f"   - ç¼–è¯‘æˆåŠŸ: {verify_summary.get('compile_success', 0)} ä¸ª")
        self.log(f"   - ç¼–è¯‘å¤±è´¥: {verify_summary.get('compile_failed', 0)} ä¸ª")
        self.log(f"   - å¹³å‡ä¿®å¤ç‡: {verify_summary.get('avg_fix_rate', 0):.1f}%")


# ä¾¿æ·å‡½æ•°
def run_multi_language_repair(files: List[Dict],
                              user_request: str = "",
                              test_cases: List[Dict] = None,
                              llm_client=None) -> Dict[str, Any]:
    """
    è¿è¡Œå¤šè¯­è¨€Bugä¿®å¤æµç¨‹çš„ä¾¿æ·å‡½æ•°

    Args:
        files: æ–‡ä»¶åˆ—è¡¨ [{"file": "xxx", "content": "..."}, ...]
        user_request: ç”¨æˆ·é¢å¤–éœ€æ±‚
        test_cases: æµ‹è¯•ç”¨ä¾‹
        llm_client: LLMå®¢æˆ·ç«¯

    Returns:
        å®Œæ•´çš„æ‰§è¡Œç»“æœ
    """
    config = {
        "fixer": {
            "llm_client": llm_client,
            "use_rules": True,
            "use_llm": llm_client is not None
        }
    }

    orchestrator = OrchestratorAgent(config)

    input_data = {
        "files": files,
        "user_request": user_request,
        "test_cases": test_cases or []
    }

    perception = orchestrator.perceive(input_data)
    decision = orchestrator.decide(perception)
    decision.update(perception)  # åˆå¹¶æ•°æ®
    results = orchestrator.execute(decision)

    return results