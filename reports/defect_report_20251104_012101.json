{
  "timestamp": "2025-11-04 01:21:01",
  "summary": {
    "static_analysis": {
      "total": 1239,
      "high": 555,
      "medium": 485,
      "low": 199
    },
    "external_tools": {
      "ruff": 285,
      "pylint": 440,
      "mypy": 1,
      "bandit": 121
    },
    "dynamic_analysis": {
      "compile_errors": 0
    },
    "fixes": {
      "total_fixed": 0,
      "fixed_files": 26
    },
    "verification": {
      "verified_files": 0,
      "compile_errors": 0
    }
  },
  "defects": [
    {
      "file": "default.py",
      "line": 120,
      "col": 15,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'TimeoutError'。",
      "snippet": "        except TimeoutError:"
    },
    {
      "file": "build_dataset.py",
      "line": 60,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if pull[\"merged_at\"] is None:"
    },
    {
      "file": "build_dataset.py",
      "line": 76,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if instance[\"patch\"] is None or instance[\"patch\"] == \"\":"
    },
    {
      "file": "build_dataset.py",
      "line": 78,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if instance[\"problem_statement\"] is None or instance[\"problem_statement\"] == \"\":"
    },
    {
      "file": "build_dataset.py",
      "line": 92,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if instance[\"test_patch\"] is None or instance[\"test_patch\"].strip() == \"\":"
    },
    {
      "file": "build_dataset.py",
      "line": 106,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if token is None:"
    },
    {
      "file": "get_tasks_pipeline.py",
      "line": 89,
      "col": 8,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "        except Exception as e:"
    },
    {
      "file": "get_top_pypi.py",
      "line": 43,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if content is not None and package_url in content:"
    },
    {
      "file": "get_top_pypi.py",
      "line": 48,
      "col": 12,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'driver'。",
      "snippet": "            driver.get(package_url)"
    },
    {
      "file": "get_top_pypi.py",
      "line": 49,
      "col": 33,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'driver'。",
      "snippet": "            soup = BeautifulSoup(driver.page_source, \"html.parser\")"
    },
    {
      "file": "get_top_pypi.py",
      "line": 65,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if package_github is not None:"
    },
    {
      "file": "get_top_pypi.py",
      "line": 74,
      "col": 16,
      "severity": "LOW",
      "rule_id": "PY010",
      "message": "使用裸 except，建议捕获具体异常类型。",
      "snippet": "                except:"
    },
    {
      "file": "print_pulls.py",
      "line": 38,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if cutoff_date is not None"
    },
    {
      "file": "print_pulls.py",
      "line": 46,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if max_pulls is not None and i_pull >= max_pulls:"
    },
    {
      "file": "print_pulls.py",
      "line": 48,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if cutoff_date is not None and pull.created_at < cutoff_date:"
    },
    {
      "file": "print_pulls.py",
      "line": 72,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if pull is None:"
    },
    {
      "file": "print_pulls.py",
      "line": 106,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if token is None:"
    },
    {
      "file": "print_pulls.py",
      "line": 111,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if pull_number is not None:"
    },
    {
      "file": "utils.py",
      "line": 149,
      "col": 19,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "                if num_pages is not None and page >= num_pages:"
    },
    {
      "file": "utils.py",
      "line": 152,
      "col": 12,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "            except Exception as e:"
    },
    {
      "file": "utils.py",
      "line": 247,
      "col": 15,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'extract_problem_statement_and_hints_django'。",
      "snippet": "        return extract_problem_statement_and_hints_django(pull, repo)"
    },
    {
      "file": "utils.py",
      "line": 257,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if issue is None:"
    },
    {
      "file": "utils.py",
      "line": 263,
      "col": 21,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 '_extract_hints'。",
      "snippet": "        hint_texts = _extract_hints(pull, repo, issue_number)"
    },
    {
      "file": "utils.py",
      "line": 328,
      "col": 12,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'test_word'。",
      "snippet": "            test_word in hunk.path for test_word in [\"test\", \"tests\", \"e2e\", \"testing\"]"
    },
    {
      "file": "utils.py",
      "line": 387,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if comment_resp is None or timestamp_resp is None:"
    },
    {
      "file": "utils.py",
      "line": 387,
      "col": 39,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if comment_resp is None or timestamp_resp is None:"
    },
    {
      "file": "remove_envs.py",
      "line": 50,
      "col": 14,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'conda_source'。",
      "snippet": "        cmd = conda_source + \" && \" + conda_cmd"
    },
    {
      "file": "criteria.py",
      "line": 14,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if re.search(pattern_git_commit_hash, text) is not None:"
    },
    {
      "file": "criteria.py",
      "line": 17,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if re.search(pattern_django_commit_hash, text) is not None:"
    },
    {
      "file": "criteria.py",
      "line": 68,
      "col": 39,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'ext'。",
      "snippet": "    pattern_image = \"|\".join(re.escape(ext) for ext in image_extensions)"
    },
    {
      "file": "criteria.py",
      "line": 74,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    return image_regex.search(text) is not None or video_regex.search(text) is not None"
    },
    {
      "file": "criteria.py",
      "line": 74,
      "col": 51,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    return image_regex.search(text) is not None or video_regex.search(text) is not None"
    },
    {
      "file": "call_make_repo.py",
      "line": 9,
      "col": 15,
      "severity": "HIGH",
      "rule_id": "PY003",
      "message": "subprocess.*(shell=True) 可能导致命令注入。",
      "snippet": "    out_make = subprocess.run("
    },
    {
      "file": "docker_build.py",
      "line": 29,
      "col": 8,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'super'。",
      "snippet": "        super().__init__(message)"
    },
    {
      "file": "docker_build.py",
      "line": 30,
      "col": 25,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'super'。",
      "snippet": "        self.super_str = super().__str__()"
    },
    {
      "file": "docker_build.py",
      "line": 155,
      "col": 4,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "docker_build.py",
      "line": 388,
      "col": 40,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'build_instance_image'。",
      "snippet": "    successful, failed = run_threadpool(build_instance_image, payloads, max_workers)"
    },
    {
      "file": "docker_build.py",
      "line": 419,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if logger is None:"
    },
    {
      "file": "docker_build.py",
      "line": 502,
      "col": 12,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "            except Exception as e:"
    },
    {
      "file": "docker_build.py",
      "line": 527,
      "col": 4,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "docker_utils.py",
      "line": 94,
      "col": 4,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "docker_utils.py",
      "line": 136,
      "col": 4,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "docker_utils.py",
      "line": 153,
      "col": 8,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "        except Exception as e2:"
    },
    {
      "file": "docker_utils.py",
      "line": 166,
      "col": 4,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "docker_utils.py",
      "line": 198,
      "col": 8,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "        except Exception as e:"
    },
    {
      "file": "docker_utils.py",
      "line": 212,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if exec_id is not None:"
    },
    {
      "file": "docker_utils.py",
      "line": 285,
      "col": 11,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'should_remove'。",
      "snippet": "        if should_remove(image_name, cache_level, clean, prior_images):"
    },
    {
      "file": "docker_utils.py",
      "line": 289,
      "col": 12,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "            except Exception as e:"
    },
    {
      "file": "grading.py",
      "line": 63,
      "col": 26,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "                lambda x: x in content,"
    },
    {
      "file": "grading.py",
      "line": 264,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if prediction[KEY_PREDICTION] is None:"
    },
    {
      "file": "prepare_images.py",
      "line": 35,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if instance_ids is None:"
    },
    {
      "file": "remove_containers.py",
      "line": 35,
      "col": 8,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "        except Exception as e:"
    },
    {
      "file": "reporting.py",
      "line": 95,
      "col": 20,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "                    x,"
    },
    {
      "file": "run_evaluation.py",
      "line": 137,
      "col": 12,
      "severity": "LOW",
      "rule_id": "PY010",
      "message": "使用裸 except，建议捕获具体异常类型。",
      "snippet": "            except:"
    },
    {
      "file": "run_evaluation.py",
      "line": 257,
      "col": 4,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "run_evaluation.py",
      "line": 307,
      "col": 16,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'instance'。",
      "snippet": "                instance,"
    },
    {
      "file": "run_evaluation.py",
      "line": 459,
      "col": 8,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'k'。",
      "snippet": "        k"
    },
    {
      "file": "run_evaluation.py",
      "line": 461,
      "col": 38,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if v[KEY_PREDICTION] == \"\" or v[KEY_PREDICTION] is None"
    },
    {
      "file": "run_evaluation.py",
      "line": 505,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if report_dir is not None:"
    },
    {
      "file": "run_evaluation.py",
      "line": 510,
      "col": 25,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if force_rebuild and namespace is not None:"
    },
    {
      "file": "run_evaluation.py",
      "line": 542,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if namespace is None and not rewrite_reports:"
    },
    {
      "file": "utils.py",
      "line": 27,
      "col": 8,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'super'。",
      "snippet": "        super().__init__(message)"
    },
    {
      "file": "utils.py",
      "line": 36,
      "col": 35,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'super'。",
      "snippet": "            f\"{self.instance_id}: {super().__str__()}\\n\""
    },
    {
      "file": "utils.py",
      "line": 44,
      "col": 18,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'load_swebench_dataset'。",
      "snippet": "        dataset = load_swebench_dataset(dataset_name, split)"
    },
    {
      "file": "utils.py",
      "line": 93,
      "col": 15,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'run_sequential'。",
      "snippet": "        return run_sequential(func, payloads)"
    },
    {
      "file": "utils.py",
      "line": 104,
      "col": 12,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "            except Exception as e:"
    },
    {
      "file": "utils.py",
      "line": 127,
      "col": 8,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "        except Exception:"
    },
    {
      "file": "utils.py",
      "line": 208,
      "col": 53,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "    first_chars = list(map(lambda x: None if not len(x) else x[0], hunk.split(\"\\n\")))"
    },
    {
      "file": "utils.py",
      "line": 208,
      "col": 61,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "    first_chars = list(map(lambda x: None if not len(x) else x[0], hunk.split(\"\\n\")))"
    },
    {
      "file": "utils.py",
      "line": 211,
      "col": 35,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "    new_lines = list(map(lambda x: x.rstrip(), hunk.split(\"\\n\")[first_idx:last_idx]))"
    },
    {
      "file": "utils.py",
      "line": 256,
      "col": 40,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "                map(lambda x: int(x) if x.isnumeric() else x, hunk)"
    },
    {
      "file": "utils.py",
      "line": 256,
      "col": 34,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "                map(lambda x: int(x) if x.isnumeric() else x, hunk)"
    },
    {
      "file": "utils.py",
      "line": 256,
      "col": 59,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "                map(lambda x: int(x) if x.isnumeric() else x, hunk)"
    },
    {
      "file": "utils.py",
      "line": 330,
      "col": 4,
      "severity": "LOW",
      "rule_id": "PY010",
      "message": "使用裸 except，建议捕获具体异常类型。",
      "snippet": "    except:"
    },
    {
      "file": "utils.py",
      "line": 363,
      "col": 28,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'swebench'。",
      "snippet": "            resources.files(swebench.resources)"
    },
    {
      "file": "java.py",
      "line": 11,
      "col": 42,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'test'。",
      "snippet": "    tests_xml = \"\\n\".join(rf'<test name=\"{test}\" />' for test in tests)"
    },
    {
      "file": "__init__.py",
      "line": 5,
      "col": 0,
      "severity": "LOW",
      "rule_id": "PY050",
      "message": "使用 from X import * 可能导致命名冲突。",
      "snippet": "from swebench.harness.constants.c import *"
    },
    {
      "file": "__init__.py",
      "line": 6,
      "col": 0,
      "severity": "LOW",
      "rule_id": "PY050",
      "message": "使用 from X import * 可能导致命名冲突。",
      "snippet": "from swebench.harness.constants.go import *"
    },
    {
      "file": "__init__.py",
      "line": 7,
      "col": 0,
      "severity": "LOW",
      "rule_id": "PY050",
      "message": "使用 from X import * 可能导致命名冲突。",
      "snippet": "from swebench.harness.constants.java import *"
    },
    {
      "file": "__init__.py",
      "line": 8,
      "col": 0,
      "severity": "LOW",
      "rule_id": "PY050",
      "message": "使用 from X import * 可能导致命名冲突。",
      "snippet": "from swebench.harness.constants.javascript import *"
    },
    {
      "file": "__init__.py",
      "line": 9,
      "col": 0,
      "severity": "LOW",
      "rule_id": "PY050",
      "message": "使用 from X import * 可能导致命名冲突。",
      "snippet": "from swebench.harness.constants.php import *"
    },
    {
      "file": "__init__.py",
      "line": 10,
      "col": 0,
      "severity": "LOW",
      "rule_id": "PY050",
      "message": "使用 from X import * 可能导致命名冲突。",
      "snippet": "from swebench.harness.constants.python import *"
    },
    {
      "file": "__init__.py",
      "line": 11,
      "col": 0,
      "severity": "LOW",
      "rule_id": "PY050",
      "message": "使用 from X import * 可能导致命名冲突。",
      "snippet": "from swebench.harness.constants.ruby import *"
    },
    {
      "file": "__init__.py",
      "line": 12,
      "col": 0,
      "severity": "LOW",
      "rule_id": "PY050",
      "message": "使用 from X import * 可能导致命名冲突。",
      "snippet": "from swebench.harness.constants.rust import *"
    },
    {
      "file": "__init__.py",
      "line": 137,
      "col": 6,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_VERSION_TO_SPECS_C'。",
      "snippet": "    **MAP_REPO_VERSION_TO_SPECS_C,"
    },
    {
      "file": "__init__.py",
      "line": 138,
      "col": 6,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_VERSION_TO_SPECS_GO'。",
      "snippet": "    **MAP_REPO_VERSION_TO_SPECS_GO,"
    },
    {
      "file": "__init__.py",
      "line": 139,
      "col": 6,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_VERSION_TO_SPECS_JAVA'。",
      "snippet": "    **MAP_REPO_VERSION_TO_SPECS_JAVA,"
    },
    {
      "file": "__init__.py",
      "line": 140,
      "col": 6,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_VERSION_TO_SPECS_JS'。",
      "snippet": "    **MAP_REPO_VERSION_TO_SPECS_JS,"
    },
    {
      "file": "__init__.py",
      "line": 141,
      "col": 6,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_VERSION_TO_SPECS_PHP'。",
      "snippet": "    **MAP_REPO_VERSION_TO_SPECS_PHP,"
    },
    {
      "file": "__init__.py",
      "line": 142,
      "col": 6,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_VERSION_TO_SPECS_PY'。",
      "snippet": "    **MAP_REPO_VERSION_TO_SPECS_PY,"
    },
    {
      "file": "__init__.py",
      "line": 143,
      "col": 6,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_VERSION_TO_SPECS_RUBY'。",
      "snippet": "    **MAP_REPO_VERSION_TO_SPECS_RUBY,"
    },
    {
      "file": "__init__.py",
      "line": 144,
      "col": 6,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_VERSION_TO_SPECS_RUST'。",
      "snippet": "    **MAP_REPO_VERSION_TO_SPECS_RUST,"
    },
    {
      "file": "__init__.py",
      "line": 148,
      "col": 6,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_TO_INSTALL_C'。",
      "snippet": "    **MAP_REPO_TO_INSTALL_C,"
    },
    {
      "file": "__init__.py",
      "line": 149,
      "col": 6,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_TO_INSTALL_GO'。",
      "snippet": "    **MAP_REPO_TO_INSTALL_GO,"
    },
    {
      "file": "__init__.py",
      "line": 150,
      "col": 6,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_TO_INSTALL_JAVA'。",
      "snippet": "    **MAP_REPO_TO_INSTALL_JAVA,"
    },
    {
      "file": "__init__.py",
      "line": 151,
      "col": 6,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_TO_INSTALL_JS'。",
      "snippet": "    **MAP_REPO_TO_INSTALL_JS,"
    },
    {
      "file": "__init__.py",
      "line": 152,
      "col": 6,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_TO_INSTALL_PHP'。",
      "snippet": "    **MAP_REPO_TO_INSTALL_PHP,"
    },
    {
      "file": "__init__.py",
      "line": 153,
      "col": 6,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_TO_INSTALL_PY'。",
      "snippet": "    **MAP_REPO_TO_INSTALL_PY,"
    },
    {
      "file": "__init__.py",
      "line": 154,
      "col": 6,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_TO_INSTALL_RUBY'。",
      "snippet": "    **MAP_REPO_TO_INSTALL_RUBY,"
    },
    {
      "file": "__init__.py",
      "line": 155,
      "col": 6,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_TO_INSTALL_RUST'。",
      "snippet": "    **MAP_REPO_TO_INSTALL_RUST,"
    },
    {
      "file": "__init__.py",
      "line": 159,
      "col": 23,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_VERSION_TO_SPECS_C'。",
      "snippet": "    **{k: \"c\" for k in MAP_REPO_VERSION_TO_SPECS_C.keys()},"
    },
    {
      "file": "__init__.py",
      "line": 160,
      "col": 24,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_VERSION_TO_SPECS_GO'。",
      "snippet": "    **{k: \"go\" for k in MAP_REPO_VERSION_TO_SPECS_GO.keys()},"
    },
    {
      "file": "__init__.py",
      "line": 161,
      "col": 26,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_VERSION_TO_SPECS_JAVA'。",
      "snippet": "    **{k: \"java\" for k in MAP_REPO_VERSION_TO_SPECS_JAVA.keys()},"
    },
    {
      "file": "__init__.py",
      "line": 162,
      "col": 24,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_VERSION_TO_SPECS_JS'。",
      "snippet": "    **{k: \"js\" for k in MAP_REPO_VERSION_TO_SPECS_JS.keys()},"
    },
    {
      "file": "__init__.py",
      "line": 163,
      "col": 25,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_VERSION_TO_SPECS_PHP'。",
      "snippet": "    **{k: \"php\" for k in MAP_REPO_VERSION_TO_SPECS_PHP.keys()},"
    },
    {
      "file": "__init__.py",
      "line": 164,
      "col": 24,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_VERSION_TO_SPECS_PY'。",
      "snippet": "    **{k: \"py\" for k in MAP_REPO_VERSION_TO_SPECS_PY.keys()},"
    },
    {
      "file": "__init__.py",
      "line": 165,
      "col": 24,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_VERSION_TO_SPECS_RUBY'。",
      "snippet": "    **{k: \"rb\" for k in MAP_REPO_VERSION_TO_SPECS_RUBY.keys()},"
    },
    {
      "file": "__init__.py",
      "line": 166,
      "col": 24,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'MAP_REPO_VERSION_TO_SPECS_RUST'。",
      "snippet": "    **{k: \"rs\" for k in MAP_REPO_VERSION_TO_SPECS_RUST.keys()},"
    },
    {
      "file": "__init__.py",
      "line": 170,
      "col": 10,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'USE_X86_PY'。",
      "snippet": "USE_X86 = USE_X86_PY"
    },
    {
      "file": "c.py",
      "line": 83,
      "col": 20,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'expr'。",
      "snippet": "                    expr.get(\"success\") == \"true\" for expr in expressions"
    },
    {
      "file": "javascript.py",
      "line": 16,
      "col": 53,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'match_pattern'。",
      "snippet": "        [\" - \".join([x[0] for x in suite]), re.match(match_pattern, line).group(1)]"
    },
    {
      "file": "javascript.py",
      "line": 16,
      "col": 68,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'line'。",
      "snippet": "        [\" - \".join([x[0] for x in suite]), re.match(match_pattern, line).group(1)]"
    },
    {
      "file": "javascript.py",
      "line": 27,
      "col": 23,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "                    if re.search(r\"\\(\\d+ms\\)\", line) is not None"
    },
    {
      "file": "javascript.py",
      "line": 37,
      "col": 23,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "                    if re.search(r\"\\(\\d+ms\\)\", line) is not None"
    },
    {
      "file": "python.py",
      "line": 119,
      "col": 46,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if line.lstrip().startswith(\"ok\") and prev_test is not None:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 75,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if timeout is None:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 98,
      "col": 8,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "        except Exception as e:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 134,
      "col": 8,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "        except Exception as e:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 150,
      "col": 24,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "                        except Exception:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 154,
      "col": 12,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "            except Exception:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 159,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'staticmethod'。",
      "snippet": "    @staticmethod"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 258,
      "col": 4,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 376,
      "col": 4,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 458,
      "col": 24,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "                        except Exception:"
    },
    {
      "file": "run_evaluation_modal_entrypoint.py",
      "line": 112,
      "col": 23,
      "severity": "HIGH",
      "rule_id": "PY001",
      "message": "使用 exec 可能导致代码执行漏洞。",
      "snippet": "    returncode = await exec(command)"
    },
    {
      "file": "run_evaluation_modal_entrypoint.py",
      "line": 113,
      "col": 4,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'exit'。",
      "snippet": "    exit(returncode)"
    },
    {
      "file": "python.py",
      "line": 90,
      "col": 20,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'l'。",
      "snippet": "                len(l) + 1 for l in lines_after_pip[:ix]"
    },
    {
      "file": "python.py",
      "line": 248,
      "col": 52,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'ext'。",
      "snippet": "        d for d in directives if not any(d.endswith(ext) for ext in NON_TEST_EXTS)"
    },
    {
      "file": "test_spec.py",
      "line": 49,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'property'。",
      "snippet": "    @property"
    },
    {
      "file": "test_spec.py",
      "line": 56,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'property'。",
      "snippet": "    @property"
    },
    {
      "file": "test_spec.py",
      "line": 64,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'property'。",
      "snippet": "    @property"
    },
    {
      "file": "test_spec.py",
      "line": 71,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'property'。",
      "snippet": "    @property"
    },
    {
      "file": "test_spec.py",
      "line": 89,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'property'。",
      "snippet": "    @property"
    },
    {
      "file": "test_spec.py",
      "line": 106,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'property'。",
      "snippet": "    @property"
    },
    {
      "file": "test_spec.py",
      "line": 115,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        return self.namespace is not None"
    },
    {
      "file": "test_spec.py",
      "line": 113,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'property'。",
      "snippet": "    @property"
    },
    {
      "file": "test_spec.py",
      "line": 122,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'property'。",
      "snippet": "    @property"
    },
    {
      "file": "test_spec.py",
      "line": 131,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'property'。",
      "snippet": "    @property"
    },
    {
      "file": "test_spec.py",
      "line": 141,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'property'。",
      "snippet": "    @property"
    },
    {
      "file": "test_spec.py",
      "line": 145,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'property'。",
      "snippet": "    @property"
    },
    {
      "file": "test_spec.py",
      "line": 168,
      "col": 22,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'make_test_spec'。",
      "snippet": "            lambda x: make_test_spec(x, namespace, instance_image_tag, env_image_tag),"
    },
    {
      "file": "test_spec.py",
      "line": 168,
      "col": 37,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "            lambda x: make_test_spec(x, namespace, instance_image_tag, env_image_tag),"
    },
    {
      "file": "test_spec.py",
      "line": 184,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    assert base_image_tag is not None, \"base_image_tag cannot be None\""
    },
    {
      "file": "test_spec.py",
      "line": 185,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    assert env_image_tag is not None, \"env_image_tag cannot be None\""
    },
    {
      "file": "test_spec.py",
      "line": 186,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    assert instance_image_tag is not None, \"instance_image_tag cannot be None\""
    },
    {
      "file": "run_api.py",
      "line": 195,
      "col": 31,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "        lambda x: gpt_tokenize(x[\"text\"], encoding) <= MODEL_LIMITS[model_name_or_path],"
    },
    {
      "file": "run_api.py",
      "line": 200,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if openai_key is None:"
    },
    {
      "file": "run_api.py",
      "line": 240,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if max_cost is not None and total_cost >= max_cost:"
    },
    {
      "file": "run_api.py",
      "line": 274,
      "col": 4,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "run_api.py",
      "line": 315,
      "col": 4,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "run_api.py",
      "line": 343,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if api_key is None:"
    },
    {
      "file": "run_api.py",
      "line": 350,
      "col": 34,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "        lambda x: claude_tokenize(x[\"text\"], anthropic)"
    },
    {
      "file": "run_api.py",
      "line": 389,
      "col": 12,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "            except Exception as e:"
    },
    {
      "file": "run_api.py",
      "line": 401,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if max_cost is not None and total_cost >= max_cost:"
    },
    {
      "file": "run_api.py",
      "line": 417,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if model_args is not None:"
    },
    {
      "file": "run_api.py",
      "line": 452,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is None and num_shards is not None:"
    },
    {
      "file": "run_api.py",
      "line": 452,
      "col": 28,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is None and num_shards is not None:"
    },
    {
      "file": "run_api.py",
      "line": 456,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is not None and num_shards is None:"
    },
    {
      "file": "run_api.py",
      "line": 456,
      "col": 32,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is not None and num_shards is None:"
    },
    {
      "file": "run_api.py",
      "line": 465,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is not None and num_shards is not None:"
    },
    {
      "file": "run_api.py",
      "line": 465,
      "col": 32,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is not None and num_shards is not None:"
    },
    {
      "file": "run_api.py",
      "line": 488,
      "col": 22,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "            lambda x: x[\"instance_id\"] not in existing_ids,"
    },
    {
      "file": "run_api.py",
      "line": 492,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is not None and num_shards is not None:"
    },
    {
      "file": "run_api.py",
      "line": 492,
      "col": 32,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is not None and num_shards is not None:"
    },
    {
      "file": "run_live.py",
      "line": 61,
      "col": 34,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "    files = list(filter(lambda x: x.is_file(), files))"
    },
    {
      "file": "run_live.py",
      "line": 62,
      "col": 34,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "    files = list(filter(lambda x: x.name.lower().startswith(\"readme\"), files))"
    },
    {
      "file": "run_live.py",
      "line": 64,
      "col": 48,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "        files = sorted(files, key=lambda x: len(x.name))"
    },
    {
      "file": "run_live.py",
      "line": 111,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if commit is None:"
    },
    {
      "file": "run_live.py",
      "line": 184,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if base_commit is not None and len(issue_url) != len(base_commit):"
    },
    {
      "file": "run_live.py",
      "line": 188,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if base_commit is None:"
    },
    {
      "file": "run_live.py",
      "line": 191,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if gh_token is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 61,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if min_len is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 63,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if max_len is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 65,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is not None and num_shards is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 65,
      "col": 32,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is not None and num_shards is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 71,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if peft_path is not None and \"checkpoint\" in Path(peft_path).name:"
    },
    {
      "file": "run_llama.py",
      "line": 73,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    elif peft_path is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 143,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if peft_path is None:"
    },
    {
      "file": "run_llama.py",
      "line": 200,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if peft_path is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 206,
      "col": 32,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "            lambda x: tokenizer(x[\"text\"], truncation=False),"
    },
    {
      "file": "run_llama.py",
      "line": 213,
      "col": 36,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "            lambda x: {\"input_ids\": x[\"input_ids\"] + [13]}, batched=False"
    },
    {
      "file": "run_llama.py",
      "line": 216,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if min_len is not None and max_len is None:"
    },
    {
      "file": "run_llama.py",
      "line": 216,
      "col": 31,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if min_len is not None and max_len is None:"
    },
    {
      "file": "run_llama.py",
      "line": 217,
      "col": 32,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "        filter_func = lambda x: x >= min_len"
    },
    {
      "file": "run_llama.py",
      "line": 218,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    elif min_len is None and max_len is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 218,
      "col": 29,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    elif min_len is None and max_len is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 219,
      "col": 32,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "        filter_func = lambda x: x < max_len"
    },
    {
      "file": "run_llama.py",
      "line": 220,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    elif min_len is not None and max_len is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 220,
      "col": 33,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    elif min_len is not None and max_len is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 221,
      "col": 43,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "        filter_func = lambda x: min_len <= x < max_len"
    },
    {
      "file": "run_llama.py",
      "line": 222,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if filter_func is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 224,
      "col": 38,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "            lambda x: filter_func(len(x[\"input_ids\"])), desc=\"filtering for length\""
    },
    {
      "file": "run_llama.py",
      "line": 226,
      "col": 47,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "    lens = torch.tensor(list(map(lambda x: len(x[\"input_ids\"]), dataset)))"
    },
    {
      "file": "run_llama.py",
      "line": 228,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is not None and num_shards is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 228,
      "col": 32,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is not None and num_shards is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 231,
      "col": 18,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "        lambda x: x[\"instance_id\"] not in existing_ids,"
    },
    {
      "file": "run_llama.py",
      "line": 234,
      "col": 47,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "    lens = torch.tensor(list(map(lambda x: len(x[\"input_ids\"]), dataset)))  # recompute"
    },
    {
      "file": "run_llama.py",
      "line": 235,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is not None and num_shards is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 235,
      "col": 32,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is not None and num_shards is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 266,
      "col": 12,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'super'。",
      "snippet": "            super().__init__()"
    },
    {
      "file": "run_llama.py",
      "line": 322,
      "col": 58,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "                model_name_or_path += f\"__{peft_path}\" if peft_path is not None else \"\""
    },
    {
      "file": "run_llama.py",
      "line": 330,
      "col": 12,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "            except Exception as e:"
    },
    {
      "file": "run_llama.py",
      "line": 345,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if match is None:"
    },
    {
      "file": "run_llama.py",
      "line": 373,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is not None and num_shards is None:"
    },
    {
      "file": "run_llama.py",
      "line": 373,
      "col": 32,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is not None and num_shards is None:"
    },
    {
      "file": "run_llama.py",
      "line": 375,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is None and num_shards is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 375,
      "col": 28,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is None and num_shards is not None:"
    },
    {
      "file": "run_llama.py",
      "line": 378,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if peft_path is not None:"
    },
    {
      "file": "distributed_attention.py",
      "line": 16,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'staticmethod'。",
      "snippet": "    @staticmethod"
    },
    {
      "file": "distributed_attention.py",
      "line": 34,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'staticmethod'。",
      "snippet": "    @staticmethod"
    },
    {
      "file": "distributed_attention.py",
      "line": 59,
      "col": 8,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'super'。",
      "snippet": "        super().__init__()"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 71,
      "col": 8,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'super'。",
      "snippet": "        super().__init__()"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 126,
      "col": 8,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'super'。",
      "snippet": "        super().__init__()"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 139,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if scale_base is not None"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 191,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if self.scale is None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 221,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if unpadded_lengths is not None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 229,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if self.scale is None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 256,
      "col": 8,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'super'。",
      "snippet": "        super().__init__()"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 287,
      "col": 8,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'super'。",
      "snippet": "        super().__init__()"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 360,
      "col": 25,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        has_layer_past = past_key_value is not None and past_key_value[0] is not None"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 360,
      "col": 56,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        has_layer_past = past_key_value is not None and past_key_value[0] is not None"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 369,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if position_ids is not None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 413,
      "col": 19,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            assert output_attentions is False"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 424,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if unpadded_lengths is not None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 426,
      "col": 23,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "                assert attention_mask is not None"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 465,
      "col": 8,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'super'。",
      "snippet": "        super().__init__()"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 547,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if module.bias is not None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 551,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if module.padding_idx is not None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 555,
      "col": 30,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'LlamaModel'。",
      "snippet": "        if isinstance(module, LlamaModel):"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 568,
      "col": 8,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'super'。",
      "snippet": "        super().__init__(config)"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 605,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if output_attentions is not None"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 610,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if output_hidden_states is not None"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 613,
      "col": 33,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        use_cache = use_cache if use_cache is not None else self.config.use_cache"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 616,
      "col": 27,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            return_dict if return_dict is not None else self.config.use_return_dict"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 620,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if input_ids is not None and inputs_embeds is not None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 620,
      "col": 37,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if input_ids is not None and inputs_embeds is not None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 624,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        elif input_ids is not None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 626,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        elif inputs_embeds is not None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 635,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if inputs_embeds is None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 649,
      "col": 14,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            ((attention_mask is not None) and (not attention_mask.all().item()))"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 669,
      "col": 19,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "                if unpadded_lengths is not None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 678,
      "col": 19,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "                if past_key_values is not None and idx < len(past_key_values)"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 714,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if unpadded_lengths is not None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 727,
      "col": 19,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "                if v is not None"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 741,
      "col": 8,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'super'。",
      "snippet": "        super().__init__(config)"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 811,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if output_attentions is not None"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 816,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if output_hidden_states is not None"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 820,
      "col": 27,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            return_dict if return_dict is not None else self.config.use_return_dict"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 839,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if labels is not None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 849,
      "col": 16,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "                avg_valid_labels_per_chunk is not None"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 865,
      "col": 39,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            return (loss,) + output if loss is not None else output"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 887,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if inputs_embeds is not None and past_key_values is None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 887,
      "col": 41,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if inputs_embeds is not None and past_key_values is None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 899,
      "col": 21,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "                    (attention_mask is not None) and (not attention_mask.all().item())"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 912,
      "col": 20,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'past_state'。",
      "snippet": "                    past_state.index_select(0, beam_idx.to(past_state.device))"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 912,
      "col": 59,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'past_state'。",
      "snippet": "                    past_state.index_select(0, beam_idx.to(past_state.device))"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 906,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'staticmethod'。",
      "snippet": "    @staticmethod"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 921,
      "col": 8,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'super'。",
      "snippet": "        super().__init__(config)"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 955,
      "col": 27,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            return_dict if return_dict is not None else self.config.use_return_dict"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 972,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if input_ids is not None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 977,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if self.config.pad_token_id is None and batch_size != 1:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 981,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if self.config.pad_token_id is None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 984,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if input_ids is not None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 996,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if labels is not None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 998,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            if self.config.problem_type is None:"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 1024,
      "col": 41,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            return ((loss,) + output) if loss is not None else output"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 58,
      "col": 8,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "        except Exception as e:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 66,
      "col": 53,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "        files = list(filter(lambda x: os.path.isfile(x), files))"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 67,
      "col": 38,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "        files = list(filter(lambda x: x.lower().startswith(\"readme\"), files))"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 96,
      "col": 4,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 136,
      "col": 12,
      "severity": "LOW",
      "rule_id": "PY010",
      "message": "使用裸 except，建议捕获具体异常类型。",
      "snippet": "            except:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 138,
      "col": 4,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 261,
      "col": 11,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'KeyboardInterrupt'。",
      "snippet": "    except KeyboardInterrupt:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 263,
      "col": 14,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'KeyboardInterrupt'。",
      "snippet": "        raise KeyboardInterrupt"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 266,
      "col": 14,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'KeyboardInterrupt'。",
      "snippet": "        raise KeyboardInterrupt"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 332,
      "col": 12,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "            except Exception as e:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 334,
      "col": 33,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'round'。",
      "snippet": "                    cutoff = int(round(cutoff * 0.8))"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 343,
      "col": 4,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "    except Exception:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 364,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if results is None:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 409,
      "col": 4,
      "severity": "LOW",
      "rule_id": "PY010",
      "message": "使用裸 except，建议捕获具体异常类型。",
      "snippet": "    except:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 447,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if index_path is None:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 478,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if shard_id is not None:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 486,
      "col": 13,
      "severity": "HIGH",
      "rule_id": "PY003",
      "message": "subprocess.*(shell=True) 可能导致命令注入。",
      "snippet": "    python = subprocess.run(\"which python\", shell=True, capture_output=True)"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 504,
      "col": 11,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'KeyboardInterrupt'。",
      "snippet": "    except KeyboardInterrupt:"
    },
    {
      "file": "create_instance.py",
      "line": 362,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    assert progress_file is not None, \"progress_file is required\""
    },
    {
      "file": "create_instance.py",
      "line": 383,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if max_context_len is not None:"
    },
    {
      "file": "create_instance.py",
      "line": 384,
      "col": 19,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "            assert tokenizer_name is not None, ("
    },
    {
      "file": "create_instance.py",
      "line": 396,
      "col": 15,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'v'。",
      "snippet": "            k: v for k, v in instances.items() if k not in processed_ids"
    },
    {
      "file": "create_instance.py",
      "line": 419,
      "col": 27,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "                        if max_context_len is not None:"
    },
    {
      "file": "create_instance.py",
      "line": 446,
      "col": 27,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "                        if max_context_len is not None:"
    },
    {
      "file": "create_instance.py",
      "line": 484,
      "col": 16,
      "severity": "LOW",
      "rule_id": "PY011",
      "message": "过于宽泛的异常捕获：Exception。",
      "snippet": "                except Exception as e:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 60,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if instance[\"text_inputs\"] is None or instance[\"patch\"] is None:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 60,
      "col": 42,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if instance[\"text_inputs\"] is None or instance[\"patch\"] is None:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 64,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if text_inputs is None or instance[\"patch\"] is None:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 64,
      "col": 30,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if text_inputs is None or instance[\"patch\"] is None:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 75,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if push_to_hub_user is not None:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 77,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        assert hub_token is not None, ("
    },
    {
      "file": "create_text_dataset.py",
      "line": 80,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        assert output_dir is None, \"Cannot provide output_dir if pushing to the Hub\""
    },
    {
      "file": "create_text_dataset.py",
      "line": 81,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if max_context_len is not None:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 82,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        assert tokenizer_name is not None"
    },
    {
      "file": "create_text_dataset.py",
      "line": 83,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if push_to_hub_user is None and not Path(output_dir).exists():"
    },
    {
      "file": "create_text_dataset.py",
      "line": 85,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if max_context_len is not None:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 89,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        assert tokenizer_name is not None, ("
    },
    {
      "file": "create_text_dataset.py",
      "line": 92,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if k is not None:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 96,
      "col": 24,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    return hub_token if push_to_hub_user is not None else None"
    },
    {
      "file": "create_text_dataset.py",
      "line": 107,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if k is not None:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 109,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if max_context_len is not None:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 140,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if push_to_hub_user is None:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 241,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if push_to_hub_user is not None:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 251,
      "col": 0,
      "severity": "LOW",
      "rule_id": "PY203",
      "message": "list.remove() 要求参数为列表中的元素，而非索引。",
      "snippet": "            os.remove(progress_file)"
    },
    {
      "file": "eval_retrieval.py",
      "line": 21,
      "col": 4,
      "severity": "LOW",
      "rule_id": "PY010",
      "message": "使用裸 except，建议捕获具体异常类型。",
      "snippet": "    except:"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 39,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if instance[\"text\"] is None or instance[\"patch\"] is None:"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 39,
      "col": 35,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if instance[\"text\"] is None or instance[\"patch\"] is None:"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 43,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if text_inputs is None or instance[\"patch\"] is None:"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 43,
      "col": 30,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if text_inputs is None or instance[\"patch\"] is None:"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 76,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if instance[\"text\"] is None or instance[\"patch\"] is None:"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 76,
      "col": 35,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if instance[\"text\"] is None or instance[\"patch\"] is None:"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 80,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if text_inputs is None or instance[\"patch\"] is None:"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 80,
      "col": 30,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if text_inputs is None or instance[\"patch\"] is None:"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 116,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if push_to_hub_user is not None:"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 118,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if hub_token is None:"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 123,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if tokenizer_name is not None:"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 137,
      "col": 22,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "        lambda x: len(x[\"text\"]) <= 5_000_000"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 159,
      "col": 24,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "                        x, tokenizer_name, tokenizer, tokenizer_func, eos_token"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 190,
      "col": 24,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "                        x, tokenizer_name, tokenizer, tokenizer_func, eos_token"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 201,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if push_to_hub_user is not None:"
    },
    {
      "file": "utils.py",
      "line": 37,
      "col": 53,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "    first_chars = list(map(lambda x: None if not len(x) else x[0], hunk.split(\"\\n\")))"
    },
    {
      "file": "utils.py",
      "line": 37,
      "col": 61,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "    first_chars = list(map(lambda x: None if not len(x) else x[0], hunk.split(\"\\n\")))"
    },
    {
      "file": "utils.py",
      "line": 40,
      "col": 35,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "    new_lines = list(map(lambda x: x.rstrip(), hunk.split(\"\\n\")[first_idx:last_idx]))"
    },
    {
      "file": "utils.py",
      "line": 66,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if model_patch is None:"
    },
    {
      "file": "utils.py",
      "line": 81,
      "col": 46,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "                *list(map(lambda x: int(x) if x.isnumeric() else x, hunk)), total_delta"
    },
    {
      "file": "utils.py",
      "line": 81,
      "col": 40,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "                *list(map(lambda x: int(x) if x.isnumeric() else x, hunk)), total_delta"
    },
    {
      "file": "utils.py",
      "line": 81,
      "col": 65,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "                *list(map(lambda x: int(x) if x.isnumeric() else x, hunk)), total_delta"
    },
    {
      "file": "utils.py",
      "line": 101,
      "col": 40,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "                map(lambda x: int(x) if x.isnumeric() else x, hunk)"
    },
    {
      "file": "utils.py",
      "line": 101,
      "col": 34,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "                map(lambda x: int(x) if x.isnumeric() else x, hunk)"
    },
    {
      "file": "utils.py",
      "line": 101,
      "col": 59,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "                map(lambda x: int(x) if x.isnumeric() else x, hunk)"
    },
    {
      "file": "utils.py",
      "line": 118,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if response is None:"
    },
    {
      "file": "utils.py",
      "line": 142,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if test_phrases is None:"
    },
    {
      "file": "utils.py",
      "line": 145,
      "col": 15,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'word'。",
      "snippet": "    return any(word in words for word in test_phrases)"
    },
    {
      "file": "utils.py",
      "line": 159,
      "col": 12,
      "severity": "HIGH",
      "rule_id": "PY003",
      "message": "subprocess.*(shell=True) 可能导致命令注入。",
      "snippet": "            subprocess.run(cmd, shell=True, check=True)"
    },
    {
      "file": "utils.py",
      "line": 161,
      "col": 12,
      "severity": "HIGH",
      "rule_id": "PY003",
      "message": "subprocess.*(shell=True) 可能导致命令注入。",
      "snippet": "            subprocess.run("
    },
    {
      "file": "utils.py",
      "line": 171,
      "col": 14,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'NotImplementedError'。",
      "snippet": "        raise NotImplementedError()  # TODO: activate conda environment and return the environment file"
    },
    {
      "file": "utils.py",
      "line": 175,
      "col": 53,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "        files = list(filter(lambda x: os.path.isfile(x), files))"
    },
    {
      "file": "utils.py",
      "line": 176,
      "col": 38,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "        files = list(filter(lambda x: x.lower().startswith(\"readme\"), files))"
    },
    {
      "file": "utils.py",
      "line": 187,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if token is None:"
    },
    {
      "file": "utils.py",
      "line": 190,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if root_dir is None:"
    },
    {
      "file": "utils.py",
      "line": 204,
      "col": 8,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'super'。",
      "snippet": "        super().__init__(repo_dir, instance[\"base_commit\"], verbose=verbose)"
    },
    {
      "file": "utils.py",
      "line": 208,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if self.tempdir is not None:"
    },
    {
      "file": "utils.py",
      "line": 210,
      "col": 15,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'super'。",
      "snippet": "        return super().__exit__(exc_type, exc_val, exc_tb)"
    },
    {
      "file": "utils.py",
      "line": 282,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if encoding is None:"
    },
    {
      "file": "utils.py",
      "line": 288,
      "col": 20,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'UnicodeDecodeError'。",
      "snippet": "            except (UnicodeDecodeError, LookupError):"
    },
    {
      "file": "utils.py",
      "line": 288,
      "col": 40,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'LookupError'。",
      "snippet": "            except (UnicodeDecodeError, LookupError):"
    },
    {
      "file": "get_versions.py",
      "line": 48,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if matches is not None:"
    },
    {
      "file": "get_versions.py",
      "line": 76,
      "col": 47,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "    keep_major_minor = lambda x, sep: \".\".join(x.strip().split(sep)[:2])"
    },
    {
      "file": "get_versions.py",
      "line": 76,
      "col": 63,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'sep'。",
      "snippet": "    keep_major_minor = lambda x, sep: \".\".join(x.strip().split(sep)[:2])"
    },
    {
      "file": "get_versions.py",
      "line": 81,
      "col": 24,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if is_build and path_repo is not None:"
    },
    {
      "file": "get_versions.py",
      "line": 96,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if version is not None:"
    },
    {
      "file": "get_versions.py",
      "line": 158,
      "col": 8,
      "severity": "HIGH",
      "rule_id": "PY003",
      "message": "subprocess.*(shell=True) 可能导致命令注入。",
      "snippet": "        subprocess.run("
    },
    {
      "file": "get_versions.py",
      "line": 161,
      "col": 8,
      "severity": "HIGH",
      "rule_id": "PY003",
      "message": "subprocess.*(shell=True) 可能导致命令注入。",
      "snippet": "        subprocess.run("
    },
    {
      "file": "get_versions.py",
      "line": 164,
      "col": 8,
      "severity": "HIGH",
      "rule_id": "PY003",
      "message": "subprocess.*(shell=True) 可能导致命令注入。",
      "snippet": "        subprocess.run("
    },
    {
      "file": "get_versions.py",
      "line": 167,
      "col": 20,
      "severity": "HIGH",
      "rule_id": "PY003",
      "message": "subprocess.*(shell=True) 可能导致命令注入。",
      "snippet": "        out_check = subprocess.run("
    },
    {
      "file": "get_versions.py",
      "line": 177,
      "col": 22,
      "severity": "HIGH",
      "rule_id": "PY003",
      "message": "subprocess.*(shell=True) 可能导致命令注入。",
      "snippet": "        out_install = subprocess.run("
    },
    {
      "file": "get_versions.py",
      "line": 210,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        if version is not None:"
    },
    {
      "file": "get_versions.py",
      "line": 213,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "        elif version_not_found is not None:"
    },
    {
      "file": "get_versions.py",
      "line": 242,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "    if output_dir is not None:"
    },
    {
      "file": "get_versions.py",
      "line": 277,
      "col": 34,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'data_task_list'。",
      "snippet": "                    \"data_tasks\": data_task_list,"
    },
    {
      "file": "get_versions.py",
      "line": 278,
      "col": 59,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'i'。",
      "snippet": "                    \"save_path\": f\"{repo_prefix}_versions_{i}.json\""
    },
    {
      "file": "get_versions.py",
      "line": 280,
      "col": 51,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'i'。",
      "snippet": "                    else f\"{repo_prefix}_versions_{i}_web.json\","
    },
    {
      "file": "get_versions.py",
      "line": 324,
      "col": 12,
      "severity": "HIGH",
      "rule_id": "PY003",
      "message": "subprocess.*(shell=True) 可能导致命令注入。",
      "snippet": "            subprocess.run(cmd_clone, shell=True, check=True, stdout=subprocess.DEVNULL)"
    },
    {
      "file": "get_versions.py",
      "line": 334,
      "col": 12,
      "severity": "HIGH",
      "rule_id": "PY003",
      "message": "subprocess.*(shell=True) 可能导致命令注入。",
      "snippet": "            subprocess.run("
    },
    {
      "file": "get_versions.py",
      "line": 382,
      "col": 12,
      "severity": "HIGH",
      "rule_id": "PY003",
      "message": "subprocess.*(shell=True) 可能导致命令注入。",
      "snippet": "            subprocess.run(f\"rm -rf {testbed_repo_name}\", shell=True, check=True)"
    },
    {
      "file": "get_versions.py",
      "line": 388,
      "col": 12,
      "severity": "HIGH",
      "rule_id": "PY003",
      "message": "subprocess.*(shell=True) 可能导致命令注入。",
      "snippet": "            subprocess.run(cmd_rm_env, shell=True, check=True)"
    },
    {
      "file": "get_versions.py",
      "line": 237,
      "col": 0,
      "severity": "LOW",
      "rule_id": "PY203",
      "message": "list.remove() 要求参数为列表中的元素，而非索引。",
      "snippet": "        os.remove(task_with_version_path)"
    },
    {
      "file": "get_versions_astropy.py",
      "line": 27,
      "col": 43,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "keep_major_minor = lambda x, sep: \".\".join(x.strip().split(sep)[:2])"
    },
    {
      "file": "get_versions_astropy.py",
      "line": 27,
      "col": 59,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'sep'。",
      "snippet": "keep_major_minor = lambda x, sep: \".\".join(x.strip().split(sep)[:2])"
    },
    {
      "file": "get_versions_astropy.py",
      "line": 46,
      "col": 20,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'k'。",
      "snippet": "version_to_time = [(k, max(v)) for k, v in map_version_to_times.items()]"
    },
    {
      "file": "get_versions_astropy.py",
      "line": 46,
      "col": 27,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'v'。",
      "snippet": "version_to_time = [(k, max(v)) for k, v in map_version_to_times.items()]"
    },
    {
      "file": "get_versions_astropy.py",
      "line": 47,
      "col": 56,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "version_to_time = sorted(version_to_time, key=lambda x: x[0])[::-1]"
    },
    {
      "file": "get_versions_matplotlib.py",
      "line": 25,
      "col": 43,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "keep_major_minor = lambda x, sep: \".\".join(x.strip().split(sep)[:2])"
    },
    {
      "file": "get_versions_matplotlib.py",
      "line": 25,
      "col": 59,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'sep'。",
      "snippet": "keep_major_minor = lambda x, sep: \".\".join(x.strip().split(sep)[:2])"
    },
    {
      "file": "get_versions_matplotlib.py",
      "line": 36,
      "col": 36,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "times = sorted(times, key=lambda x: x[0])[::-1]"
    },
    {
      "file": "get_versions_pvlib-python.py",
      "line": 28,
      "col": 43,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "keep_major_minor = lambda x, sep: \".\".join(x.strip().split(sep)[:2])"
    },
    {
      "file": "get_versions_pvlib-python.py",
      "line": 28,
      "col": 59,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'sep'。",
      "snippet": "keep_major_minor = lambda x, sep: \".\".join(x.strip().split(sep)[:2])"
    },
    {
      "file": "get_versions_pvlib-python.py",
      "line": 47,
      "col": 20,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'k'。",
      "snippet": "version_to_time = [(k, max(v)) for k, v in map_version_to_times.items()]"
    },
    {
      "file": "get_versions_pvlib-python.py",
      "line": 47,
      "col": 27,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'v'。",
      "snippet": "version_to_time = [(k, max(v)) for k, v in map_version_to_times.items()]"
    },
    {
      "file": "get_versions_pvlib-python.py",
      "line": 48,
      "col": 56,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "version_to_time = sorted(version_to_time, key=lambda x: x[0])[::-1]"
    },
    {
      "file": "get_versions_pydicom.py",
      "line": 31,
      "col": 36,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'x'。",
      "snippet": "times = sorted(times, key=lambda x: x[0], reverse=True)"
    },
    {
      "file": "get_versions_sqlfluff.py",
      "line": 10,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PY012",
      "message": "疑似硬编码凭据变量：GITHUB_TOKEN。",
      "snippet": "GITHUB_TOKEN = \"<your GitHub token>\""
    },
    {
      "file": "get_versions_sqlfluff.py",
      "line": 68,
      "col": 10,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'v'。",
      "snippet": "times = [(v, k) for k, v in version_date_map.items()]"
    },
    {
      "file": "get_versions_sqlfluff.py",
      "line": 68,
      "col": 13,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'k'。",
      "snippet": "times = [(v, k) for k, v in version_date_map.items()]"
    },
    {
      "file": "get_versions_sqlfluff.py",
      "line": 93,
      "col": 54,
      "severity": "MEDIUM",
      "rule_id": "AST002",
      "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
      "snippet": "print(sorted(list({t[\"version\"] for t in versioned if t[\"version\"] is not None})))"
    },
    {
      "file": "get_versions_xarray.py",
      "line": 28,
      "col": 59,
      "severity": "HIGH",
      "rule_id": "PY100",
      "message": "使用了未定义的名称 'sep'。",
      "snippet": "keep_major_minor = lambda x, sep: \".\".join(x.strip().split(sep)[:2])"
    },
    {
      "file": "get_versions_xarray.py",
      "line": 40,
      "col": 8,
      "severity": "LOW",
      "rule_id": "PY010",
      "message": "使用裸 except，建议捕获具体异常类型。",
      "snippet": "        except:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import json"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 41,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (93 > 88)",
      "snippet": "        __enter__(): Switches to the specified commit and returns the context manager object."
    },
    {
      "file": "bm25_retrieval.py",
      "line": 42,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (95 > 88)",
      "snippet": "        get_readme_files(): Returns a list of filenames for all README files in the repository."
    },
    {
      "file": "bm25_retrieval.py",
      "line": 115,
      "col": 9,
      "severity": "HIGH",
      "rule_id": "RUFF-F841",
      "message": "Local variable `abspath` is assigned to but never used",
      "snippet": "        abspath = Path(filename).absolute()"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 136,
      "col": 13,
      "severity": "HIGH",
      "rule_id": "RUFF-E722",
      "message": "Do not use bare `except`",
      "snippet": "            except:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 181,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (134 > 88)",
      "snippet": "        document_encoding_func (function): A function that takes a filename and a relative path and returns the encoded document text."
    },
    {
      "file": "bm25_retrieval.py",
      "line": 184,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (127 > 88)",
      "snippet": "        dict: A dictionary where the keys are the relative paths of the documents and the values are the encoded document text."
    },
    {
      "file": "bm25_retrieval.py",
      "line": 263,
      "col": 9,
      "severity": "LOW",
      "rule_id": "RUFF-B904",
      "message": "Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling",
      "snippet": "        raise KeyboardInterrupt"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 278,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (102 > 88)",
      "snippet": "    Filters a list of instances to exclude those that have already been processed and saved in a file."
    },
    {
      "file": "bm25_retrieval.py",
      "line": 281,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (115 > 88)",
      "snippet": "        instances (List[Dict]): A list of instances, where each instance is a dictionary with an \"instance_id\" key."
    },
    {
      "file": "bm25_retrieval.py",
      "line": 282,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (89 > 88)",
      "snippet": "        output_file (Path): The path to the file where the processed instances are saved."
    },
    {
      "file": "bm25_retrieval.py",
      "line": 297,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (97 > 88)",
      "snippet": "                f\"Found {len(instance_ids)} existing instances in {output_file}. Will skip them.\""
    },
    {
      "file": "bm25_retrieval.py",
      "line": 318,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (119 > 88)",
      "snippet": "        dict: A dictionary containing the instance ID and a list of hits, where each hit is a dictionary containing the"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 351,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (91 > 88)",
      "snippet": "    Searches the indexes for the given instances and writes the results to the output file."
    },
    {
      "file": "bm25_retrieval.py",
      "line": 356,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (96 > 88)",
      "snippet": "        all_index_paths (dict): A dictionary mapping instance IDs to the paths of their indexes."
    },
    {
      "file": "bm25_retrieval.py",
      "line": 409,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "RUFF-E722",
      "message": "Do not use bare `except`",
      "snippet": "    except:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 532,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (106 > 88)",
      "snippet": "        help=\"Dataset to use for test set from HuggingFace Datasets or path to a save_to_disk directory.\","
    },
    {
      "file": "build_dataset.py",
      "line": 3,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import argparse"
    },
    {
      "file": "build_dataset.py",
      "line": 183,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (123 > 88)",
      "snippet": "        f\"[{', '.join(repos.keys())}] Total instances: {total_instances}, completed: {completed}, with tests: {with_tests}\""
    },
    {
      "file": "build_dataset.py",
      "line": 186,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (109 > 88)",
      "snippet": "        f\"[{', '.join(repos.keys())}] Skipped {len(seen_prs)} pull requests that have already been inspected\""
    },
    {
      "file": "build_dataset_ft.py",
      "line": 3,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import argparse"
    },
    {
      "file": "build_dataset_ft.py",
      "line": 62,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (104 > 88)",
      "snippet": "        f\"Fine tuning dataset saved to {destination} ({total_insts} instances from {total_repos} repos)\""
    },
    {
      "file": "create_instance.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import json"
    },
    {
      "file": "create_instance.py",
      "line": 31,
      "col": 1,
      "severity": "MEDIUM",
      "rule_id": "RUFF-W293",
      "message": "Blank line contains whitespace",
      "snippet": " "
    },
    {
      "file": "create_instance.py",
      "line": 32,
      "col": 1,
      "severity": "MEDIUM",
      "rule_id": "RUFF-W293",
      "message": "Blank line contains whitespace",
      "snippet": " "
    },
    {
      "file": "create_instance.py",
      "line": 43,
      "col": 1,
      "severity": "MEDIUM",
      "rule_id": "RUFF-W293",
      "message": "Blank line contains whitespace",
      "snippet": " "
    },
    {
      "file": "create_instance.py",
      "line": 72,
      "col": 1,
      "severity": "MEDIUM",
      "rule_id": "RUFF-W293",
      "message": "Blank line contains whitespace",
      "snippet": " "
    },
    {
      "file": "create_instance.py",
      "line": 166,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (117 > 88)",
      "snippet": "    premise = \"You will be provided with a partial code base and an issue statement explaining a problem to resolve.\""
    },
    {
      "file": "create_instance.py",
      "line": 170,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (92 > 88)",
      "snippet": "        \"I need you to solve this issue by generating a single patch file that I can apply \""
    },
    {
      "file": "create_instance.py",
      "line": 171,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (92 > 88)",
      "snippet": "        + \"directly to this repository using git apply. Please respond with a single patch \""
    },
    {
      "file": "create_instance.py",
      "line": 194,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (117 > 88)",
      "snippet": "    premise = \"You will be provided with a partial code base and an issue statement explaining a problem to resolve.\""
    },
    {
      "file": "create_instance.py",
      "line": 198,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (92 > 88)",
      "snippet": "        \"I need you to solve this issue by generating a single patch file that I can apply \""
    },
    {
      "file": "create_instance.py",
      "line": 199,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (92 > 88)",
      "snippet": "        + \"directly to this repository using git apply. Please respond with a single patch \""
    },
    {
      "file": "create_instance.py",
      "line": 222,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (117 > 88)",
      "snippet": "    premise = \"You will be provided with a partial code base and an issue statement explaining a problem to resolve.\""
    },
    {
      "file": "create_instance.py",
      "line": 227,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (107 > 88)",
      "snippet": "        + \"It specifies the file names, the line numbers of each change, and the removed and added lines. \""
    },
    {
      "file": "create_instance.py",
      "line": 231,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (100 > 88)",
      "snippet": "        \"I need you to solve the provided issue by generating a single patch file that I can apply \""
    },
    {
      "file": "create_instance.py",
      "line": 232,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (92 > 88)",
      "snippet": "        + \"directly to this repository using git apply. Please respond with a single patch \""
    },
    {
      "file": "create_instance.py",
      "line": 260,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (117 > 88)",
      "snippet": "    premise = \"You will be provided with a partial code base and an issue statement explaining a problem to resolve.\""
    },
    {
      "file": "create_instance.py",
      "line": 264,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (120 > 88)",
      "snippet": "        \"I need you to solve this issue by regenerating the full files in the code base that you would like to change. \""
    },
    {
      "file": "create_instance.py",
      "line": 266,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (99 > 88)",
      "snippet": "        + \"Please respond with a list of files and their revised contents in the following format.\""
    },
    {
      "file": "create_instance.py",
      "line": 355,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (89 > 88)",
      "snippet": "    - retrieval_file: if using retrieval method for file_contents, specify retrieval_file"
    },
    {
      "file": "create_scripts.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "from swebench.harness.constants import MAP_REPO_TO_EXT"
    },
    {
      "file": "create_text_dataset.py",
      "line": 7,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import json"
    },
    {
      "file": "create_text_dataset.py",
      "line": 26,
      "col": 8,
      "severity": "HIGH",
      "rule_id": "RUFF-E721",
      "message": "Use `is` and `is not` for type comparisons, or `isinstance()` for isinstance checks",
      "snippet": "    if type(filename) == str:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 147,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (105 > 88)",
      "snippet": "                        f\"{output_file.absolute().as_posix()} already exists for split {split}. Aborting\""
    },
    {
      "file": "create_text_dataset.py",
      "line": 223,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (180 > 88)",
      "snippet": "                f\"Found {len(invalid_instances)} instances in progress file that are not in the {split} dataset: {invalid_instances}. These will be removed from the final dataset.\""
    },
    {
      "file": "create_text_dataset.py",
      "line": 262,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (106 > 88)",
      "snippet": "        help=\"Dataset to use for test set from HuggingFace Datasets or path to a save_to_disk directory.\","
    },
    {
      "file": "create_text_dataset.py",
      "line": 313,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (98 > 88)",
      "snippet": "        help=\"Tokenizer to use for max_context_len. Only needed if max_context_len is specified.\","
    },
    {
      "file": "create_text_dataset.py",
      "line": 318,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (91 > 88)",
      "snippet": "        help=\"Username to use for pushing to the Hub. If not provided, will save to disk.\","
    },
    {
      "file": "criteria.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import re"
    },
    {
      "file": "criteria.py",
      "line": 24,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (91 > 88)",
      "snippet": "    Returns True if the text contains a URL. Excludes URLs that are part of the repository."
    },
    {
      "file": "criteria.py",
      "line": 29,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (111 > 88)",
      "snippet": "        # Adding a negative lookahead assertion to ensure URLs starting with the repository prefix are excluded"
    },
    {
      "file": "criteria.py",
      "line": 79,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (96 > 88)",
      "snippet": "    Returns True if text (problem statement) contains a reference to another issue (e.g. #1234)."
    },
    {
      "file": "criteria.py",
      "line": 117,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (89 > 88)",
      "snippet": "    Returns True if the test patch contains a pytest.raises() call with a match argument."
    },
    {
      "file": "default.py",
      "line": 1,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (109 > 88)",
      "snippet": "\"\"\"Basic agent class. See https://mini-swe-agent.com/latest/advanced/control_flow/ for visual explanation.\"\"\""
    },
    {
      "file": "default.py",
      "line": 3,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import re"
    },
    {
      "file": "default.py",
      "line": 15,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (120 > 88)",
      "snippet": "    # The default settings are the bare minimum to run the agent. Take a look at the config files for improved settings."
    },
    {
      "file": "default.py",
      "line": 18,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (93 > 88)",
      "snippet": "        \"Your task: {{task}}. Please reply with a single shell command in triple backticks. \""
    },
    {
      "file": "default.py",
      "line": 19,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (119 > 88)",
      "snippet": "        \"To finish, the first line of the output of the shell command must be 'COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT'.\""
    },
    {
      "file": "default.py",
      "line": 22,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (99 > 88)",
      "snippet": "        \"The last command <command>{{action['action']}}</command> timed out and has been killed.\\n\""
    },
    {
      "file": "default.py",
      "line": 24,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (94 > 88)",
      "snippet": "        \"Please try another command and make sure to avoid those requiring interactive input.\""
    },
    {
      "file": "default.py",
      "line": 26,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (96 > 88)",
      "snippet": "    format_error_template: str = \"Please always provide EXACTLY ONE action in triple backticks.\""
    },
    {
      "file": "default.py",
      "line": 57,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (106 > 88)",
      "snippet": "    def __init__(self, model: Model, env: Environment, *, config_class: Callable = AgentConfig, **kwargs):"
    },
    {
      "file": "default.py",
      "line": 65,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (107 > 88)",
      "snippet": "        template_vars = asdict(self.config) | self.env.get_template_vars() | self.model.get_template_vars()"
    },
    {
      "file": "default.py",
      "line": 66,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (95 > 88)",
      "snippet": "        return Template(template).render(**kwargs, **template_vars, **self.extra_template_vars)"
    },
    {
      "file": "default.py",
      "line": 92,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (109 > 88)",
      "snippet": "        if 0 < self.config.step_limit <= self.model.n_calls or 0 < self.config.cost_limit <= self.model.cost:"
    },
    {
      "file": "default.py",
      "line": 101,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (98 > 88)",
      "snippet": "        observation = self.render_template(self.config.action_observation_template, output=output)"
    },
    {
      "file": "default.py",
      "line": 110,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (99 > 88)",
      "snippet": "        raise FormatError(self.render_template(self.config.format_error_template, actions=actions))"
    },
    {
      "file": "default.py",
      "line": 117,
      "col": 13,
      "severity": "LOW",
      "rule_id": "RUFF-B904",
      "message": "Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling",
      "snippet": "            raise ExecutionTimeoutError("
    },
    {
      "file": "default.py",
      "line": 118,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (96 > 88)",
      "snippet": "                self.render_template(self.config.timeout_template, action=action, output=output)"
    },
    {
      "file": "default.py",
      "line": 121,
      "col": 13,
      "severity": "LOW",
      "rule_id": "RUFF-B904",
      "message": "Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling",
      "snippet": "            raise ExecutionTimeoutError(self.render_template(self.config.timeout_template, action=action, output=\"\"))"
    },
    {
      "file": "default.py",
      "line": 121,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (117 > 88)",
      "snippet": "            raise ExecutionTimeoutError(self.render_template(self.config.timeout_template, action=action, output=\"\"))"
    },
    {
      "file": "default.py",
      "line": 126,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (94 > 88)",
      "snippet": "        \"\"\"Raises Submitted exception with final output if the agent has finished its task.\"\"\""
    },
    {
      "file": "default.py",
      "line": 128,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (114 > 88)",
      "snippet": "        if lines and lines[0].strip() in [\"MINI_SWE_AGENT_FINAL_OUTPUT\", \"COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT\"]:"
    },
    {
      "file": "distributed_attention.py",
      "line": 6,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import torch"
    },
    {
      "file": "docker_build.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "from __future__ import annotations"
    },
    {
      "file": "docker_build.py",
      "line": 58,
      "col": 5,
      "severity": "LOW",
      "rule_id": "RUFF-B010",
      "message": "Do not call `setattr` with a constant attribute value. It is not any safer than normal property access.",
      "snippet": "    setattr(logger, \"log_file\", log_file)"
    },
    {
      "file": "docker_build.py",
      "line": 94,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (106 > 88)",
      "snippet": "        build_dir (Path): Directory for the build context (will also contain logs, scripts, and artifacts)"
    },
    {
      "file": "docker_build.py",
      "line": 125,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (89 > 88)",
      "snippet": "            f\"Building docker image {image_name} in {build_dir} with platform {platform}\""
    },
    {
      "file": "docker_build.py",
      "line": 176,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (92 > 88)",
      "snippet": "        force_rebuild (bool): Whether to force rebuild the images even if they already exist"
    },
    {
      "file": "docker_build.py",
      "line": 223,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (96 > 88)",
      "snippet": "    Returns a dictionary of image names to build scripts and dockerfiles for environment images."
    },
    {
      "file": "docker_build.py",
      "line": 246,
      "col": 13,
      "severity": "HIGH",
      "rule_id": "RUFF-F841",
      "message": "Local variable `base_image` is assigned to but never used",
      "snippet": "            base_image = base_images[test_spec.base_image_key]"
    },
    {
      "file": "docker_build.py",
      "line": 248,
      "col": 13,
      "severity": "LOW",
      "rule_id": "RUFF-B904",
      "message": "Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling",
      "snippet": "            raise Exception("
    },
    {
      "file": "docker_build.py",
      "line": 249,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (99 > 88)",
      "snippet": "                f\"Base image {test_spec.base_image_key} not found for {test_spec.env_image_key}\\n.\""
    },
    {
      "file": "docker_build.py",
      "line": 256,
      "col": 13,
      "severity": "HIGH",
      "rule_id": "RUFF-F841",
      "message": "Local variable `env_image` is assigned to but never used",
      "snippet": "            env_image = client.images.get(test_spec.env_image_key)"
    },
    {
      "file": "docker_build.py",
      "line": 285,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (92 > 88)",
      "snippet": "        force_rebuild (bool): Whether to force rebuild the images even if they already exist"
    },
    {
      "file": "docker_build.py",
      "line": 351,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (92 > 88)",
      "snippet": "        force_rebuild (bool): Whether to force rebuild the images even if they already exist"
    },
    {
      "file": "docker_build.py",
      "line": 430,
      "col": 9,
      "severity": "HIGH",
      "rule_id": "RUFF-F841",
      "message": "Local variable `env_image` is assigned to but never used",
      "snippet": "        env_image = client.images.get(env_image_name)"
    },
    {
      "file": "docker_build.py",
      "line": 479,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (93 > 88)",
      "snippet": "    Builds the instance image for the given test spec and creates a container from the image."
    },
    {
      "file": "docker_build.py",
      "line": 483,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (95 > 88)",
      "snippet": "        client (docker.DockerClient): Docker client for building image + creating the container"
    },
    {
      "file": "docker_build.py",
      "line": 487,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (90 > 88)",
      "snippet": "        force_rebuild (bool): Whether to force rebuild the image even if it already exists"
    },
    {
      "file": "docker_build.py",
      "line": 503,
      "col": 17,
      "severity": "LOW",
      "rule_id": "RUFF-B904",
      "message": "Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling",
      "snippet": "                raise Exception("
    },
    {
      "file": "docker_build.py",
      "line": 504,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (94 > 88)",
      "snippet": "                    f\"Error occurred while pulling image {test_spec.base_image_key}: {str(e)}\""
    },
    {
      "file": "docker_utils.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "from __future__ import annotations"
    },
    {
      "file": "docker_utils.py",
      "line": 80,
      "col": 9,
      "severity": "HIGH",
      "rule_id": "RUFF-E731",
      "message": "Do not assign a `lambda` expression, use a `def`",
      "snippet": "        log_info = lambda x: None"
    },
    {
      "file": "docker_utils.py",
      "line": 81,
      "col": 9,
      "severity": "HIGH",
      "rule_id": "RUFF-E731",
      "message": "Do not assign a `lambda` expression, use a `def`",
      "snippet": "        log_error = lambda x: None"
    },
    {
      "file": "docker_utils.py",
      "line": 122,
      "col": 9,
      "severity": "HIGH",
      "rule_id": "RUFF-E731",
      "message": "Do not assign a `lambda` expression, use a `def`",
      "snippet": "        log_info = lambda x: None"
    },
    {
      "file": "docker_utils.py",
      "line": 123,
      "col": 9,
      "severity": "HIGH",
      "rule_id": "RUFF-E731",
      "message": "Do not assign a `lambda` expression, use a `def`",
      "snippet": "        log_error = lambda x: None"
    },
    {
      "file": "docker_utils.py",
      "line": 138,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (91 > 88)",
      "snippet": "            f\"Failed to stop container {container.name}: {e}. Trying to forcefully kill...\""
    },
    {
      "file": "docker_utils.py",
      "line": 276,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (109 > 88)",
      "snippet": "        clean (bool): Whether to clean; remove images that are higher in the cache hierarchy than the current"
    },
    {
      "file": "docker_utils.py",
      "line": 277,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (108 > 88)",
      "snippet": "            cache level. E.g. if cache_level is set to env, remove all previously built instances images. if"
    },
    {
      "file": "docker_utils.py",
      "line": 278,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (108 > 88)",
      "snippet": "            clean is false, previously built instances images will not be removed, but instance images built"
    },
    {
      "file": "eval_retrieval.py",
      "line": 3,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (175 > 88)",
      "snippet": "\"\"\"This script can be used to evaluate the BM25 retrieval results for a dataset created with create_text_dataset.py with the --retrieval_file option and --file_source bm25.\"\"\""
    },
    {
      "file": "eval_retrieval.py",
      "line": 5,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import re"
    },
    {
      "file": "eval_retrieval.py",
      "line": 21,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "RUFF-E722",
      "message": "Do not use bare `except`",
      "snippet": "    except:"
    },
    {
      "file": "get_tasks_pipeline.py",
      "line": 5,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import argparse"
    },
    {
      "file": "get_tasks_pipeline.py",
      "line": 75,
      "col": 88,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (95 > 88)",
      "snippet": "                    f\"📁 Pull request data for {repo} already exists at {path_pr}, skipping...\""
    },
    {
      "file": "get_tasks_pipeline.py",
      "line": 83,
      "col": 88,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (89 > 88)",
      "snippet": "                    f\"✅ Successfully saved task instance data for {repo} to {path_task}\""
    },
    {
      "file": "get_tasks_pipeline.py",
      "line": 87,
      "col": 88,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (98 > 88)",
      "snippet": "                    f\"📁 Task instance data for {repo} already exists at {path_task}, skipping...\""
    },
    {
      "file": "get_tasks_pipeline.py",
      "line": 121,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (91 > 88)",
      "snippet": "            \"Missing GITHUB_TOKENS, consider rerunning with GITHUB_TOKENS=$(gh auth token)\""
    },
    {
      "file": "get_tasks_pipeline.py",
      "line": 135,
      "col": 29,
      "severity": "LOW",
      "rule_id": "RUFF-B905",
      "message": "`zip()` without an explicit `strict=` parameter",
      "snippet": "        for repos, token in zip(data_task_lists, tokens)"
    },
    {
      "file": "get_tasks_pipeline.py",
      "line": 147,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (93 > 88)",
      "snippet": "        help=\"List of repositories (e.g., `sqlfluff/sqlfluff`) to create task instances for\","
    },
    {
      "file": "get_top_pypi.py",
      "line": 3,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import os"
    },
    {
      "file": "get_top_pypi.py",
      "line": 74,
      "col": 17,
      "severity": "HIGH",
      "rule_id": "RUFF-E722",
      "message": "Do not use bare `except`",
      "snippet": "                except:"
    },
    {
      "file": "get_versions.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import argparse"
    },
    {
      "file": "get_versions.py",
      "line": 76,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "RUFF-E731",
      "message": "Do not assign a `lambda` expression, use a `def`",
      "snippet": "    keep_major_minor = lambda x, sep: \".\".join(x.strip().split(sep)[:2])"
    },
    {
      "file": "get_versions.py",
      "line": 265,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (110 > 88)",
      "snippet": "        f\"Split instances into {len(data_task_lists)} groups with lengths {[len(x) for x in data_task_lists]}\""
    },
    {
      "file": "get_versions.py",
      "line": 268,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (92 > 88)",
      "snippet": "    # If retrieval method includes GitHub, then search GitHub for versions via parallel call"
    },
    {
      "file": "get_versions.py",
      "line": 304,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (128 > 88)",
      "snippet": "                f\"Split instances into {len(data_task_lists)} groups with lengths {[len(x) for x in data_task_lists]} for build\""
    },
    {
      "file": "get_versions.py",
      "line": 327,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (92 > 88)",
      "snippet": "                f\"Repo for {data_tasks[0]['repo']} exists: {testbed_repo_name}; skipping...\""
    },
    {
      "file": "get_versions.py",
      "line": 333,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (102 > 88)",
      "snippet": "            cmd_clone_env = f\"{conda_exec} create --name {conda_env_name} --clone {args.conda_env} -y\""
    },
    {
      "file": "get_versions_astropy.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import json"
    },
    {
      "file": "get_versions_astropy.py",
      "line": 27,
      "col": 1,
      "severity": "HIGH",
      "rule_id": "RUFF-E731",
      "message": "Do not assign a `lambda` expression, use a `def`",
      "snippet": "keep_major_minor = lambda x, sep: \".\".join(x.strip().split(sep)[:2])"
    },
    {
      "file": "get_versions_matplotlib.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import json"
    },
    {
      "file": "get_versions_matplotlib.py",
      "line": 19,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (119 > 88)",
      "snippet": "pattern = r'<a class=\"reference internal\" href=\"prev_whats_new/whats_new_(.*).html\">What\\'s new in Matplotlib (.*)</a>'"
    },
    {
      "file": "get_versions_matplotlib.py",
      "line": 25,
      "col": 1,
      "severity": "HIGH",
      "rule_id": "RUFF-E731",
      "message": "Do not assign a `lambda` expression, use a `def`",
      "snippet": "keep_major_minor = lambda x, sep: \".\".join(x.strip().split(sep)[:2])"
    },
    {
      "file": "get_versions_pvlib-python.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import json"
    },
    {
      "file": "get_versions_pvlib-python.py",
      "line": 28,
      "col": 1,
      "severity": "HIGH",
      "rule_id": "RUFF-E731",
      "message": "Do not assign a `lambda` expression, use a `def`",
      "snippet": "keep_major_minor = lambda x, sep: \".\".join(x.strip().split(sep)[:2])"
    },
    {
      "file": "get_versions_pydicom.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import datetime"
    },
    {
      "file": "get_versions_sqlfluff.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import json"
    },
    {
      "file": "get_versions_sqlfluff.py",
      "line": 56,
      "col": 22,
      "severity": "HIGH",
      "rule_id": "RUFF-E711",
      "message": "Comparison to `None` should be `cond is None`",
      "snippet": "    if pair_rv[0] == None:"
    },
    {
      "file": "get_versions_sqlfluff.py",
      "line": 61,
      "col": 37,
      "severity": "HIGH",
      "rule_id": "RUFF-E711",
      "message": "Comparison to `None` should be `cond is None`",
      "snippet": "    date = pair[1] if pair_rv[1] == None else pair_rv[1]"
    },
    {
      "file": "get_versions_xarray.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import json"
    },
    {
      "file": "get_versions_xarray.py",
      "line": 28,
      "col": 1,
      "severity": "HIGH",
      "rule_id": "RUFF-E731",
      "message": "Do not assign a `lambda` expression, use a `def`",
      "snippet": "keep_major_minor = lambda x, sep: \".\".join(x.strip().split(sep)[:2])"
    },
    {
      "file": "get_versions_xarray.py",
      "line": 40,
      "col": 9,
      "severity": "HIGH",
      "rule_id": "RUFF-E722",
      "message": "Do not use bare `except`",
      "snippet": "        except:"
    },
    {
      "file": "go.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import re"
    },
    {
      "file": "grading.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "from typing import Any"
    },
    {
      "file": "grading.py",
      "line": 88,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (102 > 88)",
      "snippet": "            # This handles cases where pytest output goes to stderr and isn't captured between markers"
    },
    {
      "file": "grading.py",
      "line": 221,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (98 > 88)",
      "snippet": "        - If (fail-to-pass (Resolution) < 1 and > 0) and pass-to-pass (Maintenance) = 1 -> PARTIAL"
    },
    {
      "file": "grading.py",
      "line": 246,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (101 > 88)",
      "snippet": "        test_spec (dict): test spec containing keys \"instance_id\", \"FAIL_TO_PASS\", and \"PASS_TO_PASS\""
    },
    {
      "file": "grading.py",
      "line": 247,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (108 > 88)",
      "snippet": "        prediction (dict): prediction containing keys \"instance_id\", \"model_name_or_path\", and \"model_patch\""
    },
    {
      "file": "grading.py",
      "line": 249,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (102 > 88)",
      "snippet": "        include_tests_status (bool): whether to include the status of each test in the returned report"
    },
    {
      "file": "java.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import re"
    },
    {
      "file": "javascript.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import json"
    },
    {
      "file": "javascript.py",
      "line": 34,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (100 > 88)",
      "snippet": "                    f\"./node_modules/.bin/jest --verbose -c=test/{pkg}/jest.config.js '{test_path}'\""
    },
    {
      "file": "javascript.py",
      "line": 49,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (102 > 88)",
      "snippet": "                    f\"./node_modules/.bin/jest --verbose -c=test/{pkg}/jest.config.json '{test_path}'\""
    },
    {
      "file": "make_lite.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "from criteria import ("
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 21,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "from typing import Optional, Union, Any"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 49,
      "col": 5,
      "severity": "LOW",
      "rule_id": "RUFF-B904",
      "message": "Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling",
      "snippet": "    raise ImportError("
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 112,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (91 > 88)",
      "snippet": "        interleaved: if True, rotate pairs of even and odd dimensions (GPT-J style) instead"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 114,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (90 > 88)",
      "snippet": "        pos_idx_in_fp32: if True, the position indices [0.0, ..., seqlen - 1] are in fp32,"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 116,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (91 > 88)",
      "snippet": "            This option was added because previously (before 2023-07-02), when we construct"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 117,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (93 > 88)",
      "snippet": "            the position indices, we use the dtype of self.inv_freq. In most cases this would"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 118,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (89 > 88)",
      "snippet": "            be fp32, but if the model is trained in pure bf16 (not mixed precision), then"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 120,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (92 > 88)",
      "snippet": "            Because of the limited precision of bf16 (e.g. 1995.0 is rounded to 2000.0), the"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 170,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (97 > 88)",
      "snippet": "            # We want fp32 here, not self.inv_freq.dtype, since the model could be loaded in bf16"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 171,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (97 > 88)",
      "snippet": "            # And the output of arange can be quite large, so bf16 would lose a lot of precision."
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 172,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (100 > 88)",
      "snippet": "            # However, for compatibility reason, we add an option to use the dtype of self.inv_freq."
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 176,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (100 > 88)",
      "snippet": "                # We want fp32 here as well since inv_freq will be multiplied with t, and the output"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 177,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (93 > 88)",
      "snippet": "                # will be large. Having it in bf16 will lose a lot of precision and cause the"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 218,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (95 > 88)",
      "snippet": "        seqlen_offset: can be used in generation where the qkv being passed in is only the last"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 251,
      "col": 20,
      "severity": "LOW",
      "rule_id": "RUFF-B011",
      "message": "Do not `assert False` (`python -O` removes these calls), raise `AssertionError()`",
      "snippet": "            assert False"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 272,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (113 > 88)",
      "snippet": "    This is the equivalent of torch.repeat_interleave(x, dim=1, repeats=n_rep). The hidden states go from (batch,"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 273,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (92 > 88)",
      "snippet": "    num_key_value_heads, seqlen, head_dim) to (batch, num_attention_heads, seqlen, head_dim)"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 300,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (100 > 88)",
      "snippet": "                f\"hidden_size must be divisible by num_heads (got `hidden_size`: {self.hidden_size}\""
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 368,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (94 > 88)",
      "snippet": "        # NOTE: Hack to include position_ids, assuming they are increasing uniformly per block"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 412,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (112 > 88)",
      "snippet": "            # NOTE: we assume that padding tokens are at the end of the sequence and may ignore `attention_mask`"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 425,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (93 > 88)",
      "snippet": "                # varlen, ignore padding tokens, efficient for large batch with many paddings"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 490,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (106 > 88)",
      "snippet": "            hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 492,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (114 > 88)",
      "snippet": "                `(batch, 1, tgt_len, src_len)` where padding elements are indicated by very large negative values."
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 494,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (111 > 88)",
      "snippet": "                Whether or not to return the attentions tensors of all attention layers. See `attentions` under"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 497,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (118 > 88)",
      "snippet": "                If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 499,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (112 > 88)",
      "snippet": "            past_key_value (`Tuple(torch.FloatTensor)`, *optional*): cached past key and value projection states"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 561,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (110 > 88)",
      "snippet": "    Transformer decoder consisting of *config.num_hidden_layers* layers. Each layer is a [`LlamaDecoderLayer`]"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 622,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (102 > 88)",
      "snippet": "                \"You cannot specify both decoder_input_ids and decoder_inputs_embeds at the same time\""
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 644,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (112 > 88)",
      "snippet": "                    \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\""
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 785,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (93 > 88)",
      "snippet": "            labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 786,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (109 > 88)",
      "snippet": "                Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 787,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (118 > 88)",
      "snippet": "                config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 788,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (112 > 88)",
      "snippet": "                (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`."
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 805,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (113 > 88)",
      "snippet": "        >>> tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 806,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (96 > 88)",
      "snippet": "        \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\""
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 852,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (108 > 88)",
      "snippet": "                # Don't take mean since this will give unequal weight to GPUs with unequal amount of padding"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 886,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (92 > 88)",
      "snippet": "        # if `inputs_embeds` are passed, we only want to use them in the 1st generation step"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 950,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (108 > 88)",
      "snippet": "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 951,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (117 > 88)",
      "snippet": "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If"
    },
    {
      "file": "php.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import re"
    },
    {
      "file": "prepare_images.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import docker"
    },
    {
      "file": "prepare_images.py",
      "line": 50,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (99 > 88)",
      "snippet": "        # Check if the instance needs to be built (based on force_rebuild flag and existing images)"
    },
    {
      "file": "print_pulls.py",
      "line": 3,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (137 > 88)",
      "snippet": "\"\"\"Given the `<owner/name>` of a GitHub repo, this script writes the raw information for all the repo's PRs to a single `.jsonl` file.\"\"\""
    },
    {
      "file": "print_pulls.py",
      "line": 5,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "from __future__ import annotations"
    },
    {
      "file": "print_pulls.py",
      "line": 44,
      "col": 13,
      "severity": "LOW",
      "rule_id": "RUFF-B010",
      "message": "Do not call `setattr` with a constant attribute value. It is not any safer than normal property access.",
      "snippet": "            setattr(pull, \"resolved_issues\", repo.extract_resolved_issues(pull))"
    },
    {
      "file": "print_pulls.py",
      "line": 77,
      "col": 5,
      "severity": "LOW",
      "rule_id": "RUFF-B010",
      "message": "Do not call `setattr` with a constant attribute value. It is not any safer than normal property access.",
      "snippet": "    setattr(pull, \"resolved_issues\", repo.extract_resolved_issues(pull))"
    },
    {
      "file": "python.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import os"
    },
    {
      "file": "python.py",
      "line": 22,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (141 > 88)",
      "snippet": "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36\""
    },
    {
      "file": "python.py",
      "line": 40,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (123 > 88)",
      "snippet": "            f\"Could not find environment.yml at paths {MAP_REPO_TO_ENV_YML_PATHS[repo]} for repo {repo} at commit {commit}\""
    },
    {
      "file": "python.py",
      "line": 75,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "RUFF-F841",
      "message": "Local variable `pip_line_start` is assigned to but never used",
      "snippet": "    pip_line_start = pip_match.start()"
    },
    {
      "file": "python.py",
      "line": 79,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (90 > 88)",
      "snippet": "    # find where pip section ends by looking for a line that's at same or less indentation"
    },
    {
      "file": "python.py",
      "line": 90,
      "col": 32,
      "severity": "HIGH",
      "rule_id": "RUFF-E741",
      "message": "Ambiguous variable name: `l`",
      "snippet": "                len(l) + 1 for l in lines_after_pip[:ix]"
    },
    {
      "file": "python.py",
      "line": 99,
      "col": 27,
      "severity": "HIGH",
      "rule_id": "RUFF-E711",
      "message": "Comparison to `None` should be `cond is None`",
      "snippet": "        if replacement == None:"
    },
    {
      "file": "python.py",
      "line": 146,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (121 > 88)",
      "snippet": "            f\"Could not find requirements.txt at paths {MAP_REPO_TO_REQS_PATHS[repo]} for repo {repo} at commit {commit}\""
    },
    {
      "file": "python.py",
      "line": 153,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "RUFF-E731",
      "message": "Do not assign a `lambda` expression, use a `def`",
      "snippet": "    exclude_line = lambda line: any("
    },
    {
      "file": "python.py",
      "line": 188,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (94 > 88)",
      "snippet": "    E.g. types-pkg_resources has been yanked from PyPI, so we replace it with types-setuptools"
    },
    {
      "file": "python.py",
      "line": 191,
      "col": 27,
      "severity": "HIGH",
      "rule_id": "RUFF-E711",
      "message": "Comparison to `None` should be `cond is None`",
      "snippet": "        if replacement == None:"
    },
    {
      "file": "python.py",
      "line": 251,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (107 > 88)",
      "snippet": "    # For Django tests, remove extension + \"tests/\" prefix and convert slashes to dots (module referencing)"
    },
    {
      "file": "python.py",
      "line": 274,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (99 > 88)",
      "snippet": "        f\"git clone -o origin {branch} --single-branch https://github.com/{repo} {repo_directory}\","
    },
    {
      "file": "python.py",
      "line": 282,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (211 > 88)",
      "snippet": "        'git tag -l | while read tag; do TAG_COMMIT=$(git rev-list -n 1 \"$tag\"); TAG_TIME=$(git show -s --format=%ci \"$TAG_COMMIT\"); if [[ \"$TAG_TIME\" > \"$TARGET_TIMESTAMP\" ]]; then git tag -d \"$tag\"; fi; done',"
    },
    {
      "file": "python.py",
      "line": 286,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (91 > 88)",
      "snippet": "        \"AFTER_TIMESTAMP=$(date -d \\\"$TARGET_TIMESTAMP + 1 second\\\" '+%Y-%m-%d %H:%M:%S')\","
    },
    {
      "file": "python.py",
      "line": 326,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (110 > 88)",
      "snippet": "        f\"cat <<'{HEREDOC_DELIMITER}' > /root/environment.yml\\n{cached_environment_yml}\\n{HEREDOC_DELIMITER}\","
    },
    {
      "file": "python.py",
      "line": 385,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (91 > 88)",
      "snippet": "            cmd = f\"conda activate {env_name} && conda install python={specs['python']} -y\""
    },
    {
      "file": "python.py",
      "line": 434,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (89 > 88)",
      "snippet": "        f\"git config --global --add safe.directory {repo_directory}\",  # for nonroot user"
    },
    {
      "file": "python.py",
      "line": 451,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (99 > 88)",
      "snippet": "        reset_tests_command,  # Revert tests after done, leave the repo in the same state as before"
    },
    {
      "file": "remove_containers.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import docker"
    },
    {
      "file": "remove_envs.py",
      "line": 3,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import argparse"
    },
    {
      "file": "remove_envs.py",
      "line": 12,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (91 > 88)",
      "snippet": "    Parse conda environments (`conda env list`) created for a particular conda installation"
    },
    {
      "file": "remove_envs.py",
      "line": 92,
      "col": 29,
      "severity": "LOW",
      "rule_id": "RUFF-B905",
      "message": "`zip()` without an explicit `strict=` parameter",
      "snippet": "        remove_environment, zip(conda_envs_names, [args.prefix] * len(conda_envs_names))"
    },
    {
      "file": "remove_envs.py",
      "line": 97,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (95 > 88)",
      "snippet": "        f\"Removing miniconda folder for environments with {args.prefix} from {args.conda_path}\""
    },
    {
      "file": "reporting.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import docker"
    },
    {
      "file": "run_api.py",
      "line": 3,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (139 > 88)",
      "snippet": "\"\"\"This python script is designed to run inference on a dataset using either the OpenAI or Anthropic API, depending on the model specified."
    },
    {
      "file": "run_api.py",
      "line": 4,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (157 > 88)",
      "snippet": "It sorts instances by length and continually writes the outputs to a specified file, so that the script can be stopped and restarted without losing progress."
    },
    {
      "file": "run_api.py",
      "line": 7,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import json"
    },
    {
      "file": "run_api.py",
      "line": 345,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (90 > 88)",
      "snippet": "            \"Must provide an api key. Expected in ANTHROPIC_API_KEY environment variable.\""
    },
    {
      "file": "run_api.py",
      "line": 411,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (99 > 88)",
      "snippet": "        model_args (str): A string of comma-separated key-value pairs representing model arguments."
    },
    {
      "file": "run_api.py",
      "line": 528,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (90 > 88)",
      "snippet": "        help=\"Name of API model. Update MODEL* constants in this file to add new models.\","
    },
    {
      "file": "run_api.py",
      "line": 554,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (97 > 88)",
      "snippet": "        help=\"List of model arguments separated by commas. (e.g. 'top_p=0.95,temperature=0.70')\","
    },
    {
      "file": "run_evaluation.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "from __future__ import annotations"
    },
    {
      "file": "run_evaluation.py",
      "line": 12,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter"
    },
    {
      "file": "run_evaluation.py",
      "line": 137,
      "col": 13,
      "severity": "HIGH",
      "rule_id": "RUFF-E722",
      "message": "Do not use bare `except`",
      "snippet": "            except:"
    },
    {
      "file": "run_evaluation.py",
      "line": 162,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (105 > 88)",
      "snippet": "            f\"Intermediate patch for {instance_id} written to {patch_file}, now applying to container...\""
    },
    {
      "file": "run_evaluation.py",
      "line": 201,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (92 > 88)",
      "snippet": "            f\"Eval script for {instance_id} written to {eval_file}; copying to container...\""
    },
    {
      "file": "run_evaluation.py",
      "line": 270,
      "col": 9,
      "severity": "LOW",
      "rule_id": "RUFF-B012",
      "message": "`return` inside `finally` blocks cause exceptions to be silenced",
      "snippet": "        return {"
    },
    {
      "file": "run_evaluation.py",
      "line": 498,
      "col": 90,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (94 > 88)",
      "snippet": "            \"⚠️ Local evaluation for the test split of SWE-bench Multimodal is not supported. \""
    },
    {
      "file": "run_evaluation.py",
      "line": 499,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (123 > 88)",
      "snippet": "            \"Please check out sb-cli (https://github.com/swe-bench/sb-cli/) for instructions on how to submit predictions.\""
    },
    {
      "file": "run_evaluation.py",
      "line": 643,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (96 > 88)",
      "snippet": "    # if clean is false, we only remove images above the cache level if they don't already exist"
    },
    {
      "file": "run_evaluation.py",
      "line": 667,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (103 > 88)",
      "snippet": "        help=\"Doesn't run new instances, only writes reports for instances with existing test outputs\","
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 3,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "from __future__ import annotations"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 31,
      "col": 1,
      "severity": "HIGH",
      "rule_id": "RUFF-E402",
      "message": "Module level import not at top of file",
      "snippet": "from swebench.harness.constants import ("
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 31,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "from swebench.harness.constants import ("
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 36,
      "col": 1,
      "severity": "HIGH",
      "rule_id": "RUFF-E402",
      "message": "Module level import not at top of file",
      "snippet": "from swebench.harness.grading import get_eval_report"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 37,
      "col": 1,
      "severity": "HIGH",
      "rule_id": "RUFF-E402",
      "message": "Module level import not at top of file",
      "snippet": "from swebench.harness.test_spec.test_spec import make_test_spec, TestSpec"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 165,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (127 > 88)",
      "snippet": "            \"conda activate testbed && python -m pip install --trusted-host pypi-mirror.modal.local -r $HOME/requirements.txt\","
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 194,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (120 > 88)",
      "snippet": "                \"wget 'https://repo.anaconda.com/miniconda/Miniconda3-py311_23.11.0-2-Linux-x86_64.sh' -O miniconda.sh\","
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 210,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (114 > 88)",
      "snippet": "                \"echo 'source /opt/miniconda3/etc/profile.d/conda.sh && conda activate testbed' >> /root/.bashrc\","
    },
    {
      "file": "run_evaluation_modal_entrypoint.py",
      "line": 3,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (93 > 88)",
      "snippet": "# In a perfect world, we would execute commands using the Sandbox directly, but Modal imposes"
    },
    {
      "file": "run_evaluation_modal_entrypoint.py",
      "line": 4,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (93 > 88)",
      "snippet": "# a container stdio rate limit of 64 KiB/s. Some test harnesses exceed this limit which leads"
    },
    {
      "file": "run_evaluation_modal_entrypoint.py",
      "line": 5,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (90 > 88)",
      "snippet": "# to \"dropped container output\" logs that interfere with parsing the test output. Instead,"
    },
    {
      "file": "run_evaluation_modal_entrypoint.py",
      "line": 6,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (95 > 88)",
      "snippet": "# we mount and run this script in the Sandbox to control the rate at which stdio is streamed to"
    },
    {
      "file": "run_evaluation_modal_entrypoint.py",
      "line": 8,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import asyncio"
    },
    {
      "file": "run_evaluation_modal_entrypoint.py",
      "line": 74,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (120 > 88)",
      "snippet": "                # chance of errors of the form: \"Error reading stream: 'utf-8' codec can't decode bytes in position ...\""
    },
    {
      "file": "run_live.py",
      "line": 10,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import json"
    },
    {
      "file": "run_live.py",
      "line": 107,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "RUFF-F841",
      "message": "Local variable `thread_id` is assigned to but never used",
      "snippet": "    thread_id = 0"
    },
    {
      "file": "run_live.py",
      "line": 151,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (93 > 88)",
      "snippet": "            f\"Including {len(include_files)} files in context with {cur_input_len} tokens:\\n\""
    },
    {
      "file": "run_live.py",
      "line": 198,
      "col": 31,
      "severity": "LOW",
      "rule_id": "RUFF-B905",
      "message": "`zip()` without an explicit `strict=` parameter",
      "snippet": "    for issue, commit in tqdm(zip(issue_url, base_commit), total=len(issue_url)):"
    },
    {
      "file": "run_live.py",
      "line": 228,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (109 > 88)",
      "snippet": "                f\"Generated {response.usage.completion_tokens} tokens in {(time.time() - start):.2f} seconds\""
    },
    {
      "file": "run_llama.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import json"
    },
    {
      "file": "run_llama.py",
      "line": 111,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (105 > 88)",
      "snippet": "        peft_path (str or None): The path to the PEFT adapters. If None, no PEFT adapters will be loaded."
    },
    {
      "file": "run_llama.py",
      "line": 122,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (90 > 88)",
      "snippet": "            k: f\"{torch.cuda.get_device_properties(k).total_memory // 1_010_000_000:d}GIB\""
    },
    {
      "file": "run_llama.py",
      "line": 203,
      "col": 9,
      "severity": "HIGH",
      "rule_id": "RUFF-F841",
      "message": "Local variable `model_nickname` is assigned to but never used",
      "snippet": "        model_nickname = \"__\".join(model_name_or_path.split(\"/\")[-2:])"
    },
    {
      "file": "run_llama.py",
      "line": 217,
      "col": 9,
      "severity": "HIGH",
      "rule_id": "RUFF-E731",
      "message": "Do not assign a `lambda` expression, use a `def`",
      "snippet": "        filter_func = lambda x: x >= min_len"
    },
    {
      "file": "run_llama.py",
      "line": 219,
      "col": 9,
      "severity": "HIGH",
      "rule_id": "RUFF-E731",
      "message": "Do not assign a `lambda` expression, use a `def`",
      "snippet": "        filter_func = lambda x: x < max_len"
    },
    {
      "file": "run_llama.py",
      "line": 221,
      "col": 9,
      "severity": "HIGH",
      "rule_id": "RUFF-E731",
      "message": "Do not assign a `lambda` expression, use a `def`",
      "snippet": "        filter_func = lambda x: min_len <= x < max_len"
    },
    {
      "file": "run_llama.py",
      "line": 237,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (146 > 88)",
      "snippet": "            f\"filtered dataset - {len(dataset)} examples, min length: {min(lens):_}, max length: {max(lens):_} (shard {shard_id} of {num_shards})\""
    },
    {
      "file": "run_llama.py",
      "line": 241,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (111 > 88)",
      "snippet": "            f\"filtered dataset - {len(dataset)} examples, min length: {min(lens):_}, max length: {max(lens):_}\""
    },
    {
      "file": "run_llama.py",
      "line": 262,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (115 > 88)",
      "snippet": "            min_tokens (int): The minimum number of unique tokens required in the suffix of the generated sequence."
    },
    {
      "file": "run_llama.py",
      "line": 316,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (116 > 88)",
      "snippet": "                    f\"Generated {new_len} tokens ({total_len} total) in {(datetime.now() - start).total_seconds()} \""
    },
    {
      "file": "run_llama.py",
      "line": 317,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (98 > 88)",
      "snippet": "                    + f\"seconds (speed: {new_len / (datetime.now() - start).total_seconds()} tps)\""
    },
    {
      "file": "run_llama.py",
      "line": 335,
      "col": 21,
      "severity": "LOW",
      "rule_id": "RUFF-B904",
      "message": "Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling",
      "snippet": "                    raise ValueError(\"too many failures\")"
    },
    {
      "file": "run_llama.py",
      "line": 382,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (132 > 88)",
      "snippet": "                f\"model_name_or_path {model_name_or_path} does not match peft_path base_model {peft_config.base_model_name_or_path}\""
    },
    {
      "file": "test_evaluation.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import collections"
    },
    {
      "file": "test_harness_utils.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import unittest"
    },
    {
      "file": "test_harness_utils.py",
      "line": 18,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (98 > 88)",
      "snippet": "        We want to make sure that our cleaner only modifies the pip section of the environment.yml"
    },
    {
      "file": "test_harness_utils.py",
      "line": 21,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (98 > 88)",
      "snippet": "        We expect \"types-pkg_resources\" to be replaced with \"types-setuptools\" in the pip section."
    },
    {
      "file": "test_harness_utils.py",
      "line": 89,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (90 > 88)",
      "snippet": "        \"\"\"Test environment.yml cleaning with various version specifiers in pip section\"\"\""
    },
    {
      "file": "test_spec.py",
      "line": 1,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import hashlib"
    },
    {
      "file": "test_spec.py",
      "line": 83,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (104 > 88)",
      "snippet": "            ]  # 10 characters is still likely to be unique given only a few base images will be created"
    },
    {
      "file": "test_spec.py",
      "line": 84,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (100 > 88)",
      "snippet": "            return f\"sweb.base.{MAP_REPO_TO_EXT[self.repo]}.{self.arch}.{val}:{self.base_image_tag}\""
    },
    {
      "file": "test_spec.py",
      "line": 92,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (94 > 88)",
      "snippet": "        The key for the environment image is based on the hash of the environment script list."
    },
    {
      "file": "test_spec.py",
      "line": 95,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (108 > 88)",
      "snippet": "        Note that old images are not automatically deleted, so consider cleaning up old images periodically."
    },
    {
      "file": "test_spec.py",
      "line": 104,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (94 > 88)",
      "snippet": "        return f\"sweb.env.{MAP_REPO_TO_EXT[self.repo]}.{self.arch}.{val}:{self.env_image_tag}\""
    },
    {
      "file": "test_spec.py",
      "line": 108,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (91 > 88)",
      "snippet": "        key = f\"sweb.eval.{self.arch}.{self.instance_id.lower()}:{self.instance_image_tag}\""
    },
    {
      "file": "test_spec.py",
      "line": 162,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (103 > 88)",
      "snippet": "    Idempotent function that converts a list of SWEbenchInstance objects to a list of TestSpec objects."
    },
    {
      "file": "test_spec.py",
      "line": 191,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "RUFF-F841",
      "message": "Local variable `problem_statement` is assigned to but never used",
      "snippet": "    problem_statement = instance.get(\"problem_statement\")"
    },
    {
      "file": "test_spec.py",
      "line": 192,
      "col": 5,
      "severity": "HIGH",
      "rule_id": "RUFF-F841",
      "message": "Local variable `hints_text` is assigned to but never used",
      "snippet": "    hints_text = instance.get(\"hints_text\")  # Unused"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 3,
      "col": 89,
      "severity": "HIGH",
      "rule_id": "RUFF-E501",
      "message": "Line too long (180 > 88)",
      "snippet": "\"\"\"Provided a source (raw) directory and the final (eval) directory, create a training split by removing all instances that are in the final directory from the source directory.\"\"\""
    },
    {
      "file": "tokenize_dataset.py",
      "line": 5,
      "col": 1,
      "severity": "LOW",
      "rule_id": "RUFF-I001",
      "message": "Import block is un-sorted or un-formatted",
      "snippet": "import os"
    },
    {
      "file": "default.py",
      "line": 8,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'jinja2'",
      "snippet": "from jinja2 import Template"
    },
    {
      "file": "default.py",
      "line": 10,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'minisweagent'",
      "snippet": "from minisweagent import Environment, Model"
    },
    {
      "file": "default.py",
      "line": 117,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-raise-missing-from",
      "message": "Consider explicitly re-raising using 'raise ExecutionTimeoutError(self.render_template(self.config.timeout_template, action=action, output=output)) from e'",
      "snippet": "            raise ExecutionTimeoutError("
    },
    {
      "file": "default.py",
      "line": 121,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-raise-missing-from",
      "message": "Consider explicitly re-raising using 'except TimeoutError as exc' and 'raise ExecutionTimeoutError(self.render_template(self.config.timeout_template, action=action, output='')) from exc'",
      "snippet": "            raise ExecutionTimeoutError(self.render_template(self.config.timeout_template, action=action, output=\"\"))"
    },
    {
      "file": "build_dataset.py",
      "line": 9,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.collect.utils'",
      "snippet": "from swebench.collect.utils import ("
    },
    {
      "file": "build_dataset.py",
      "line": 124,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(all_output) as f:"
    },
    {
      "file": "build_dataset.py",
      "line": 137,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info("
    },
    {
      "file": "build_dataset.py",
      "line": 143,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(all_output, write_mode_all) as all_output:"
    },
    {
      "file": "build_dataset.py",
      "line": 146,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(output, write_mode) as output:"
    },
    {
      "file": "build_dataset.py",
      "line": 147,
      "col": 38,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "            for ix, line in enumerate(open(pr_file)):"
    },
    {
      "file": "build_dataset.py",
      "line": 151,
      "col": 20,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "                    logger.info("
    },
    {
      "file": "build_dataset.py",
      "line": 182,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info("
    },
    {
      "file": "build_dataset.py",
      "line": 185,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info("
    },
    {
      "file": "build_dataset_ft.py",
      "line": 34,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(x) as f:"
    },
    {
      "file": "build_dataset_ft.py",
      "line": 39,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(destination, \"w\") as f_out:"
    },
    {
      "file": "build_dataset_ft.py",
      "line": 44,
      "col": 17,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "            with open(dataset_path) as f:"
    },
    {
      "file": "get_tasks_pipeline.py",
      "line": 9,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'dotenv'",
      "snippet": "from dotenv import load_dotenv"
    },
    {
      "file": "get_tasks_pipeline.py",
      "line": 11,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.collect.build_dataset'",
      "snippet": "from swebench.collect.build_dataset import main as build_dataset"
    },
    {
      "file": "get_tasks_pipeline.py",
      "line": 12,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.collect.print_pulls'",
      "snippet": "from swebench.collect.print_pulls import main as print_pulls"
    },
    {
      "file": "get_tasks_pipeline.py",
      "line": 89,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "        except Exception as e:"
    },
    {
      "file": "get_tasks_pipeline.py",
      "line": 120,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-raised",
      "message": "Raising too general exception: Exception",
      "snippet": "        raise Exception("
    },
    {
      "file": "get_top_pypi.py",
      "line": 7,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'bs4'",
      "snippet": "from bs4 import BeautifulSoup"
    },
    {
      "file": "get_top_pypi.py",
      "line": 8,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'ghapi.core'",
      "snippet": "from ghapi.core import GhApi"
    },
    {
      "file": "get_top_pypi.py",
      "line": 9,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'selenium'",
      "snippet": "from selenium import webdriver"
    },
    {
      "file": "get_top_pypi.py",
      "line": 10,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'selenium.webdriver.common.by'",
      "snippet": "from selenium.webdriver.common.by import By"
    },
    {
      "file": "get_top_pypi.py",
      "line": 49,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-redefined-outer-name",
      "message": "Redefining name 'soup' from outer scope (line 109)",
      "snippet": "            soup = BeautifulSoup(driver.page_source, \"html.parser\")"
    },
    {
      "file": "get_top_pypi.py",
      "line": 32,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(f) as fp_:"
    },
    {
      "file": "get_top_pypi.py",
      "line": 38,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(f, access_type) as fp_:"
    },
    {
      "file": "get_top_pypi.py",
      "line": 48,
      "col": 12,
      "severity": "HIGH",
      "rule_id": "PL-possibly-used-before-assignment",
      "message": "Possibly using variable 'driver' before assignment",
      "snippet": "            driver.get(package_url)"
    },
    {
      "file": "get_top_pypi.py",
      "line": 74,
      "col": 16,
      "severity": "MEDIUM",
      "rule_id": "PL-bare-except",
      "message": "No exception type(s) specified",
      "snippet": "                except:"
    },
    {
      "file": "print_pulls.py",
      "line": 13,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'fastcore.xtras'",
      "snippet": "from fastcore.xtras import obj2dict"
    },
    {
      "file": "print_pulls.py",
      "line": 14,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.collect.utils'",
      "snippet": "from swebench.collect.utils import Repo"
    },
    {
      "file": "print_pulls.py",
      "line": 42,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(output, \"w\") as file:"
    },
    {
      "file": "print_pulls.py",
      "line": 65,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Fetching PR #{pull_number} from {repo.owner}/{repo.name}\")"
    },
    {
      "file": "print_pulls.py",
      "line": 73,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.error(f\"PR #{pull_number} not found in {repo.owner}/{repo.name}\")"
    },
    {
      "file": "print_pulls.py",
      "line": 80,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(output, \"w\") as file:"
    },
    {
      "file": "print_pulls.py",
      "line": 83,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"PR #{pull_number} saved to {output}\")"
    },
    {
      "file": "print_pulls.py",
      "line": 84,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Resolved issues: {pull.resolved_issues}\")"
    },
    {
      "file": "utils.py",
      "line": 15,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(instance_path) as f:"
    },
    {
      "file": "utils.py",
      "line": 20,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(instance_path) as f:"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 16,
      "col": 23,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "    branches_command = subprocess.run("
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 21,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "    subprocess.run("
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 33,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "        subprocess.run([\"git\", \"checkout\", branch])"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 39,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "            subprocess.run([\"rm\", \"-rf\", workflows_path])"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 40,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "            subprocess.run([\"git\", \"add\", \"-A\"])"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 41,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "            subprocess.run([\"git\", \"commit\", \"-m\", \"Remove .github/workflows folder\"])"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 42,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "            subprocess.run([\"git\", \"push\"])"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 47,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "    subprocess.run([\"rm\", \"-rf\", \"temp_repo\"])"
    },
    {
      "file": "remove_envs.py",
      "line": 40,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "    subprocess.run(command.split(\" \"))"
    },
    {
      "file": "remove_envs.py",
      "line": 50,
      "col": 14,
      "severity": "HIGH",
      "rule_id": "PL-possibly-used-before-assignment",
      "message": "Possibly using variable 'conda_source' before assignment",
      "snippet": "        cmd = conda_source + \" && \" + conda_cmd"
    },
    {
      "file": "remove_envs.py",
      "line": 63,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-pointless-string-statement",
      "message": "String statement has no effect",
      "snippet": "    \"\"\""
    },
    {
      "file": "criteria.py",
      "line": 4,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.collect.utils'",
      "snippet": "from swebench.collect.utils import PR_KEYWORDS"
    },
    {
      "file": "criteria.py",
      "line": 5,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'unidiff'",
      "snippet": "from unidiff import PatchSet"
    },
    {
      "file": "criteria.py",
      "line": 30,
      "col": 23,
      "severity": "MEDIUM",
      "rule_id": "PL-duplicate-string-formatting-argument",
      "message": "Duplicate string formatting argument 'pattern_repo', consider passing as named argument",
      "snippet": "        pattern_urls = r\"(?:https?://(?!{}).+)|(?:www\\.(?!{}).+)\".format("
    },
    {
      "file": "criteria.py",
      "line": 101,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "PL-missing-timeout",
      "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
      "snippet": "        if requests.get(url).status_code == 200:"
    },
    {
      "file": "make_lite.py",
      "line": 1,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'criteria'",
      "snippet": "from criteria import ("
    },
    {
      "file": "make_lite.py",
      "line": 12,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'datasets'",
      "snippet": "from datasets import load_dataset, disable_caching, DatasetDict"
    },
    {
      "file": "make_lite.py",
      "line": 49,
      "col": 18,
      "severity": "MEDIUM",
      "rule_id": "PL-redefined-outer-name",
      "message": "Redefining name 'dset' from outer scope (line 85)",
      "snippet": "def apply_filters(dset, filters, name=\"\"):"
    },
    {
      "file": "make_lite.py",
      "line": 61,
      "col": 16,
      "severity": "MEDIUM",
      "rule_id": "PL-redefined-outer-name",
      "message": "Redefining name 'dset' from outer scope (line 85)",
      "snippet": "def take_subset(dset, n, name=\"\"):"
    },
    {
      "file": "call_make_repo.py",
      "line": 9,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "    out_make = subprocess.run("
    },
    {
      "file": "docker_build.py",
      "line": 3,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'docker'",
      "snippet": "import docker"
    },
    {
      "file": "docker_build.py",
      "line": 4,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'docker.errors'",
      "snippet": "import docker.errors"
    },
    {
      "file": "docker_build.py",
      "line": 11,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.constants'",
      "snippet": "from swebench.harness.constants import ("
    },
    {
      "file": "docker_build.py",
      "line": 18,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.docker_utils'",
      "snippet": "from swebench.harness.docker_utils import cleanup_container, remove_image"
    },
    {
      "file": "docker_build.py",
      "line": 19,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
      "snippet": "from swebench.harness.test_spec.test_spec import ("
    },
    {
      "file": "docker_build.py",
      "line": 24,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.utils'",
      "snippet": "from swebench.harness.utils import ansi_escape, run_threadpool"
    },
    {
      "file": "docker_build.py",
      "line": 99,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info("
    },
    {
      "file": "docker_build.py",
      "line": 106,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.info(f\"[SETUP SCRIPT] {setup_script_name}:\\n{setup_script}\")"
    },
    {
      "file": "docker_build.py",
      "line": 111,
      "col": 17,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "            with open(setup_script_path, \"w\") as f:"
    },
    {
      "file": "docker_build.py",
      "line": 114,
      "col": 16,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "                logger.warning("
    },
    {
      "file": "docker_build.py",
      "line": 120,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(dockerfile_path, \"w\") as f:"
    },
    {
      "file": "docker_build.py",
      "line": 124,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.info("
    },
    {
      "file": "docker_build.py",
      "line": 147,
      "col": 16,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "                logger.error(f\"Error: {ansi_escape(chunk['errorDetail']['message'])}\")"
    },
    {
      "file": "docker_build.py",
      "line": 153,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.error(f\"docker.errors.BuildError during {image_name}: {e}\")"
    },
    {
      "file": "docker_build.py",
      "line": 156,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.error(f\"Error building image {image_name}: {e}\")"
    },
    {
      "file": "docker_build.py",
      "line": 248,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-raise-missing-from",
      "message": "Consider explicitly re-raising using 'except Exception as exc' and 'raise Exception(f'Base image {test_spec.base_image_key} not found for {test_spec.env_image_key}\\n.Please build the base images first.') from exc'",
      "snippet": "            raise Exception("
    },
    {
      "file": "docker_build.py",
      "line": 248,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-raised",
      "message": "Raising too general exception: Exception",
      "snippet": "            raise Exception("
    },
    {
      "file": "docker_build.py",
      "line": 246,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-variable",
      "message": "Unused variable 'base_image'",
      "snippet": "            base_image = base_images[test_spec.base_image_key]"
    },
    {
      "file": "docker_build.py",
      "line": 256,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-variable",
      "message": "Unused variable 'env_image'",
      "snippet": "            env_image = client.images.get(test_spec.env_image_key)"
    },
    {
      "file": "docker_build.py",
      "line": 437,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info("
    },
    {
      "file": "docker_build.py",
      "line": 464,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.info(f\"Image {image_name} already exists, skipping build.\")"
    },
    {
      "file": "docker_build.py",
      "line": 430,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-variable",
      "message": "Unused variable 'env_image'",
      "snippet": "        env_image = client.images.get(env_image_name)"
    },
    {
      "file": "docker_build.py",
      "line": 503,
      "col": 16,
      "severity": "MEDIUM",
      "rule_id": "PL-raise-missing-from",
      "message": "Consider explicitly re-raising using 'raise Exception(f'Error occurred while pulling image {test_spec.base_image_key}: {str(e)}') from e'",
      "snippet": "                raise Exception("
    },
    {
      "file": "docker_build.py",
      "line": 503,
      "col": 16,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-raised",
      "message": "Raising too general exception: Exception",
      "snippet": "                raise Exception("
    },
    {
      "file": "docker_utils.py",
      "line": 3,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'docker'",
      "snippet": "import docker"
    },
    {
      "file": "docker_utils.py",
      "line": 4,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'docker.errors'",
      "snippet": "import docker.errors"
    },
    {
      "file": "docker_utils.py",
      "line": 13,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'docker.models.containers'",
      "snippet": "from docker.models.containers import Container"
    },
    {
      "file": "docker_utils.py",
      "line": 94,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "docker_utils.py",
      "line": 136,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "docker_utils.py",
      "line": 153,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "        except Exception as e2:"
    },
    {
      "file": "docker_utils.py",
      "line": 150,
      "col": 29,
      "severity": "HIGH",
      "rule_id": "PL-no-member",
      "message": "Module 'signal' has no 'SIGKILL' member; maybe 'SIGILL'?",
      "snippet": "                os.kill(pid, signal.SIGKILL)"
    },
    {
      "file": "docker_utils.py",
      "line": 166,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "docker_utils.py",
      "line": 198,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "        except Exception as e:"
    },
    {
      "file": "docker_utils.py",
      "line": 289,
      "col": 19,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "            except Exception as e:"
    },
    {
      "file": "grading.py",
      "line": 60,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-fixme",
      "message": "TODO fix constant here",
      "snippet": "        # TODO fix constant here"
    },
    {
      "file": "grading.py",
      "line": 210,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-fixme",
      "message": "TODO: Don't factor in p2p metrics",
      "snippet": "        # TODO: Don't factor in p2p metrics"
    },
    {
      "file": "grading.py",
      "line": 3,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.constants'",
      "snippet": "from swebench.harness.constants import ("
    },
    {
      "file": "grading.py",
      "line": 22,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
      "snippet": "from swebench.harness.test_spec.test_spec import TestSpec"
    },
    {
      "file": "grading.py",
      "line": 23,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.log_parsers'",
      "snippet": "from swebench.harness.log_parsers import MAP_REPO_TO_PARSER"
    },
    {
      "file": "grading.py",
      "line": 58,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(log_fp) as f:"
    },
    {
      "file": "prepare_images.py",
      "line": 1,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'docker'",
      "snippet": "import docker"
    },
    {
      "file": "prepare_images.py",
      "line": 2,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'resource'",
      "snippet": "import resource"
    },
    {
      "file": "prepare_images.py",
      "line": 6,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.constants'",
      "snippet": "from swebench.harness.constants import KEY_INSTANCE_ID"
    },
    {
      "file": "prepare_images.py",
      "line": 7,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.docker_build'",
      "snippet": "from swebench.harness.docker_build import build_instance_images"
    },
    {
      "file": "prepare_images.py",
      "line": 8,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.docker_utils'",
      "snippet": "from swebench.harness.docker_utils import list_images"
    },
    {
      "file": "prepare_images.py",
      "line": 9,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
      "snippet": "from swebench.harness.test_spec.test_spec import make_test_spec"
    },
    {
      "file": "prepare_images.py",
      "line": 10,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.utils'",
      "snippet": "from swebench.harness.utils import load_swebench_dataset, str2bool, optional_str"
    },
    {
      "file": "remove_containers.py",
      "line": 1,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'docker'",
      "snippet": "import docker"
    },
    {
      "file": "remove_containers.py",
      "line": 6,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "PL-pointless-string-statement",
      "message": "String statement has no effect",
      "snippet": "\"\"\""
    },
    {
      "file": "remove_containers.py",
      "line": 11,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-redefined-outer-name",
      "message": "Redefining name 'instance_ids' from outer scope (line 51)",
      "snippet": "def main(instance_ids, predictions_path):"
    },
    {
      "file": "remove_containers.py",
      "line": 14,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(predictions_path, \"r\") as f:"
    },
    {
      "file": "remove_containers.py",
      "line": 35,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "        except Exception as e:"
    },
    {
      "file": "reporting.py",
      "line": 1,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'docker'",
      "snippet": "import docker"
    },
    {
      "file": "reporting.py",
      "line": 6,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.constants'",
      "snippet": "from swebench.harness.constants import ("
    },
    {
      "file": "reporting.py",
      "line": 13,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.docker_utils'",
      "snippet": "from swebench.harness.docker_utils import list_images"
    },
    {
      "file": "reporting.py",
      "line": 14,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
      "snippet": "from swebench.harness.test_spec.test_spec import make_test_spec"
    },
    {
      "file": "reporting.py",
      "line": 157,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(report_file, \"w\") as f:"
    },
    {
      "file": "run_evaluation.py",
      "line": 3,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'docker'",
      "snippet": "import docker"
    },
    {
      "file": "run_evaluation.py",
      "line": 10,
      "col": 4,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'resource'",
      "snippet": "    import resource"
    },
    {
      "file": "run_evaluation.py",
      "line": 16,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.constants'",
      "snippet": "from swebench.harness.constants import ("
    },
    {
      "file": "run_evaluation.py",
      "line": 32,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.docker_utils'",
      "snippet": "from swebench.harness.docker_utils import ("
    },
    {
      "file": "run_evaluation.py",
      "line": 41,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.docker_build'",
      "snippet": "from swebench.harness.docker_build import ("
    },
    {
      "file": "run_evaluation.py",
      "line": 48,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.grading'",
      "snippet": "from swebench.harness.grading import get_eval_report"
    },
    {
      "file": "run_evaluation.py",
      "line": 49,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.reporting'",
      "snippet": "from swebench.harness.reporting import make_run_report"
    },
    {
      "file": "run_evaluation.py",
      "line": 50,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.modal_eval'",
      "snippet": "from swebench.harness.modal_eval import ("
    },
    {
      "file": "run_evaluation.py",
      "line": 54,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
      "snippet": "from swebench.harness.test_spec.test_spec import make_test_spec, TestSpec"
    },
    {
      "file": "run_evaluation.py",
      "line": 55,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.utils'",
      "snippet": "from swebench.harness.utils import ("
    },
    {
      "file": "run_evaluation.py",
      "line": 112,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(report_path, \"w\") as f:"
    },
    {
      "file": "run_evaluation.py",
      "line": 137,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-bare-except",
      "message": "No exception type(s) specified",
      "snippet": "            except:"
    },
    {
      "file": "run_evaluation.py",
      "line": 270,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-return-in-finally",
      "message": "'return' shadowed by the 'finally' clause.",
      "snippet": "        return {"
    },
    {
      "file": "run_evaluation.py",
      "line": 257,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "run_evaluation.py",
      "line": 160,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        patch_file.write_text(pred[KEY_PREDICTION] or \"\")"
    },
    {
      "file": "run_evaluation.py",
      "line": 199,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        eval_file.write_text(test_spec.eval_script)"
    },
    {
      "file": "run_evaluation.py",
      "line": 211,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(test_output_path, \"w\") as f:"
    },
    {
      "file": "run_evaluation.py",
      "line": 250,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(report_path, \"w\") as f:"
    },
    {
      "file": "run_evaluation.py",
      "line": 270,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-lost-exception",
      "message": "return statement in finally block may swallow exception",
      "snippet": "        return {"
    },
    {
      "file": "run_evaluation.py",
      "line": 356,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "PL-redefined-outer-name",
      "message": "Redefining name 'args' from outer scope (line 676)",
      "snippet": "    def run_evaluation_with_progress(*args):"
    },
    {
      "file": "c.py",
      "line": 4,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.constants'",
      "snippet": "from swebench.harness.constants import TestStatus"
    },
    {
      "file": "c.py",
      "line": 5,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
      "snippet": "from swebench.harness.test_spec.test_spec import TestSpec"
    },
    {
      "file": "c.py",
      "line": 8,
      "col": 30,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'test_spec'",
      "snippet": "def parse_log_redis(log: str, test_spec: TestSpec) -> dict[str, str]:"
    },
    {
      "file": "c.py",
      "line": 35,
      "col": 27,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'test_spec'",
      "snippet": "def parse_log_jq(log: str, test_spec: TestSpec) -> dict[str, str]:"
    },
    {
      "file": "c.py",
      "line": 57,
      "col": 32,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'test_spec'",
      "snippet": "def parse_log_doctest(log: str, test_spec: TestSpec) -> dict[str, str]:"
    },
    {
      "file": "c.py",
      "line": 94,
      "col": 41,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'test_spec'",
      "snippet": "def parse_log_micropython_test(log: str, test_spec: TestSpec) -> dict[str, str]:"
    },
    {
      "file": "c.py",
      "line": 113,
      "col": 35,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'test_spec'",
      "snippet": "def parse_log_googletest(log: str, test_spec: TestSpec) -> dict[str, str]:"
    },
    {
      "file": "go.py",
      "line": 2,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.constants'",
      "snippet": "from swebench.harness.constants import TestStatus"
    },
    {
      "file": "go.py",
      "line": 3,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
      "snippet": "from swebench.harness.test_spec.test_spec import TestSpec"
    },
    {
      "file": "go.py",
      "line": 6,
      "col": 31,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'test_spec'",
      "snippet": "def parse_log_gotest(log: str, test_spec: TestSpec) -> dict[str, str]:"
    },
    {
      "file": "java.py",
      "line": 2,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.constants'",
      "snippet": "from swebench.harness.constants import TestStatus"
    },
    {
      "file": "java.py",
      "line": 3,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
      "snippet": "from swebench.harness.test_spec.test_spec import TestSpec"
    },
    {
      "file": "java.py",
      "line": 6,
      "col": 30,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'test_spec'",
      "snippet": "def parse_log_maven(log: str, test_spec: TestSpec) -> dict[str, str]:"
    },
    {
      "file": "java.py",
      "line": 42,
      "col": 28,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'test_spec'",
      "snippet": "def parse_log_ant(log: str, test_spec: TestSpec) -> dict[str, str]:"
    },
    {
      "file": "java.py",
      "line": 59,
      "col": 38,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'test_spec'",
      "snippet": "def parse_log_gradle_custom(log: str, test_spec: TestSpec) -> dict[str, str]:"
    },
    {
      "file": "javascript.py",
      "line": 5,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.constants'",
      "snippet": "from swebench.harness.constants import ("
    },
    {
      "file": "javascript.py",
      "line": 9,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.utils'",
      "snippet": "from swebench.harness.test_spec.utils import make_eval_script_list_common"
    },
    {
      "file": "javascript.py",
      "line": 10,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'unidiff'",
      "snippet": "from unidiff import PatchSet"
    },
    {
      "file": "php.py",
      "line": 2,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.constants'",
      "snippet": "from swebench.harness.constants import TestStatus"
    },
    {
      "file": "php.py",
      "line": 3,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
      "snippet": "from swebench.harness.test_spec.test_spec import TestSpec"
    },
    {
      "file": "php.py",
      "line": 6,
      "col": 32,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'test_spec'",
      "snippet": "def parse_log_phpunit(log: str, test_spec: TestSpec) -> dict[str, str]:"
    },
    {
      "file": "python.py",
      "line": 6,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.constants'",
      "snippet": "from swebench.harness.constants import ("
    },
    {
      "file": "python.py",
      "line": 18,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.utils'",
      "snippet": "from swebench.harness.utils import get_modified_files, load_cached_environment_yml"
    },
    {
      "file": "python.py",
      "line": 35,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "PL-missing-timeout",
      "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
      "snippet": "        reqs = requests.get(reqs_url, headers=HEADERS)"
    },
    {
      "file": "python.py",
      "line": 75,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-variable",
      "message": "Unused variable 'pip_line_start'",
      "snippet": "    pip_line_start = pip_match.start()"
    },
    {
      "file": "python.py",
      "line": 141,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "PL-missing-timeout",
      "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
      "snippet": "        reqs = requests.get(reqs_url, headers=HEADERS)"
    },
    {
      "file": "python.py",
      "line": 168,
      "col": 19,
      "severity": "MEDIUM",
      "rule_id": "PL-missing-timeout",
      "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
      "snippet": "            reqs = requests.get(reqs_url, headers=HEADERS)"
    },
    {
      "file": "python.py",
      "line": 321,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'instance'",
      "snippet": "    instance, specs, env_name, cached_environment_yml"
    },
    {
      "file": "python.py",
      "line": 321,
      "col": 14,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'specs'",
      "snippet": "    instance, specs, env_name, cached_environment_yml"
    },
    {
      "file": "ruby.py",
      "line": 3,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.constants'",
      "snippet": "from swebench.harness.constants import TestStatus"
    },
    {
      "file": "ruby.py",
      "line": 4,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
      "snippet": "from swebench.harness.test_spec.test_spec import TestSpec"
    },
    {
      "file": "ruby.py",
      "line": 7,
      "col": 33,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'test_spec'",
      "snippet": "def parse_log_minitest(log: str, test_spec: TestSpec) -> dict[str, str]:"
    },
    {
      "file": "ruby.py",
      "line": 30,
      "col": 33,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'test_spec'",
      "snippet": "def parse_log_cucumber(log: str, test_spec: TestSpec) -> dict[str, str]:"
    },
    {
      "file": "ruby.py",
      "line": 50,
      "col": 34,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'test_spec'",
      "snippet": "def parse_log_ruby_unit(log: str, test_spec: TestSpec) -> dict[str, str]:"
    },
    {
      "file": "ruby.py",
      "line": 69,
      "col": 47,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'test_spec'",
      "snippet": "def parse_log_rspec_transformed_json(log: str, test_spec: TestSpec) -> dict[str, str]:"
    },
    {
      "file": "rust.py",
      "line": 3,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.constants'",
      "snippet": "from swebench.harness.constants import TestStatus"
    },
    {
      "file": "rust.py",
      "line": 4,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
      "snippet": "from swebench.harness.test_spec.test_spec import TestSpec"
    },
    {
      "file": "rust.py",
      "line": 7,
      "col": 30,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'test_spec'",
      "snippet": "def parse_log_cargo(log: str, test_spec: TestSpec) -> dict[str, str]:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 7,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'modal'",
      "snippet": "import modal"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 8,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'modal.container_process'",
      "snippet": "import modal.container_process"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 9,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'modal.io_streams'",
      "snippet": "import modal.io_streams"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 10,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'tenacity'",
      "snippet": "import tenacity"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 16,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.docker_build'",
      "snippet": "from swebench.harness.docker_build import setup_logger"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 17,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.reporting'",
      "snippet": "from swebench.harness.reporting import make_run_report"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 18,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.utils'",
      "snippet": "from swebench.harness.utils import EvaluationError"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 31,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.constants'",
      "snippet": "from swebench.harness.constants import ("
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 36,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.grading'",
      "snippet": "from swebench.harness.grading import get_eval_report"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 37,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
      "snippet": "from swebench.harness.test_spec.test_spec import make_test_spec, TestSpec"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 98,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "        except Exception as e:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 134,
      "col": 15,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "        except Exception as e:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 154,
      "col": 19,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "            except Exception:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 150,
      "col": 31,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "                        except Exception:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 172,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        Path(remote_env_script_path).write_text(env_script)"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 173,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        Path(remote_repo_script_path).write_text(repo_script)"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 376,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 323,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(test_output_path, \"w\") as f:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 448,
      "col": 25,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "                    with open(log_dir / \"run_instance.log\", \"w\") as f:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 450,
      "col": 25,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "                    with open(log_dir / \"test_output.txt\", \"w\") as f:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 452,
      "col": 25,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "                    with open(log_dir / \"patch.diff\", \"w\") as f:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 454,
      "col": 25,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "                    with open(log_dir / \"report.json\", \"w\") as f:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 458,
      "col": 31,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "                        except Exception:"
    },
    {
      "file": "run_evaluation_modal_entrypoint.py",
      "line": 16,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "PL-redefined-builtin",
      "message": "Redefining built-in 'exec'",
      "snippet": "async def exec(command: str) -> int:"
    },
    {
      "file": "create_scripts.py",
      "line": 1,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.constants'",
      "snippet": "from swebench.harness.constants import MAP_REPO_TO_EXT"
    },
    {
      "file": "create_scripts.py",
      "line": 2,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.javascript'",
      "snippet": "from swebench.harness.test_spec.javascript import ("
    },
    {
      "file": "create_scripts.py",
      "line": 5,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.python'",
      "snippet": "from swebench.harness.test_spec.python import ("
    },
    {
      "file": "create_scripts.py",
      "line": 10,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.utils'",
      "snippet": "from swebench.harness.test_spec.utils import ("
    },
    {
      "file": "test_spec.py",
      "line": 7,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.constants'",
      "snippet": "from swebench.harness.constants import ("
    },
    {
      "file": "test_spec.py",
      "line": 15,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.dockerfiles'",
      "snippet": "from swebench.harness.dockerfiles import ("
    },
    {
      "file": "test_spec.py",
      "line": 20,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.create_scripts'",
      "snippet": "from swebench.harness.test_spec.create_scripts import ("
    },
    {
      "file": "test_spec.py",
      "line": 191,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-variable",
      "message": "Unused variable 'problem_statement'",
      "snippet": "    problem_statement = instance.get(\"problem_statement\")"
    },
    {
      "file": "test_spec.py",
      "line": 192,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-variable",
      "message": "Unused variable 'hints_text'",
      "snippet": "    hints_text = instance.get(\"hints_text\")  # Unused"
    },
    {
      "file": "run_api.py",
      "line": 10,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'dotenv'",
      "snippet": "import dotenv"
    },
    {
      "file": "run_api.py",
      "line": 15,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'tiktoken'",
      "snippet": "import tiktoken"
    },
    {
      "file": "run_api.py",
      "line": 17,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'anthropic'",
      "snippet": "from anthropic import HUMAN_PROMPT, AI_PROMPT, Anthropic"
    },
    {
      "file": "run_api.py",
      "line": 18,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'tenacity'",
      "snippet": "from tenacity import ("
    },
    {
      "file": "run_api.py",
      "line": 23,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'datasets'",
      "snippet": "from datasets import load_dataset, load_from_disk"
    },
    {
      "file": "run_api.py",
      "line": 24,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.inference.make_datasets.utils'",
      "snippet": "from swebench.inference.make_datasets.utils import extract_diff"
    },
    {
      "file": "run_api.py",
      "line": 107,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info("
    },
    {
      "file": "run_api.py",
      "line": 219,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(output_file, \"a+\") as f:"
    },
    {
      "file": "run_api.py",
      "line": 274,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "run_api.py",
      "line": 276,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.error(f\"Inputs: {inputs}\")"
    },
    {
      "file": "run_api.py",
      "line": 315,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "run_api.py",
      "line": 317,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.error(f\"Inputs: {inputs}\")"
    },
    {
      "file": "run_api.py",
      "line": 284,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'model_args'",
      "snippet": "    inputs, anthropic, model_name_or_path, temperature, top_p, **model_args"
    },
    {
      "file": "run_api.py",
      "line": 367,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(output_file, \"a+\") as f:"
    },
    {
      "file": "run_api.py",
      "line": 389,
      "col": 19,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "            except Exception as e:"
    },
    {
      "file": "run_api.py",
      "line": 453,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.warning("
    },
    {
      "file": "run_api.py",
      "line": 457,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.warning(f\"Received shard_id={shard_id} but num_shards is None, ignoring\")"
    },
    {
      "file": "run_api.py",
      "line": 468,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Will write to {output_file}\")"
    },
    {
      "file": "run_api.py",
      "line": 471,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(output_file) as f:"
    },
    {
      "file": "run_api.py",
      "line": 476,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Read {len(existing_ids)} already completed ids from {output_file}\")"
    },
    {
      "file": "run_live.py",
      "line": 13,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'ghapi.all'",
      "snippet": "from ghapi.all import GhApi"
    },
    {
      "file": "run_live.py",
      "line": 19,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.inference.make_datasets.utils'",
      "snippet": "from swebench.inference.make_datasets.utils import ("
    },
    {
      "file": "run_live.py",
      "line": 25,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.inference.make_datasets.create_instance'",
      "snippet": "from swebench.inference.make_datasets.create_instance import ("
    },
    {
      "file": "run_live.py",
      "line": 31,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.inference.make_datasets.bm25_retrieval'",
      "snippet": "from swebench.inference.make_datasets.bm25_retrieval import ("
    },
    {
      "file": "run_live.py",
      "line": 37,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.inference.run_api'",
      "snippet": "from swebench.inference.run_api import call_chat, call_anthropic"
    },
    {
      "file": "run_live.py",
      "line": 109,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Cloning repo {owner}/{repo}\")"
    },
    {
      "file": "run_live.py",
      "line": 117,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Building BM25 retrieval index for {owner}/{repo}@{commit}\")"
    },
    {
      "file": "run_live.py",
      "line": 129,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Retrieved {len(hits)} documents\")"
    },
    {
      "file": "run_live.py",
      "line": 137,
      "col": 35,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "            hit[\"file_contents\"] = open(hit[\"docid\"]).read()"
    },
    {
      "file": "run_live.py",
      "line": 150,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-not-lazy",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.info("
    },
    {
      "file": "run_live.py",
      "line": 107,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-variable",
      "message": "Unused variable 'thread_id'",
      "snippet": "    thread_id = 0"
    },
    {
      "file": "run_live.py",
      "line": 192,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.warning(f\"Using GitHub token: {'*' * 8}{gh_token[-4:]}\")"
    },
    {
      "file": "run_live.py",
      "line": 202,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.info(f\"Creating instance {instance_id}\")"
    },
    {
      "file": "run_live.py",
      "line": 219,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.info(f\"Calling model {model_name}\")"
    },
    {
      "file": "run_live.py",
      "line": 227,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "            logger.info("
    },
    {
      "file": "run_live.py",
      "line": 231,
      "col": 12,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'anthropic'",
      "snippet": "            from anthropic import Anthropic"
    },
    {
      "file": "run_live.py",
      "line": 256,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(output_file, \"+a\") as f:"
    },
    {
      "file": "run_live.py",
      "line": 259,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Wrote output to {output_file}\")"
    },
    {
      "file": "run_llama.py",
      "line": 8,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'torch'",
      "snippet": "import torch"
    },
    {
      "file": "run_llama.py",
      "line": 9,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'datasets'",
      "snippet": "from datasets import load_from_disk, load_dataset"
    },
    {
      "file": "run_llama.py",
      "line": 10,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'peft'",
      "snippet": "from peft import PeftConfig, PeftModel"
    },
    {
      "file": "run_llama.py",
      "line": 12,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'transformers'",
      "snippet": "from transformers import ("
    },
    {
      "file": "run_llama.py",
      "line": 17,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.inference.llamao.modeling_flash_llama'",
      "snippet": "from swebench.inference.llamao.modeling_flash_llama import ("
    },
    {
      "file": "run_llama.py",
      "line": 20,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.inference.make_datasets.utils'",
      "snippet": "from swebench.inference.make_datasets.utils import extract_diff"
    },
    {
      "file": "run_llama.py",
      "line": 25,
      "col": 24,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "DEVICE_MAPS = json.load(open(Path(__file__).parent / \"codellama_device_maps.json\"))"
    },
    {
      "file": "run_llama.py",
      "line": 119,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Loading base model from {model_name_or_path}\")"
    },
    {
      "file": "run_llama.py",
      "line": 127,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Using max memory {max_memory}\")"
    },
    {
      "file": "run_llama.py",
      "line": 136,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Using device_map {device_map}\")"
    },
    {
      "file": "run_llama.py",
      "line": 146,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Loading PEFT adapters from {peft_path}\")"
    },
    {
      "file": "run_llama.py",
      "line": 158,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Loading tokenizer {model_name_or_path}\")"
    },
    {
      "file": "run_llama.py",
      "line": 193,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Loading dataset from {dataset_path}\")"
    },
    {
      "file": "run_llama.py",
      "line": 236,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.info("
    },
    {
      "file": "run_llama.py",
      "line": 240,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.info("
    },
    {
      "file": "run_llama.py",
      "line": 201,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-variable",
      "message": "Unused variable 'model_nickname'",
      "snippet": "        model_nickname = \"__\".join(peft_path.split(\"/\")[-2:])"
    },
    {
      "file": "run_llama.py",
      "line": 330,
      "col": 19,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "            except Exception as e:"
    },
    {
      "file": "run_llama.py",
      "line": 300,
      "col": 16,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "                logger.info(f\"Processing {input_ids.shape[-1]} tokens\")"
    },
    {
      "file": "run_llama.py",
      "line": 335,
      "col": 20,
      "severity": "MEDIUM",
      "rule_id": "PL-raise-missing-from",
      "message": "Consider explicitly re-raising using 'raise ValueError('too many failures') from e'",
      "snippet": "                    raise ValueError(\"too many failures\")"
    },
    {
      "file": "run_llama.py",
      "line": 351,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.info(f\"Loading existing ids from existing {filename}\")"
    },
    {
      "file": "run_llama.py",
      "line": 352,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(filename) as f:"
    },
    {
      "file": "run_llama.py",
      "line": 356,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Found {len(existing_ids)} existing ids\")"
    },
    {
      "file": "run_llama.py",
      "line": 381,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "            logger.warning("
    },
    {
      "file": "run_llama.py",
      "line": 397,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.warning(f\"output_file: {output_file}\")"
    },
    {
      "file": "run_llama.py",
      "line": 413,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(output_file, \"a\") as f:"
    },
    {
      "file": "distributed_attention.py",
      "line": 6,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'torch'",
      "snippet": "import torch"
    },
    {
      "file": "distributed_attention.py",
      "line": 9,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'torch'",
      "snippet": "from torch import Tensor"
    },
    {
      "file": "distributed_attention.py",
      "line": 10,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'torch.nn'",
      "snippet": "from torch.nn import Module"
    },
    {
      "file": "distributed_attention.py",
      "line": 12,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'torch.distributed'",
      "snippet": "import torch.distributed as dist"
    },
    {
      "file": "distributed_attention.py",
      "line": 18,
      "col": 18,
      "severity": "MEDIUM",
      "rule_id": "PL-redefined-builtin",
      "message": "Redefining built-in 'input'",
      "snippet": "        ctx: Any, input: Tensor, scatter_idx: int, gather_idx: int, group: Any"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 23,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'torch'",
      "snippet": "import torch"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 24,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'torch.nn.functional'",
      "snippet": "import torch.nn.functional as F"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 25,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'torch.utils.checkpoint'",
      "snippet": "import torch.utils.checkpoint"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 26,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'torch'",
      "snippet": "from torch import nn"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 27,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'torch.nn'",
      "snippet": "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 29,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'torch.distributed'",
      "snippet": "import torch.distributed as dist"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 31,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'transformers'",
      "snippet": "from transformers import GenerationMixin"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 32,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'transformers.activations'",
      "snippet": "from transformers.activations import ACT2FN"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 33,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'transformers.modeling_outputs'",
      "snippet": "from transformers.modeling_outputs import ("
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 38,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'transformers.modeling_utils'",
      "snippet": "from transformers.modeling_utils import PreTrainedModel"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 39,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'transformers.utils'",
      "snippet": "from transformers.utils import logging"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 40,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'transformers.models.llama.configuration_llama'",
      "snippet": "from transformers.models.llama.configuration_llama import LlamaConfig"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 42,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.inference.llamao.distributed_attention'",
      "snippet": "from swebench.inference.llamao.distributed_attention import DistributedAttention"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 43,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'flash_attn'",
      "snippet": "from flash_attn import flash_attn_kvpacked_func, flash_attn_varlen_kvpacked_func"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 44,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'flash_attn.bert_padding'",
      "snippet": "from flash_attn.bert_padding import unpad_input, pad_input"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 49,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-raise-missing-from",
      "message": "Consider explicitly re-raising using 'except ImportError as exc' and 'raise ImportError('Please install RoPE kernels: `pip install git+https://github.com/HazyResearch/flash-attention.git#subdirectory=csrc/rotary`') from exc'",
      "snippet": "    raise ImportError("
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 671,
      "col": 49,
      "severity": "HIGH",
      "rule_id": "PL-possibly-used-before-assignment",
      "message": "Possibly using variable 'unpad_indices' before assignment",
      "snippet": "                        pad_input(hidden_states, unpad_indices, bsz, max_seqlen),"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 625,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-variable",
      "message": "Unused variable 'batch_size'",
      "snippet": "            batch_size, seq_length = input_ids.shape"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 625,
      "col": 24,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-variable",
      "message": "Unused variable 'seq_length'",
      "snippet": "            batch_size, seq_length = input_ids.shape"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 779,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'unpadded_lengths'",
      "snippet": "        unpadded_lengths: Optional[bool] = None,"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 4,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'jedi'",
      "snippet": "import jedi"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 8,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'filelock'",
      "snippet": "from filelock import FileLock"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 10,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'datasets'",
      "snippet": "from datasets import load_from_disk, load_dataset"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 11,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'pyserini.search.lucene'",
      "snippet": "from pyserini.search.lucene import LuceneSearcher"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 12,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'git'",
      "snippet": "from git import Repo"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 17,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.inference.make_datasets.utils'",
      "snippet": "from swebench.inference.make_datasets.utils import list_files, string_to_bool"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 59,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "            logger.error(f\"Failed to switch to {self.base_commit}\")"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 66,
      "col": 28,
      "severity": "MEDIUM",
      "rule_id": "PL-unnecessary-lambda",
      "message": "Lambda may not be necessary",
      "snippet": "        files = list(filter(lambda x: os.path.isfile(x), files))"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 76,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(filename) as f:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 96,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 84,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(filename) as f:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 98,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.error(f\"Failed to parse file {str(filename)}. Using simple filecontent.\")"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 99,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(filename) as f:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 106,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(filename) as f:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 138,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "    except Exception as e:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 136,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-bare-except",
      "message": "No exception type(s) specified",
      "snippet": "            except:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 140,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.error(f\"Failed to parse file {str(filename)}. Using simple filecontent.\")"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 115,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-variable",
      "message": "Unused variable 'abspath'",
      "snippet": "        abspath = Path(filename).absolute()"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 169,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.info(f\"Cloning {repo} {os.getpid()}\")"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 228,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(documents_path, \"w\") as docfile:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 263,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-raise-missing-from",
      "message": "Consider explicitly re-raising using 'except KeyboardInterrupt as exc' and 'raise KeyboardInterrupt from exc'",
      "snippet": "        raise KeyboardInterrupt"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 265,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-not-lazy",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.warning(thread_prefix + \"Process killed by user\")"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 268,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.error(f\"return code: {proc.returncode}\")"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 269,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-raised",
      "message": "Raising too general exception: Exception",
      "snippet": "        raise Exception("
    },
    {
      "file": "bm25_retrieval.py",
      "line": 199,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'query'",
      "snippet": "    query,"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 260,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-variable",
      "message": "Unused variable 'output'",
      "snippet": "        output, error = proc.communicate()"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 291,
      "col": 17,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "            with open(output_file) as f:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 296,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "            logger.warning("
    },
    {
      "file": "bm25_retrieval.py",
      "line": 343,
      "col": 11,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "    except Exception:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 332,
      "col": 19,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "            except Exception as e:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 344,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.error(f\"Failed to process {instance_id}\")"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 367,
      "col": 17,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "            with open(output_file, \"a\") as out_file:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 372,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(output_file) as f:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 409,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-bare-except",
      "message": "No exception type(s) specified",
      "snippet": "    except:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 410,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.error(f\"Failed to process {repo}/{commit} (instance {instance_id})\")"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 421,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'output_file'",
      "snippet": "    output_file: str,"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 486,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "    python = subprocess.run(\"which python\", shell=True, capture_output=True)"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 505,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.info(f\"Cleaning up {root_dir}\")"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 512,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Finished indexing {len(all_index_paths)} instances\")"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 515,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.warning(f\"Missing indexes for {len(missing_ids)} instances.\")"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 516,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Saved retrieval results to {output_file}\")"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 518,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Cleaning up {root_dir}\")"
    },
    {
      "file": "create_instance.py",
      "line": 8,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'unidiff'",
      "snippet": "import unidiff"
    },
    {
      "file": "create_instance.py",
      "line": 11,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.inference.make_datasets.tokenize_dataset'",
      "snippet": "from swebench.inference.make_datasets.tokenize_dataset import TOKENIZER_FUNCS"
    },
    {
      "file": "create_instance.py",
      "line": 12,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.inference.make_datasets.utils'",
      "snippet": "from swebench.inference.make_datasets.utils import ("
    },
    {
      "file": "create_instance.py",
      "line": 139,
      "col": 49,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'add_line_numbers'",
      "snippet": "def make_code_text_edits_only(files_dict, patch, add_line_numbers=True):"
    },
    {
      "file": "create_instance.py",
      "line": 290,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(filename) as f:"
    },
    {
      "file": "create_instance.py",
      "line": 312,
      "col": 54,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    retrieval_results = [json.loads(line) for line in open(retrieval_results_path)]"
    },
    {
      "file": "create_instance.py",
      "line": 322,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "            logger.warning(f\"Instance {instance_id} not found in retrieval results\")"
    },
    {
      "file": "create_instance.py",
      "line": 304,
      "col": 62,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'file_source'",
      "snippet": "def add_retrieval_results(input_instances, retrieval_file, k, file_source):"
    },
    {
      "file": "create_instance.py",
      "line": 373,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(progress_file) as f:"
    },
    {
      "file": "create_instance.py",
      "line": 377,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.info(f\"Found {len(processed_ids)} already processed instances\")"
    },
    {
      "file": "create_instance.py",
      "line": 378,
      "col": 31,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        progress_file_handle = open(progress_file, \"a\")"
    },
    {
      "file": "create_instance.py",
      "line": 380,
      "col": 31,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        progress_file_handle = open(progress_file, \"w\")"
    },
    {
      "file": "create_instance.py",
      "line": 398,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.info(f\"Processing {len(instances_to_process)} instances\")"
    },
    {
      "file": "create_instance.py",
      "line": 484,
      "col": 23,
      "severity": "MEDIUM",
      "rule_id": "PL-broad-exception-caught",
      "message": "Catching too general exception Exception",
      "snippet": "                except Exception as e:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 12,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'datasets'",
      "snippet": "from datasets import Dataset, DatasetDict, load_dataset, load_from_disk"
    },
    {
      "file": "create_text_dataset.py",
      "line": 15,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.inference.make_datasets.create_instance'",
      "snippet": "from swebench.inference.make_datasets.create_instance import ("
    },
    {
      "file": "create_text_dataset.py",
      "line": 19,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.inference.make_datasets.tokenize_dataset'",
      "snippet": "from swebench.inference.make_datasets.tokenize_dataset import TOKENIZER_FUNCS"
    },
    {
      "file": "create_text_dataset.py",
      "line": 29,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(filename) as f:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 32,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(filename) as f:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 53,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Found {len(train_instances)} training ids\")"
    },
    {
      "file": "create_text_dataset.py",
      "line": 54,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Found {len(eval_instances)} eval ids\")"
    },
    {
      "file": "create_text_dataset.py",
      "line": 61,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.warning(f\"No text for {instance_id}\")"
    },
    {
      "file": "create_text_dataset.py",
      "line": 65,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.warning(f\"No inputs for {instance_id}\")"
    },
    {
      "file": "create_text_dataset.py",
      "line": 146,
      "col": 20,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "                    logger.info("
    },
    {
      "file": "create_text_dataset.py",
      "line": 158,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Found {set(dataset.keys())} splits\")"
    },
    {
      "file": "create_text_dataset.py",
      "line": 183,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.info(f\"Processing {split} split\")"
    },
    {
      "file": "create_text_dataset.py",
      "line": 210,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(progress_files[split]) as f:"
    },
    {
      "file": "create_text_dataset.py",
      "line": 222,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "            logger.warning("
    },
    {
      "file": "create_text_dataset.py",
      "line": 238,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.info(f\"Found {len(final_dataset[split])} {split} instances\")"
    },
    {
      "file": "create_text_dataset.py",
      "line": 253,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info(f\"Finished saving to {output_file}\")"
    },
    {
      "file": "eval_retrieval.py",
      "line": 7,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'datasets'",
      "snippet": "from datasets import load_dataset, disable_caching, load_from_disk"
    },
    {
      "file": "eval_retrieval.py",
      "line": 21,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-bare-except",
      "message": "No exception type(s) specified",
      "snippet": "    except:"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 10,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'tiktoken'",
      "snippet": "import tiktoken"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 11,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'datasets'",
      "snippet": "from datasets import disable_caching, load_from_disk, load_dataset"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 13,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'transformers'",
      "snippet": "from transformers import LlamaTokenizer"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 74,
      "col": 34,
      "severity": "MEDIUM",
      "rule_id": "PL-unused-argument",
      "message": "Unused argument 'tokenizer_name'",
      "snippet": "def extract_test_fields(instance, tokenizer_name, tokenizer, tokenizer_func, eos_token):"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 148,
      "col": 20,
      "severity": "HIGH",
      "rule_id": "PL-possibly-used-before-assignment",
      "message": "Possibly using variable 'tokenizer_func' before assignment",
      "snippet": "                    tokenizer_func,"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 149,
      "col": 20,
      "severity": "HIGH",
      "rule_id": "PL-possibly-used-before-assignment",
      "message": "Possibly using variable 'eos_token' before assignment",
      "snippet": "                    eos_token,"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 171,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "            logger.warning(f\"Split {split} not in dataset. Skipping\")"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 207,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.warning(f\"Saved to {output_file}\")"
    },
    {
      "file": "get_versions.py",
      "line": 12,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.versioning.constants'",
      "snippet": "from swebench.versioning.constants import ("
    },
    {
      "file": "get_versions.py",
      "line": 17,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.versioning.utils'",
      "snippet": "from swebench.versioning.utils import get_instances, split_instances"
    },
    {
      "file": "get_versions.py",
      "line": 84,
      "col": 16,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "                logger.info(f\"Found version file at {path_to_version}\")"
    },
    {
      "file": "get_versions.py",
      "line": 85,
      "col": 21,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "                with open(path_to_version) as f:"
    },
    {
      "file": "get_versions.py",
      "line": 94,
      "col": 24,
      "severity": "MEDIUM",
      "rule_id": "PL-missing-timeout",
      "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
      "snippet": "            init_text = requests.get(url).text"
    },
    {
      "file": "get_versions.py",
      "line": 167,
      "col": 20,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "        out_check = subprocess.run("
    },
    {
      "file": "get_versions.py",
      "line": 173,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "            logger.error(f\"[{instance['instance_id']}] Checkout failed\")"
    },
    {
      "file": "get_versions.py",
      "line": 177,
      "col": 22,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "        out_install = subprocess.run("
    },
    {
      "file": "get_versions.py",
      "line": 183,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "            logger.error(f\"[{instance['instance_id']}] Installation failed\")"
    },
    {
      "file": "get_versions.py",
      "line": 189,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "        logger.info(f\"For instance {instance['instance_id']}, version is {version}\")"
    },
    {
      "file": "get_versions.py",
      "line": 192,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(save_path, \"w\") as f:"
    },
    {
      "file": "get_versions.py",
      "line": 212,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "            logger.info(f\"For instance {instance['instance_id']}, version is {version}\")"
    },
    {
      "file": "get_versions.py",
      "line": 214,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "            logger.info(f\"[{instance['instance_id']}]: version not found\")"
    },
    {
      "file": "get_versions.py",
      "line": 216,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(save_path, \"w\") as f:"
    },
    {
      "file": "get_versions.py",
      "line": 234,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "        with open(task_with_version_path) as f:"
    },
    {
      "file": "get_versions.py",
      "line": 244,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "    with open(f\"{instances_path_new}\", \"w\") as f:"
    },
    {
      "file": "get_versions.py",
      "line": 246,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info("
    },
    {
      "file": "get_versions.py",
      "line": 252,
      "col": 9,
      "severity": "MEDIUM",
      "rule_id": "PL-redefined-outer-name",
      "message": "Redefining name 'args' from outer scope (line 426)",
      "snippet": "def main(args):"
    },
    {
      "file": "get_versions.py",
      "line": 261,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info("
    },
    {
      "file": "get_versions.py",
      "line": 264,
      "col": 4,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "    logger.info("
    },
    {
      "file": "get_versions.py",
      "line": 301,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "            logger.info(f\"Retrieved {total_web} versions from web\")"
    },
    {
      "file": "get_versions.py",
      "line": 303,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "            logger.info("
    },
    {
      "file": "get_versions.py",
      "line": 318,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "            logger.info("
    },
    {
      "file": "get_versions.py",
      "line": 326,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "            logger.info("
    },
    {
      "file": "get_versions.py",
      "line": 332,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "            logger.info(f\"Creating clone of {args.conda_env} at {conda_env_name}\")"
    },
    {
      "file": "get_versions.py",
      "line": 338,
      "col": 12,
      "severity": "MEDIUM",
      "rule_id": "PL-logging-fstring-interpolation",
      "message": "Use lazy % formatting in logging functions",
      "snippet": "            logger.info("
    },
    {
      "file": "get_versions_astropy.py",
      "line": 10,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'utils'",
      "snippet": "from utils import get_instances"
    },
    {
      "file": "get_versions_astropy.py",
      "line": 18,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "PL-missing-timeout",
      "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
      "snippet": "resp = requests.get(\"https://docs.astropy.org/en/latest/changelog.html\")"
    },
    {
      "file": "get_versions_astropy.py",
      "line": 66,
      "col": 39,
      "severity": "MEDIUM",
      "rule_id": "PL-undefined-loop-variable",
      "message": "Using possibly undefined loop variable 't'",
      "snippet": "    map_v_to_t[task[\"version\"]].append(t)"
    },
    {
      "file": "get_versions_astropy.py",
      "line": 69,
      "col": 5,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "with open("
    },
    {
      "file": "get_versions_matplotlib.py",
      "line": 10,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'utils'",
      "snippet": "from utils import get_instances"
    },
    {
      "file": "get_versions_matplotlib.py",
      "line": 18,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "PL-missing-timeout",
      "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
      "snippet": "resp = requests.get(\"https://matplotlib.org/stable/users/release_notes#past-versions\")"
    },
    {
      "file": "get_versions_matplotlib.py",
      "line": 53,
      "col": 5,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "with open("
    },
    {
      "file": "get_versions_pvlib-python.py",
      "line": 9,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'utils'",
      "snippet": "from utils import get_instances"
    },
    {
      "file": "get_versions_pvlib-python.py",
      "line": 23,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "PL-missing-timeout",
      "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
      "snippet": "resp = requests.get(WEBPAGE)"
    },
    {
      "file": "get_versions_pvlib-python.py",
      "line": 67,
      "col": 39,
      "severity": "MEDIUM",
      "rule_id": "PL-undefined-loop-variable",
      "message": "Using possibly undefined loop variable 't'",
      "snippet": "    map_v_to_t[task[\"version\"]].append(t)"
    },
    {
      "file": "get_versions_pvlib-python.py",
      "line": 70,
      "col": 5,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "with open(PATH_TASKS_PVLIB_V, \"w\") as f:"
    },
    {
      "file": "get_versions_pydicom.py",
      "line": 5,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'bs4'",
      "snippet": "from bs4 import BeautifulSoup"
    },
    {
      "file": "get_versions_pydicom.py",
      "line": 8,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'utils'",
      "snippet": "from utils import get_instances"
    },
    {
      "file": "get_versions_pydicom.py",
      "line": 14,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "PL-missing-timeout",
      "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
      "snippet": "resp = requests.get(\"https://pydicom.github.io/pydicom/dev/faq/index.html\")"
    },
    {
      "file": "get_versions_pydicom.py",
      "line": 27,
      "col": 19,
      "severity": "HIGH",
      "rule_id": "PL-no-member",
      "message": "Module 'datetime' has no 'strptime' member",
      "snippet": "            date = datetime.strptime(date, \"%B %Y\").strftime(\"%Y-%m-%d\")"
    },
    {
      "file": "get_versions_pydicom.py",
      "line": 43,
      "col": 5,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "with open(PATH_TASKS_PYDICOM_V, \"w\") as f:"
    },
    {
      "file": "get_versions_sqlfluff.py",
      "line": 5,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'ghapi.core'",
      "snippet": "from ghapi.core import GhApi"
    },
    {
      "file": "get_versions_sqlfluff.py",
      "line": 8,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'utils'",
      "snippet": "from utils import get_instances"
    },
    {
      "file": "get_versions_sqlfluff.py",
      "line": 38,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-redefined-outer-name",
      "message": "Redefining name 'version' from outer scope (line 58)",
      "snippet": "        version = parts[0].replace(\"[\", \"\").replace(\"]\", \"\")"
    },
    {
      "file": "get_versions_sqlfluff.py",
      "line": 85,
      "col": 5,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "with open("
    },
    {
      "file": "get_versions_sqlfluff.py",
      "line": 92,
      "col": 22,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "versioned = json.load(open(os.path.join(PATH_TO_SAVE, versioned_path)))"
    },
    {
      "file": "get_versions_xarray.py",
      "line": 10,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'utils'",
      "snippet": "from utils import get_instances"
    },
    {
      "file": "get_versions_xarray.py",
      "line": 18,
      "col": 7,
      "severity": "MEDIUM",
      "rule_id": "PL-missing-timeout",
      "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
      "snippet": "resp = requests.get(\"https://docs.xarray.dev/en/stable/whats-new.html\")"
    },
    {
      "file": "get_versions_xarray.py",
      "line": 40,
      "col": 8,
      "severity": "MEDIUM",
      "rule_id": "PL-bare-except",
      "message": "No exception type(s) specified",
      "snippet": "        except:"
    },
    {
      "file": "get_versions_xarray.py",
      "line": 58,
      "col": 5,
      "severity": "MEDIUM",
      "rule_id": "PL-unspecified-encoding",
      "message": "Using open without explicitly specifying an encoding",
      "snippet": "with open("
    },
    {
      "file": "test_cli.py",
      "line": 6,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "    result = subprocess.run(cmd, capture_output=True)"
    },
    {
      "file": "test_cli.py",
      "line": 26,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "    result = subprocess.run(cmd, capture_output=True)"
    },
    {
      "file": "test_collect_cli.py",
      "line": 7,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "    result = subprocess.run(cmd, capture_output=True)"
    },
    {
      "file": "test_collect_cli.py",
      "line": 24,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "    result = subprocess.run(cmd, capture_output=True)"
    },
    {
      "file": "test_collect_cli.py",
      "line": 39,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "    result = subprocess.run(cmd, capture_output=True)"
    },
    {
      "file": "test_collect_cli.py",
      "line": 57,
      "col": 13,
      "severity": "MEDIUM",
      "rule_id": "PL-subprocess-run-check",
      "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
      "snippet": "    result = subprocess.run(cmd, capture_output=True)"
    },
    {
      "file": "test_evaluation.py",
      "line": 3,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'docker'",
      "snippet": "import docker"
    },
    {
      "file": "test_evaluation.py",
      "line": 5,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.constants'",
      "snippet": "from swebench.harness.constants import ("
    },
    {
      "file": "test_evaluation.py",
      "line": 11,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.run_evaluation'",
      "snippet": "from swebench.harness.run_evaluation import make_run_report"
    },
    {
      "file": "test_harness_utils.py",
      "line": 2,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.utils'",
      "snippet": "from swebench.harness.utils import run_threadpool"
    },
    {
      "file": "test_harness_utils.py",
      "line": 3,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "PL-import-error",
      "message": "Unable to import 'swebench.harness.test_spec.python'",
      "snippet": "from swebench.harness.test_spec.python import clean_environment_yml, clean_requirements"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 7,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B404",
      "message": "Consider possible security implications associated with the subprocess module.",
      "snippet": "import subprocess"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 136,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B112",
      "message": "Try, Except, Continue detected.",
      "snippet": "            except:"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 254,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "        proc = subprocess.Popen("
    },
    {
      "file": "bm25_retrieval.py",
      "line": 476,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B615",
      "message": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
      "snippet": "        dataset = load_dataset(dataset_name_or_path)"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 486,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B607",
      "message": "Starting a process with a partial executable path",
      "snippet": "    python = subprocess.run(\"which python\", shell=True, capture_output=True)"
    },
    {
      "file": "bm25_retrieval.py",
      "line": 486,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B602",
      "message": "subprocess call with shell=True seems safe, but may be changed in the future, consider rewriting without shell",
      "snippet": "    python = subprocess.run(\"which python\", shell=True, capture_output=True)"
    },
    {
      "file": "c.py",
      "line": 2,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B405",
      "message": "Using xml.etree.ElementTree to parse untrusted XML data is known to be vulnerable to XML attacks. Replace xml.etree.ElementTree with the equivalent defusedxml package, or make sure defusedxml.defuse_stdlib() is called.",
      "snippet": "import xml.etree.ElementTree as ET"
    },
    {
      "file": "c.py",
      "line": 73,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B314",
      "message": "Using xml.etree.ElementTree.fromstring to parse untrusted XML data is known to be vulnerable to XML attacks. Replace xml.etree.ElementTree.fromstring with its defusedxml equivalent function or make sure defusedxml.defuse_stdlib() is called",
      "snippet": "        root = ET.fromstring(xml_string)"
    },
    {
      "file": "call_make_repo.py",
      "line": 3,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B404",
      "message": "Consider possible security implications associated with the subprocess module.",
      "snippet": "import subprocess"
    },
    {
      "file": "call_make_repo.py",
      "line": 11,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "B602",
      "message": "subprocess call with shell=True identified, security issue.",
      "snippet": "        shell=True,"
    },
    {
      "file": "create_instance.py",
      "line": 309,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "    assert retrieval_results_path.exists(), ("
    },
    {
      "file": "create_instance.py",
      "line": 362,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "    assert progress_file is not None, \"progress_file is required\""
    },
    {
      "file": "create_instance.py",
      "line": 384,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "            assert tokenizer_name is not None, ("
    },
    {
      "file": "create_instance.py",
      "line": 402,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B108",
      "message": "Probable insecure usage of temp file/directory.",
      "snippet": "            dir=\"/scratch\" if os.path.exists(\"/scratch\") else \"/tmp\""
    },
    {
      "file": "create_text_dataset.py",
      "line": 77,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "        assert hub_token is not None, ("
    },
    {
      "file": "create_text_dataset.py",
      "line": 80,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "        assert output_dir is None, \"Cannot provide output_dir if pushing to the Hub\""
    },
    {
      "file": "create_text_dataset.py",
      "line": 82,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "        assert tokenizer_name is not None"
    },
    {
      "file": "create_text_dataset.py",
      "line": 86,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "        assert file_source not in {\"all\", \"oracle\"}, ("
    },
    {
      "file": "create_text_dataset.py",
      "line": 89,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "        assert tokenizer_name is not None, ("
    },
    {
      "file": "create_text_dataset.py",
      "line": 93,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "        assert file_source not in {\"all\", \"oracle\"}, ("
    },
    {
      "file": "create_text_dataset.py",
      "line": 156,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B615",
      "message": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
      "snippet": "        else load_dataset(dataset_name_or_path)"
    },
    {
      "file": "criteria.py",
      "line": 101,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B113",
      "message": "Call to requests without timeout",
      "snippet": "        if requests.get(url).status_code == 200:"
    },
    {
      "file": "default.py",
      "line": 4,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B404",
      "message": "Consider possible security implications associated with the subprocess module.",
      "snippet": "import subprocess"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 5,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B404",
      "message": "Consider possible security implications associated with the subprocess module.",
      "snippet": "import subprocess"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 16,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B607",
      "message": "Starting a process with a partial executable path",
      "snippet": "    branches_command = subprocess.run("
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 16,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "    branches_command = subprocess.run("
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 21,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B607",
      "message": "Starting a process with a partial executable path",
      "snippet": "    subprocess.run("
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 21,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "    subprocess.run("
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 33,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B607",
      "message": "Starting a process with a partial executable path",
      "snippet": "        subprocess.run([\"git\", \"checkout\", branch])"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 33,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "        subprocess.run([\"git\", \"checkout\", branch])"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 39,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B607",
      "message": "Starting a process with a partial executable path",
      "snippet": "            subprocess.run([\"rm\", \"-rf\", workflows_path])"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 39,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "            subprocess.run([\"rm\", \"-rf\", workflows_path])"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 40,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B607",
      "message": "Starting a process with a partial executable path",
      "snippet": "            subprocess.run([\"git\", \"add\", \"-A\"])"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 40,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "            subprocess.run([\"git\", \"add\", \"-A\"])"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 41,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B607",
      "message": "Starting a process with a partial executable path",
      "snippet": "            subprocess.run([\"git\", \"commit\", \"-m\", \"Remove .github/workflows folder\"])"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 41,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "            subprocess.run([\"git\", \"commit\", \"-m\", \"Remove .github/workflows folder\"])"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 42,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B607",
      "message": "Starting a process with a partial executable path",
      "snippet": "            subprocess.run([\"git\", \"push\"])"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 42,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "            subprocess.run([\"git\", \"push\"])"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 47,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B607",
      "message": "Starting a process with a partial executable path",
      "snippet": "    subprocess.run([\"rm\", \"-rf\", \"temp_repo\"])"
    },
    {
      "file": "delete_gh_workflows.py",
      "line": 47,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "    subprocess.run([\"rm\", \"-rf\", \"temp_repo\"])"
    },
    {
      "file": "eval_retrieval.py",
      "line": 22,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B615",
      "message": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
      "snippet": "        dataset = load_dataset(dataset_name_or_path, split=split)"
    },
    {
      "file": "get_top_pypi.py",
      "line": 74,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B110",
      "message": "Try, Except, Pass detected.",
      "snippet": "                except:"
    },
    {
      "file": "get_versions.py",
      "line": 8,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B404",
      "message": "Consider possible security implications associated with the subprocess module.",
      "snippet": "import subprocess"
    },
    {
      "file": "get_versions.py",
      "line": 94,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B113",
      "message": "Call to requests without timeout",
      "snippet": "            init_text = requests.get(url).text"
    },
    {
      "file": "get_versions.py",
      "line": 158,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B607",
      "message": "Starting a process with a partial executable path",
      "snippet": "        subprocess.run("
    },
    {
      "file": "get_versions.py",
      "line": 159,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B602",
      "message": "subprocess call with shell=True seems safe, but may be changed in the future, consider rewriting without shell",
      "snippet": "            \"git restore .\", check=True, shell=True, stdout=subprocess.DEVNULL"
    },
    {
      "file": "get_versions.py",
      "line": 161,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B607",
      "message": "Starting a process with a partial executable path",
      "snippet": "        subprocess.run("
    },
    {
      "file": "get_versions.py",
      "line": 162,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B602",
      "message": "subprocess call with shell=True seems safe, but may be changed in the future, consider rewriting without shell",
      "snippet": "            \"git reset HEAD .\", check=True, shell=True, stdout=subprocess.DEVNULL"
    },
    {
      "file": "get_versions.py",
      "line": 164,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B607",
      "message": "Starting a process with a partial executable path",
      "snippet": "        subprocess.run("
    },
    {
      "file": "get_versions.py",
      "line": 165,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B602",
      "message": "subprocess call with shell=True seems safe, but may be changed in the future, consider rewriting without shell",
      "snippet": "            \"git clean -fd\", shell=True, check=True, stdout=subprocess.DEVNULL"
    },
    {
      "file": "get_versions.py",
      "line": 169,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "B602",
      "message": "subprocess call with shell=True identified, security issue.",
      "snippet": "            shell=True,"
    },
    {
      "file": "get_versions.py",
      "line": 179,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "B602",
      "message": "subprocess call with shell=True identified, security issue.",
      "snippet": "            shell=True,"
    },
    {
      "file": "get_versions.py",
      "line": 293,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "            assert len(data_tasks) == merge_results("
    },
    {
      "file": "get_versions.py",
      "line": 308,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "    assert any([x == args.retrieval_method for x in [\"build\", \"mix\"]])"
    },
    {
      "file": "get_versions.py",
      "line": 309,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "    assert all([x in args for x in [\"testbed\", \"path_conda\", \"conda_env\"]])"
    },
    {
      "file": "get_versions.py",
      "line": 324,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "B602",
      "message": "subprocess call with shell=True identified, security issue.",
      "snippet": "            subprocess.run(cmd_clone, shell=True, check=True, stdout=subprocess.DEVNULL)"
    },
    {
      "file": "get_versions.py",
      "line": 335,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "B602",
      "message": "subprocess call with shell=True identified, security issue.",
      "snippet": "                cmd_clone_env, shell=True, check=True, stdout=subprocess.DEVNULL"
    },
    {
      "file": "get_versions.py",
      "line": 365,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "        assert ("
    },
    {
      "file": "get_versions.py",
      "line": 371,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "        assert len(data_tasks) == merge_results("
    },
    {
      "file": "get_versions.py",
      "line": 382,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "B602",
      "message": "subprocess call with shell=True identified, security issue.",
      "snippet": "            subprocess.run(f\"rm -rf {testbed_repo_name}\", shell=True, check=True)"
    },
    {
      "file": "get_versions.py",
      "line": 388,
      "col": 0,
      "severity": "HIGH",
      "rule_id": "B602",
      "message": "subprocess call with shell=True identified, security issue.",
      "snippet": "            subprocess.run(cmd_rm_env, shell=True, check=True)"
    },
    {
      "file": "get_versions_astropy.py",
      "line": 18,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B113",
      "message": "Call to requests without timeout",
      "snippet": "resp = requests.get(\"https://docs.astropy.org/en/latest/changelog.html\")"
    },
    {
      "file": "get_versions_matplotlib.py",
      "line": 18,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B113",
      "message": "Call to requests without timeout",
      "snippet": "resp = requests.get(\"https://matplotlib.org/stable/users/release_notes#past-versions\")"
    },
    {
      "file": "get_versions_pvlib-python.py",
      "line": 23,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B113",
      "message": "Call to requests without timeout",
      "snippet": "resp = requests.get(WEBPAGE)"
    },
    {
      "file": "get_versions_pydicom.py",
      "line": 14,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B113",
      "message": "Call to requests without timeout",
      "snippet": "resp = requests.get(\"https://pydicom.github.io/pydicom/dev/faq/index.html\")"
    },
    {
      "file": "get_versions_sqlfluff.py",
      "line": 10,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B105",
      "message": "Possible hardcoded password: '<your GitHub token>'",
      "snippet": "GITHUB_TOKEN = \"<your GitHub token>\""
    },
    {
      "file": "get_versions_xarray.py",
      "line": 18,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B113",
      "message": "Call to requests without timeout",
      "snippet": "resp = requests.get(\"https://docs.xarray.dev/en/stable/whats-new.html\")"
    },
    {
      "file": "get_versions_xarray.py",
      "line": 40,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B112",
      "message": "Try, Except, Continue detected.",
      "snippet": "        except:"
    },
    {
      "file": "make_lite.py",
      "line": 75,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B615",
      "message": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
      "snippet": "    dev = load_dataset(\"SWE-bench/SWE-bench\")[\"dev\"]"
    },
    {
      "file": "make_lite.py",
      "line": 76,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B615",
      "message": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
      "snippet": "    test = load_dataset(\"SWE-bench/SWE-bench\")[\"test\"]"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 251,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "            assert False"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 329,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "            assert scaling_type == \"linear\""
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 413,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "            assert output_attentions is False"
    },
    {
      "file": "modeling_flash_llama.py",
      "line": 426,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "                assert attention_mask is not None"
    },
    {
      "file": "python.py",
      "line": 35,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B113",
      "message": "Call to requests without timeout",
      "snippet": "        reqs = requests.get(reqs_url, headers=HEADERS)"
    },
    {
      "file": "python.py",
      "line": 141,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B113",
      "message": "Call to requests without timeout",
      "snippet": "        reqs = requests.get(reqs_url, headers=HEADERS)"
    },
    {
      "file": "python.py",
      "line": 168,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B113",
      "message": "Call to requests without timeout",
      "snippet": "            reqs = requests.get(reqs_url, headers=HEADERS)"
    },
    {
      "file": "remove_envs.py",
      "line": 5,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B404",
      "message": "Consider possible security implications associated with the subprocess module.",
      "snippet": "import subprocess"
    },
    {
      "file": "remove_envs.py",
      "line": 40,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "    subprocess.run(command.split(\" \"))"
    },
    {
      "file": "remove_envs.py",
      "line": 52,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "            conda_create_output = subprocess.run("
    },
    {
      "file": "remove_envs.py",
      "line": 79,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "        conda_envs = subprocess.run("
    },
    {
      "file": "run_api.py",
      "line": 480,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B615",
      "message": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
      "snippet": "        dataset = load_dataset(dataset_name_or_path)"
    },
    {
      "file": "run_evaluation.py",
      "line": 137,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B110",
      "message": "Try, Except, Pass detected.",
      "snippet": "            except:"
    },
    {
      "file": "run_evaluation.py",
      "line": 504,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "    assert len(run_id) > 0, \"Run ID must be provided\""
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 150,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B110",
      "message": "Try, Except, Pass detected.",
      "snippet": "                        except Exception:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 154,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B110",
      "message": "Try, Except, Pass detected.",
      "snippet": "            except Exception:"
    },
    {
      "file": "run_evaluation_modal.py",
      "line": 269,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B108",
      "message": "Probable insecure usage of temp file/directory.",
      "snippet": "        patch_file = \"/tmp/patch.diff\""
    },
    {
      "file": "run_evaluation_modal_entrypoint.py",
      "line": 112,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B102",
      "message": "Use of exec detected.",
      "snippet": "    returncode = await exec(command)"
    },
    {
      "file": "run_live.py",
      "line": 11,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B404",
      "message": "Consider possible security implications associated with the subprocess module.",
      "snippet": "import subprocess"
    },
    {
      "file": "run_live.py",
      "line": 113,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B607",
      "message": "Starting a process with a partial executable path",
      "snippet": "            subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=repo_dir)"
    },
    {
      "file": "run_live.py",
      "line": 113,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "            subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=repo_dir)"
    },
    {
      "file": "run_live.py",
      "line": 196,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B607",
      "message": "Starting a process with a partial executable path",
      "snippet": "    python = subprocess.check_output([\"which\", \"python\"]).decode(\"utf-8\").strip()"
    },
    {
      "file": "run_live.py",
      "line": 196,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "    python = subprocess.check_output([\"which\", \"python\"]).decode(\"utf-8\").strip()"
    },
    {
      "file": "run_llama.py",
      "line": 159,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B615",
      "message": "Unsafe Hugging Face Hub download without revision pinning in from_pretrained()",
      "snippet": "    tokenizer = LlamaTokenizer.from_pretrained(model_name_or_path)"
    },
    {
      "file": "run_llama.py",
      "line": 195,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B615",
      "message": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
      "snippet": "        dataset = load_dataset(dataset_path, split=split)"
    },
    {
      "file": "run_llama.py",
      "line": 199,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B615",
      "message": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
      "snippet": "        dataset = load_dataset(dataset_path)[split]"
    },
    {
      "file": "test_cli.py",
      "line": 1,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B404",
      "message": "Consider possible security implications associated with the subprocess module.",
      "snippet": "import subprocess"
    },
    {
      "file": "test_cli.py",
      "line": 6,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "    result = subprocess.run(cmd, capture_output=True)"
    },
    {
      "file": "test_cli.py",
      "line": 9,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "    assert result.returncode == 0"
    },
    {
      "file": "test_cli.py",
      "line": 26,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "    result = subprocess.run(cmd, capture_output=True)"
    },
    {
      "file": "test_cli.py",
      "line": 29,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "    assert result.returncode == 0"
    },
    {
      "file": "test_collect_cli.py",
      "line": 2,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B404",
      "message": "Consider possible security implications associated with the subprocess module.",
      "snippet": "import subprocess"
    },
    {
      "file": "test_collect_cli.py",
      "line": 7,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "    result = subprocess.run(cmd, capture_output=True)"
    },
    {
      "file": "test_collect_cli.py",
      "line": 10,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "    assert result.returncode == 0"
    },
    {
      "file": "test_collect_cli.py",
      "line": 24,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "    result = subprocess.run(cmd, capture_output=True)"
    },
    {
      "file": "test_collect_cli.py",
      "line": 27,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "    assert result.returncode == 0"
    },
    {
      "file": "test_collect_cli.py",
      "line": 39,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "    result = subprocess.run(cmd, capture_output=True)"
    },
    {
      "file": "test_collect_cli.py",
      "line": 42,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "    assert result.returncode == 0"
    },
    {
      "file": "test_collect_cli.py",
      "line": 57,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B603",
      "message": "subprocess call - check for execution of untrusted input.",
      "snippet": "    result = subprocess.run(cmd, capture_output=True)"
    },
    {
      "file": "test_collect_cli.py",
      "line": 60,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "    assert result.returncode == 0"
    },
    {
      "file": "test_collect_cli.py",
      "line": 62,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "    assert len(data[\"resolved_issues\"]) == 2"
    },
    {
      "file": "test_collect_cli.py",
      "line": 63,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "    assert sorted(data[\"resolved_issues\"]) == [\"26194\", \"26230\"]"
    },
    {
      "file": "test_evaluation.py",
      "line": 29,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "        assert output_path.is_file()"
    },
    {
      "file": "test_evaluation.py",
      "line": 31,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "        assert report[\"schema_version\"] == 2"
    },
    {
      "file": "test_spec.py",
      "line": 184,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "    assert base_image_tag is not None, \"base_image_tag cannot be None\""
    },
    {
      "file": "test_spec.py",
      "line": 185,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "    assert env_image_tag is not None, \"env_image_tag cannot be None\""
    },
    {
      "file": "test_spec.py",
      "line": 186,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "    assert instance_image_tag is not None, \"instance_image_tag cannot be None\""
    },
    {
      "file": "tokenize_dataset.py",
      "line": 33,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B615",
      "message": "Unsafe Hugging Face Hub download without revision pinning in from_pretrained()",
      "snippet": "    \"llama\": (LlamaTokenizer.from_pretrained(\"togethercomputer/LLaMA-2-7B-32K\"), llama),"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 55,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "        assert idx <= 2, ("
    },
    {
      "file": "tokenize_dataset.py",
      "line": 64,
      "col": 0,
      "severity": "LOW",
      "rule_id": "B101",
      "message": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
      "snippet": "    assert len(inputs) == len(labels)"
    },
    {
      "file": "tokenize_dataset.py",
      "line": 135,
      "col": 0,
      "severity": "MEDIUM",
      "rule_id": "B615",
      "message": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
      "snippet": "        dataset = load_dataset(dataset_name_or_path)"
    }
  ],
  "external_tools_details": {
    "ruff": {
      "count": 285,
      "findings": [
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 15,
            "row": 19
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import ast\nimport json\nimport logging\nimport os\nimport shutil\nimport subprocess\nimport traceback\nfrom argparse import ArgumentParser\nfrom pathlib import Path\nfrom typing import Any\n\nimport jedi\nfrom datasets import load_dataset, load_from_disk\nfrom filelock import FileLock\nfrom git import Repo\nfrom pyserini.search.lucene import LuceneSearcher\nfrom swebench.inference.make_datasets.utils import list_files, string_to_bool\nfrom tqdm.auto import tqdm\n\n",
                "end_location": {
                  "column": 1,
                  "row": 21
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 94,
            "row": 41
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 41
          },
          "message": "Line too long (93 > 88)",
          "noqa_row": 44,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 96,
            "row": 42
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 42
          },
          "message": "Line too long (95 > 88)",
          "noqa_row": 44,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "F841",
          "end_location": {
            "column": 16,
            "row": 115
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "",
                "end_location": {
                  "column": 19,
                  "row": 115
                },
                "location": {
                  "column": 9,
                  "row": 115
                }
              }
            ],
            "message": "Remove assignment to unused variable `abspath`"
          },
          "location": {
            "column": 9,
            "row": 115
          },
          "message": "Local variable `abspath` is assigned to but never used",
          "noqa_row": 115,
          "url": "https://docs.astral.sh/ruff/rules/unused-variable"
        },
        {
          "cell": null,
          "code": "E722",
          "end_location": {
            "column": 19,
            "row": 136
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "fix": null,
          "location": {
            "column": 13,
            "row": 136
          },
          "message": "Do not use bare `except`",
          "noqa_row": 136,
          "url": "https://docs.astral.sh/ruff/rules/bare-except"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 135,
            "row": 181
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 181
          },
          "message": "Line too long (134 > 88)",
          "noqa_row": 185,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 128,
            "row": 184
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 184
          },
          "message": "Line too long (127 > 88)",
          "noqa_row": 185,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "B904",
          "end_location": {
            "column": 32,
            "row": 263
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "fix": null,
          "location": {
            "column": 9,
            "row": 263
          },
          "message": "Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling",
          "noqa_row": 263,
          "url": "https://docs.astral.sh/ruff/rules/raise-without-from-inside-except"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 103,
            "row": 278
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 278
          },
          "message": "Line too long (102 > 88)",
          "noqa_row": 286,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 116,
            "row": 281
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 281
          },
          "message": "Line too long (115 > 88)",
          "noqa_row": 286,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 90,
            "row": 282
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 282
          },
          "message": "Line too long (89 > 88)",
          "noqa_row": 286,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 98,
            "row": 297
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 297
          },
          "message": "Line too long (97 > 88)",
          "noqa_row": 297,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 120,
            "row": 318
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 318
          },
          "message": "Line too long (119 > 88)",
          "noqa_row": 320,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 92,
            "row": 351
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 351
          },
          "message": "Line too long (91 > 88)",
          "noqa_row": 357,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 97,
            "row": 356
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 356
          },
          "message": "Line too long (96 > 88)",
          "noqa_row": 357,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E722",
          "end_location": {
            "column": 11,
            "row": 409
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "fix": null,
          "location": {
            "column": 5,
            "row": 409
          },
          "message": "Do not use bare `except`",
          "noqa_row": 409,
          "url": "https://docs.astral.sh/ruff/rules/bare-except"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 107,
            "row": 532
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 532
          },
          "message": "Line too long (106 > 88)",
          "noqa_row": 532,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 2,
            "row": 13
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\build_dataset.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import argparse\nimport json\nimport logging\nimport os\nfrom typing import Optional\n\nfrom swebench.collect.utils import (\n    Repo,\n    extract_patches,\n    extract_problem_statement_and_hints,\n)\n\n",
                "end_location": {
                  "column": 1,
                  "row": 15
                },
                "location": {
                  "column": 1,
                  "row": 3
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 3
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 3,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 124,
            "row": 183
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\build_dataset.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 183
          },
          "message": "Line too long (123 > 88)",
          "noqa_row": 183,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 110,
            "row": 186
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\build_dataset.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 186
          },
          "message": "Line too long (109 > 88)",
          "noqa_row": 186,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 30,
            "row": 10
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\build_dataset_ft.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import argparse\nimport glob\nimport json\nimport os\nimport random\nfrom datetime import datetime\n\nfrom tqdm import tqdm\n\n\n",
                "end_location": {
                  "column": 1,
                  "row": 13
                },
                "location": {
                  "column": 1,
                  "row": 3
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 3
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 3,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 105,
            "row": 62
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\build_dataset_ft.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 62
          },
          "message": "Line too long (104 > 88)",
          "noqa_row": 62,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 2,
            "row": 15
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import json\nimport logging\nimport os\nimport traceback\nfrom copy import deepcopy\nfrom pathlib import Path\nfrom tempfile import TemporaryDirectory\n\nimport unidiff\nfrom swebench.inference.make_datasets.tokenize_dataset import TOKENIZER_FUNCS\nfrom swebench.inference.make_datasets.utils import (\n    AutoContextManager,\n    ingest_directory_contents,\n)\nfrom tqdm.auto import tqdm\n\n",
                "end_location": {
                  "column": 1,
                  "row": 17
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "W293",
          "end_location": {
            "column": 2,
            "row": 31
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "",
                "end_location": {
                  "column": 2,
                  "row": 31
                },
                "location": {
                  "column": 1,
                  "row": 31
                }
              }
            ],
            "message": "Remove whitespace from blank line"
          },
          "location": {
            "column": 1,
            "row": 31
          },
          "message": "Blank line contains whitespace",
          "noqa_row": 74,
          "url": "https://docs.astral.sh/ruff/rules/blank-line-with-whitespace"
        },
        {
          "cell": null,
          "code": "W293",
          "end_location": {
            "column": 2,
            "row": 32
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "",
                "end_location": {
                  "column": 2,
                  "row": 32
                },
                "location": {
                  "column": 1,
                  "row": 32
                }
              }
            ],
            "message": "Remove whitespace from blank line"
          },
          "location": {
            "column": 1,
            "row": 32
          },
          "message": "Blank line contains whitespace",
          "noqa_row": 74,
          "url": "https://docs.astral.sh/ruff/rules/blank-line-with-whitespace"
        },
        {
          "cell": null,
          "code": "W293",
          "end_location": {
            "column": 2,
            "row": 43
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "",
                "end_location": {
                  "column": 2,
                  "row": 43
                },
                "location": {
                  "column": 1,
                  "row": 43
                }
              }
            ],
            "message": "Remove whitespace from blank line"
          },
          "location": {
            "column": 1,
            "row": 43
          },
          "message": "Blank line contains whitespace",
          "noqa_row": 74,
          "url": "https://docs.astral.sh/ruff/rules/blank-line-with-whitespace"
        },
        {
          "cell": null,
          "code": "W293",
          "end_location": {
            "column": 2,
            "row": 72
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "",
                "end_location": {
                  "column": 2,
                  "row": 72
                },
                "location": {
                  "column": 1,
                  "row": 72
                }
              }
            ],
            "message": "Remove whitespace from blank line"
          },
          "location": {
            "column": 1,
            "row": 72
          },
          "message": "Blank line contains whitespace",
          "noqa_row": 74,
          "url": "https://docs.astral.sh/ruff/rules/blank-line-with-whitespace"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 118,
            "row": 166
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 166
          },
          "message": "Line too long (117 > 88)",
          "noqa_row": 166,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 93,
            "row": 170
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 170
          },
          "message": "Line too long (92 > 88)",
          "noqa_row": 170,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 93,
            "row": 171
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 171
          },
          "message": "Line too long (92 > 88)",
          "noqa_row": 171,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 118,
            "row": 194
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 194
          },
          "message": "Line too long (117 > 88)",
          "noqa_row": 194,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 93,
            "row": 198
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 198
          },
          "message": "Line too long (92 > 88)",
          "noqa_row": 198,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 93,
            "row": 199
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 199
          },
          "message": "Line too long (92 > 88)",
          "noqa_row": 199,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 118,
            "row": 222
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 222
          },
          "message": "Line too long (117 > 88)",
          "noqa_row": 222,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 108,
            "row": 227
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 227
          },
          "message": "Line too long (107 > 88)",
          "noqa_row": 227,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 101,
            "row": 231
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 231
          },
          "message": "Line too long (100 > 88)",
          "noqa_row": 231,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 93,
            "row": 232
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 232
          },
          "message": "Line too long (92 > 88)",
          "noqa_row": 232,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 118,
            "row": 260
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 260
          },
          "message": "Line too long (117 > 88)",
          "noqa_row": 260,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 121,
            "row": 264
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 264
          },
          "message": "Line too long (120 > 88)",
          "noqa_row": 264,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 100,
            "row": 266
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 266
          },
          "message": "Line too long (99 > 88)",
          "noqa_row": 266,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 90,
            "row": 355
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 355
          },
          "message": "Line too long (89 > 88)",
          "noqa_row": 361,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 2,
            "row": 14
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_scripts.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "from swebench.harness.constants import MAP_REPO_TO_EXT\nfrom swebench.harness.test_spec.javascript import (\n    make_eval_script_list_js,\n)\nfrom swebench.harness.test_spec.python import (\n    make_env_script_list_py,\n    make_eval_script_list_py,\n    make_repo_script_list_py,\n)\nfrom swebench.harness.test_spec.utils import (\n    make_env_script_list_common,\n    make_eval_script_list_common,\n    make_repo_script_list_common,\n)\n\n\n",
                "end_location": {
                  "column": 1,
                  "row": 17
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 78,
            "row": 19
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_text_dataset.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import json\nimport logging\nimport os\nfrom argparse import ArgumentParser\nfrom pathlib import Path\n\nfrom datasets import Dataset, DatasetDict, load_dataset, load_from_disk\nfrom swebench.inference.make_datasets.create_instance import (\n    PROMPT_FUNCTIONS,\n    add_text_inputs,\n)\nfrom swebench.inference.make_datasets.tokenize_dataset import TOKENIZER_FUNCS\nfrom tqdm.auto import tqdm\n\n",
                "end_location": {
                  "column": 1,
                  "row": 21
                },
                "location": {
                  "column": 1,
                  "row": 7
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 7
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 7,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E721",
          "end_location": {
            "column": 29,
            "row": 26
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_text_dataset.py",
          "fix": null,
          "location": {
            "column": 8,
            "row": 26
          },
          "message": "Use `is` and `is not` for type comparisons, or `isinstance()` for isinstance checks",
          "noqa_row": 26,
          "url": "https://docs.astral.sh/ruff/rules/type-comparison"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 106,
            "row": 147
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_text_dataset.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 147
          },
          "message": "Line too long (105 > 88)",
          "noqa_row": 147,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 181,
            "row": 223
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_text_dataset.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 223
          },
          "message": "Line too long (180 > 88)",
          "noqa_row": 223,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 107,
            "row": 262
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_text_dataset.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 262
          },
          "message": "Line too long (106 > 88)",
          "noqa_row": 262,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 99,
            "row": 313
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_text_dataset.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 313
          },
          "message": "Line too long (98 > 88)",
          "noqa_row": 313,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 92,
            "row": 318
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_text_dataset.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 318
          },
          "message": "Line too long (91 > 88)",
          "noqa_row": 318,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 29,
            "row": 5
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\criteria.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import re\n\nimport requests\nfrom swebench.collect.utils import PR_KEYWORDS\nfrom unidiff import PatchSet\n\n\n",
                "end_location": {
                  "column": 1,
                  "row": 8
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 92,
            "row": 24
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\criteria.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 24
          },
          "message": "Line too long (91 > 88)",
          "noqa_row": 25,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 112,
            "row": 29
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\criteria.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 29
          },
          "message": "Line too long (111 > 88)",
          "noqa_row": 29,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 97,
            "row": 79
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\criteria.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 79
          },
          "message": "Line too long (96 > 88)",
          "noqa_row": 80,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 90,
            "row": 117
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\criteria.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 117
          },
          "message": "Line too long (89 > 88)",
          "noqa_row": 118,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 110,
            "row": 1
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 1
          },
          "message": "Line too long (109 > 88)",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 44,
            "row": 10
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import re\nimport subprocess\nfrom collections.abc import Callable\nfrom dataclasses import asdict, dataclass\n\nfrom jinja2 import Template\nfrom minisweagent import Environment, Model\n\n\n",
                "end_location": {
                  "column": 1,
                  "row": 13
                },
                "location": {
                  "column": 1,
                  "row": 3
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 3
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 3,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 121,
            "row": 15
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 15
          },
          "message": "Line too long (120 > 88)",
          "noqa_row": 15,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 94,
            "row": 18
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 18
          },
          "message": "Line too long (93 > 88)",
          "noqa_row": 18,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 120,
            "row": 19
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 19
          },
          "message": "Line too long (119 > 88)",
          "noqa_row": 19,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 100,
            "row": 22
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 22
          },
          "message": "Line too long (99 > 88)",
          "noqa_row": 22,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 95,
            "row": 24
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 24
          },
          "message": "Line too long (94 > 88)",
          "noqa_row": 24,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 97,
            "row": 26
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 26
          },
          "message": "Line too long (96 > 88)",
          "noqa_row": 26,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 107,
            "row": 57
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 57
          },
          "message": "Line too long (106 > 88)",
          "noqa_row": 57,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 108,
            "row": 65
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 65
          },
          "message": "Line too long (107 > 88)",
          "noqa_row": 65,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 96,
            "row": 66
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 66
          },
          "message": "Line too long (95 > 88)",
          "noqa_row": 66,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 110,
            "row": 92
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 92
          },
          "message": "Line too long (109 > 88)",
          "noqa_row": 92,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 99,
            "row": 101
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 101
          },
          "message": "Line too long (98 > 88)",
          "noqa_row": 101,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 100,
            "row": 110
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 110
          },
          "message": "Line too long (99 > 88)",
          "noqa_row": 110,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "B904",
          "end_location": {
            "column": 14,
            "row": 119
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 13,
            "row": 117
          },
          "message": "Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling",
          "noqa_row": 117,
          "url": "https://docs.astral.sh/ruff/rules/raise-without-from-inside-except"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 97,
            "row": 118
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 118
          },
          "message": "Line too long (96 > 88)",
          "noqa_row": 118,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "B904",
          "end_location": {
            "column": 118,
            "row": 121
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 13,
            "row": 121
          },
          "message": "Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling",
          "noqa_row": 121,
          "url": "https://docs.astral.sh/ruff/rules/raise-without-from-inside-except"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 118,
            "row": 121
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 121
          },
          "message": "Line too long (117 > 88)",
          "noqa_row": 121,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 95,
            "row": 126
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 126
          },
          "message": "Line too long (94 > 88)",
          "noqa_row": 126,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 115,
            "row": 128
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 128
          },
          "message": "Line too long (114 > 88)",
          "noqa_row": 128,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 33,
            "row": 12
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\distributed_attention.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "from typing import Any\n\nimport torch\nimport torch.distributed as dist\nfrom torch import Tensor\nfrom torch.nn import Module\n\n\n",
                "end_location": {
                  "column": 1,
                  "row": 15
                },
                "location": {
                  "column": 1,
                  "row": 6
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 6
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 6,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 63,
            "row": 24
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "from __future__ import annotations\n\nimport logging\nimport sys\nimport traceback\nfrom pathlib import Path\n\nimport docker\nimport docker.errors\nfrom swebench.harness.constants import (\n    BASE_IMAGE_BUILD_DIR,\n    DOCKER_USER,\n    ENV_IMAGE_BUILD_DIR,\n    INSTANCE_IMAGE_BUILD_DIR,\n    UTF8,\n)\nfrom swebench.harness.docker_utils import cleanup_container, remove_image\nfrom swebench.harness.test_spec.test_spec import (\n    TestSpec,\n    get_test_specs_from_dataset,\n    make_test_spec,\n)\nfrom swebench.harness.utils import ansi_escape, run_threadpool\n\n\n",
                "end_location": {
                  "column": 1,
                  "row": 27
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "B010",
          "end_location": {
            "column": 42,
            "row": 58
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "logger.log_file = log_file",
                "end_location": {
                  "column": 42,
                  "row": 58
                },
                "location": {
                  "column": 5,
                  "row": 58
                }
              }
            ],
            "message": "Replace `setattr` with assignment"
          },
          "location": {
            "column": 5,
            "row": 58
          },
          "message": "Do not call `setattr` with a constant attribute value. It is not any safer than normal property access.",
          "noqa_row": 58,
          "url": "https://docs.astral.sh/ruff/rules/set-attr-with-constant"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 107,
            "row": 94
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 94
          },
          "message": "Line too long (106 > 88)",
          "noqa_row": 96,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 90,
            "row": 125
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 125
          },
          "message": "Line too long (89 > 88)",
          "noqa_row": 125,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 93,
            "row": 176
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 176
          },
          "message": "Line too long (92 > 88)",
          "noqa_row": 177,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 97,
            "row": 223
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 223
          },
          "message": "Line too long (96 > 88)",
          "noqa_row": 229,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "F841",
          "end_location": {
            "column": 23,
            "row": 246
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "",
                "end_location": {
                  "column": 26,
                  "row": 246
                },
                "location": {
                  "column": 13,
                  "row": 246
                }
              }
            ],
            "message": "Remove assignment to unused variable `base_image`"
          },
          "location": {
            "column": 13,
            "row": 246
          },
          "message": "Local variable `base_image` is assigned to but never used",
          "noqa_row": 246,
          "url": "https://docs.astral.sh/ruff/rules/unused-variable"
        },
        {
          "cell": null,
          "code": "B904",
          "end_location": {
            "column": 14,
            "row": 251
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": null,
          "location": {
            "column": 13,
            "row": 248
          },
          "message": "Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling",
          "noqa_row": 248,
          "url": "https://docs.astral.sh/ruff/rules/raise-without-from-inside-except"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 100,
            "row": 249
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 249
          },
          "message": "Line too long (99 > 88)",
          "noqa_row": 249,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "F841",
          "end_location": {
            "column": 22,
            "row": 256
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "",
                "end_location": {
                  "column": 25,
                  "row": 256
                },
                "location": {
                  "column": 13,
                  "row": 256
                }
              }
            ],
            "message": "Remove assignment to unused variable `env_image`"
          },
          "location": {
            "column": 13,
            "row": 256
          },
          "message": "Local variable `env_image` is assigned to but never used",
          "noqa_row": 256,
          "url": "https://docs.astral.sh/ruff/rules/unused-variable"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 93,
            "row": 285
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 285
          },
          "message": "Line too long (92 > 88)",
          "noqa_row": 287,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 93,
            "row": 351
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 351
          },
          "message": "Line too long (92 > 88)",
          "noqa_row": 353,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "F841",
          "end_location": {
            "column": 18,
            "row": 430
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "",
                "end_location": {
                  "column": 21,
                  "row": 430
                },
                "location": {
                  "column": 9,
                  "row": 430
                }
              }
            ],
            "message": "Remove assignment to unused variable `env_image`"
          },
          "location": {
            "column": 9,
            "row": 430
          },
          "message": "Local variable `env_image` is assigned to but never used",
          "noqa_row": 430,
          "url": "https://docs.astral.sh/ruff/rules/unused-variable"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 94,
            "row": 479
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 479
          },
          "message": "Line too long (93 > 88)",
          "noqa_row": 488,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 96,
            "row": 483
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 483
          },
          "message": "Line too long (95 > 88)",
          "noqa_row": 488,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 91,
            "row": 487
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 487
          },
          "message": "Line too long (90 > 88)",
          "noqa_row": 488,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "B904",
          "end_location": {
            "column": 18,
            "row": 505
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": null,
          "location": {
            "column": 17,
            "row": 503
          },
          "message": "Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling",
          "noqa_row": 503,
          "url": "https://docs.astral.sh/ruff/rules/raise-without-from-inside-except"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 95,
            "row": 504
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_build.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 504
          },
          "message": "Line too long (94 > 88)",
          "noqa_row": 504,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 47,
            "row": 13
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_utils.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "from __future__ import annotations\n\nimport os\nimport signal\nimport tarfile\nimport threading\nimport time\nimport traceback\nfrom pathlib import Path\n\nimport docker\nimport docker.errors\nfrom docker.models.containers import Container\n\n",
                "end_location": {
                  "column": 1,
                  "row": 15
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E731",
          "end_location": {
            "column": 34,
            "row": 80
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_utils.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "def log_info(x):\n            return None",
                "end_location": {
                  "column": 34,
                  "row": 80
                },
                "location": {
                  "column": 9,
                  "row": 80
                }
              }
            ],
            "message": "Rewrite `log_info` as a `def`"
          },
          "location": {
            "column": 9,
            "row": 80
          },
          "message": "Do not assign a `lambda` expression, use a `def`",
          "noqa_row": 80,
          "url": "https://docs.astral.sh/ruff/rules/lambda-assignment"
        },
        {
          "cell": null,
          "code": "E731",
          "end_location": {
            "column": 35,
            "row": 81
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_utils.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "def log_error(x):\n            return None",
                "end_location": {
                  "column": 35,
                  "row": 81
                },
                "location": {
                  "column": 9,
                  "row": 81
                }
              }
            ],
            "message": "Rewrite `log_error` as a `def`"
          },
          "location": {
            "column": 9,
            "row": 81
          },
          "message": "Do not assign a `lambda` expression, use a `def`",
          "noqa_row": 81,
          "url": "https://docs.astral.sh/ruff/rules/lambda-assignment"
        },
        {
          "cell": null,
          "code": "E731",
          "end_location": {
            "column": 34,
            "row": 122
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_utils.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "def log_info(x):\n            return None",
                "end_location": {
                  "column": 34,
                  "row": 122
                },
                "location": {
                  "column": 9,
                  "row": 122
                }
              }
            ],
            "message": "Rewrite `log_info` as a `def`"
          },
          "location": {
            "column": 9,
            "row": 122
          },
          "message": "Do not assign a `lambda` expression, use a `def`",
          "noqa_row": 122,
          "url": "https://docs.astral.sh/ruff/rules/lambda-assignment"
        },
        {
          "cell": null,
          "code": "E731",
          "end_location": {
            "column": 35,
            "row": 123
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_utils.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "def log_error(x):\n            return None",
                "end_location": {
                  "column": 35,
                  "row": 123
                },
                "location": {
                  "column": 9,
                  "row": 123
                }
              }
            ],
            "message": "Rewrite `log_error` as a `def`"
          },
          "location": {
            "column": 9,
            "row": 123
          },
          "message": "Do not assign a `lambda` expression, use a `def`",
          "noqa_row": 123,
          "url": "https://docs.astral.sh/ruff/rules/lambda-assignment"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 92,
            "row": 138
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_utils.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 138
          },
          "message": "Line too long (91 > 88)",
          "noqa_row": 138,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 110,
            "row": 276
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_utils.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 276
          },
          "message": "Line too long (109 > 88)",
          "noqa_row": 280,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 109,
            "row": 277
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_utils.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 277
          },
          "message": "Line too long (108 > 88)",
          "noqa_row": 280,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 109,
            "row": 278
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\docker_utils.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 278
          },
          "message": "Line too long (108 > 88)",
          "noqa_row": 280,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 176,
            "row": 3
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\eval_retrieval.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 3
          },
          "message": "Line too long (175 > 88)",
          "noqa_row": 3,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 15,
            "row": 9
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\eval_retrieval.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import logging\nimport re\nfrom argparse import ArgumentParser\n\nimport numpy as np\nfrom datasets import disable_caching, load_dataset, load_from_disk\n\n",
                "end_location": {
                  "column": 1,
                  "row": 11
                },
                "location": {
                  "column": 1,
                  "row": 5
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 5
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 5,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E722",
          "end_location": {
            "column": 11,
            "row": 21
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\eval_retrieval.py",
          "fix": null,
          "location": {
            "column": 5,
            "row": 21
          },
          "message": "Do not use bare `except`",
          "noqa_row": 21,
          "url": "https://docs.astral.sh/ruff/rules/bare-except"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 61,
            "row": 12
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_tasks_pipeline.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import argparse\nimport os\nimport traceback\nfrom multiprocessing import Pool\n\nfrom dotenv import load_dotenv\nfrom swebench.collect.build_dataset import main as build_dataset\nfrom swebench.collect.print_pulls import main as print_pulls\n\n",
                "end_location": {
                  "column": 1,
                  "row": 15
                },
                "location": {
                  "column": 1,
                  "row": 5
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 5
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 5,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 95,
            "row": 75
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_tasks_pipeline.py",
          "fix": null,
          "location": {
            "column": 88,
            "row": 75
          },
          "message": "Line too long (95 > 88)",
          "noqa_row": 75,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 89,
            "row": 83
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_tasks_pipeline.py",
          "fix": null,
          "location": {
            "column": 88,
            "row": 83
          },
          "message": "Line too long (89 > 88)",
          "noqa_row": 83,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 98,
            "row": 87
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_tasks_pipeline.py",
          "fix": null,
          "location": {
            "column": 88,
            "row": 87
          },
          "message": "Line too long (98 > 88)",
          "noqa_row": 87,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 92,
            "row": 121
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_tasks_pipeline.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 121
          },
          "message": "Line too long (91 > 88)",
          "noqa_row": 121,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "B905",
          "end_location": {
            "column": 57,
            "row": 135
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_tasks_pipeline.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": ", strict=False",
                "end_location": {
                  "column": 56,
                  "row": 135
                },
                "location": {
                  "column": 56,
                  "row": 135
                }
              }
            ],
            "message": "Add explicit value for parameter `strict=`"
          },
          "location": {
            "column": 29,
            "row": 135
          },
          "message": "`zip()` without an explicit `strict=` parameter",
          "noqa_row": 135,
          "url": "https://docs.astral.sh/ruff/rules/zip-without-explicit-strict"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 94,
            "row": 147
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_tasks_pipeline.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 147
          },
          "message": "Line too long (93 > 88)",
          "noqa_row": 147,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 44,
            "row": 10
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_top_pypi.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import argparse\nimport json\nimport os\n\nfrom bs4 import BeautifulSoup\nfrom ghapi.core import GhApi\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\n\n",
                "end_location": {
                  "column": 1,
                  "row": 13
                },
                "location": {
                  "column": 1,
                  "row": 3
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 3
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 3,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E722",
          "end_location": {
            "column": 23,
            "row": 74
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_top_pypi.py",
          "fix": null,
          "location": {
            "column": 17,
            "row": 74
          },
          "message": "Do not use bare `except`",
          "noqa_row": 74,
          "url": "https://docs.astral.sh/ruff/rules/bare-except"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 69,
            "row": 17
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import argparse\nimport glob\nimport json\nimport logging\nimport os\nimport re\nimport subprocess\nfrom multiprocessing import Manager, Pool\n\nimport requests\nfrom swebench.versioning.constants import (\n    MAP_REPO_TO_VERSION_PATHS,\n    MAP_REPO_TO_VERSION_PATTERNS,\n    SWE_BENCH_URL_RAW,\n)\nfrom swebench.versioning.utils import get_instances, split_instances\n\n",
                "end_location": {
                  "column": 1,
                  "row": 19
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E731",
          "end_location": {
            "column": 73,
            "row": 76
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "def keep_major_minor(x, sep):\n        return \".\".join(x.strip().split(sep)[:2])",
                "end_location": {
                  "column": 73,
                  "row": 76
                },
                "location": {
                  "column": 5,
                  "row": 76
                }
              }
            ],
            "message": "Rewrite `keep_major_minor` as a `def`"
          },
          "location": {
            "column": 5,
            "row": 76
          },
          "message": "Do not assign a `lambda` expression, use a `def`",
          "noqa_row": 76,
          "url": "https://docs.astral.sh/ruff/rules/lambda-assignment"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 111,
            "row": 265
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 265
          },
          "message": "Line too long (110 > 88)",
          "noqa_row": 265,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 93,
            "row": 268
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 268
          },
          "message": "Line too long (92 > 88)",
          "noqa_row": 268,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 129,
            "row": 304
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 304
          },
          "message": "Line too long (128 > 88)",
          "noqa_row": 304,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 93,
            "row": 327
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 327
          },
          "message": "Line too long (92 > 88)",
          "noqa_row": 327,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 103,
            "row": 333
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 333
          },
          "message": "Line too long (102 > 88)",
          "noqa_row": 333,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 30,
            "row": 7
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_astropy.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import json\nimport os\nimport re\nimport sys\nfrom datetime import datetime\n\nimport requests\n\n",
                "end_location": {
                  "column": 1,
                  "row": 9
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E731",
          "end_location": {
            "column": 69,
            "row": 27
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_astropy.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "def keep_major_minor(x, sep):\n    return \".\".join(x.strip().split(sep)[:2])",
                "end_location": {
                  "column": 69,
                  "row": 27
                },
                "location": {
                  "column": 1,
                  "row": 27
                }
              }
            ],
            "message": "Rewrite `keep_major_minor` as a `def`"
          },
          "location": {
            "column": 1,
            "row": 27
          },
          "message": "Do not assign a `lambda` expression, use a `def`",
          "noqa_row": 27,
          "url": "https://docs.astral.sh/ruff/rules/lambda-assignment"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 30,
            "row": 7
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_matplotlib.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import json\nimport os\nimport re\nimport sys\nfrom datetime import datetime\n\nimport requests\n\n",
                "end_location": {
                  "column": 1,
                  "row": 9
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 120,
            "row": 19
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_matplotlib.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 19
          },
          "message": "Line too long (119 > 88)",
          "noqa_row": 19,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E731",
          "end_location": {
            "column": 69,
            "row": 25
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_matplotlib.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "def keep_major_minor(x, sep):\n    return \".\".join(x.strip().split(sep)[:2])",
                "end_location": {
                  "column": 69,
                  "row": 25
                },
                "location": {
                  "column": 1,
                  "row": 25
                }
              }
            ],
            "message": "Rewrite `keep_major_minor` as a `def`"
          },
          "location": {
            "column": 1,
            "row": 25
          },
          "message": "Do not assign a `lambda` expression, use a `def`",
          "noqa_row": 25,
          "url": "https://docs.astral.sh/ruff/rules/lambda-assignment"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 30,
            "row": 6
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_pvlib-python.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import json\nimport re\nimport sys\nfrom datetime import datetime\n\nimport requests\n\n",
                "end_location": {
                  "column": 1,
                  "row": 8
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E731",
          "end_location": {
            "column": 69,
            "row": 28
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_pvlib-python.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "def keep_major_minor(x, sep):\n    return \".\".join(x.strip().split(sep)[:2])",
                "end_location": {
                  "column": 69,
                  "row": 28
                },
                "location": {
                  "column": 1,
                  "row": 28
                }
              }
            ],
            "message": "Rewrite `keep_major_minor` as a `def`"
          },
          "location": {
            "column": 1,
            "row": 28
          },
          "message": "Do not assign a `lambda` expression, use a `def`",
          "noqa_row": 28,
          "url": "https://docs.astral.sh/ruff/rules/lambda-assignment"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 30,
            "row": 5
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_pydicom.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import datetime\nimport json\nimport sys\n\nimport requests\nfrom bs4 import BeautifulSoup\n\n",
                "end_location": {
                  "column": 1,
                  "row": 7
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 29,
            "row": 5
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_sqlfluff.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import json\nimport os\nimport re\nimport sys\n\nfrom ghapi.core import GhApi\n\n",
                "end_location": {
                  "column": 1,
                  "row": 7
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E711",
          "end_location": {
            "column": 26,
            "row": 56
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_sqlfluff.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "pair_rv[0] is None",
                "end_location": {
                  "column": 26,
                  "row": 56
                },
                "location": {
                  "column": 8,
                  "row": 56
                }
              }
            ],
            "message": "Replace with `cond is None`"
          },
          "location": {
            "column": 22,
            "row": 56
          },
          "message": "Comparison to `None` should be `cond is None`",
          "noqa_row": 56,
          "url": "https://docs.astral.sh/ruff/rules/none-comparison"
        },
        {
          "cell": null,
          "code": "E711",
          "end_location": {
            "column": 41,
            "row": 61
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_sqlfluff.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "pair_rv[1] is None",
                "end_location": {
                  "column": 41,
                  "row": 61
                },
                "location": {
                  "column": 23,
                  "row": 61
                }
              }
            ],
            "message": "Replace with `cond is None`"
          },
          "location": {
            "column": 37,
            "row": 61
          },
          "message": "Comparison to `None` should be `cond is None`",
          "noqa_row": 61,
          "url": "https://docs.astral.sh/ruff/rules/none-comparison"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 30,
            "row": 7
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_xarray.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import json\nimport os\nimport re\nimport sys\nfrom datetime import datetime\n\nimport requests\n\n",
                "end_location": {
                  "column": 1,
                  "row": 9
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E731",
          "end_location": {
            "column": 69,
            "row": 28
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_xarray.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "def keep_major_minor(x, sep):\n    return \".\".join(x.strip().split(sep)[:2])",
                "end_location": {
                  "column": 69,
                  "row": 28
                },
                "location": {
                  "column": 1,
                  "row": 28
                }
              }
            ],
            "message": "Rewrite `keep_major_minor` as a `def`"
          },
          "location": {
            "column": 1,
            "row": 28
          },
          "message": "Do not assign a `lambda` expression, use a `def`",
          "noqa_row": 28,
          "url": "https://docs.astral.sh/ruff/rules/lambda-assignment"
        },
        {
          "cell": null,
          "code": "E722",
          "end_location": {
            "column": 15,
            "row": 40
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_xarray.py",
          "fix": null,
          "location": {
            "column": 9,
            "row": 40
          },
          "message": "Do not use bare `except`",
          "noqa_row": 40,
          "url": "https://docs.astral.sh/ruff/rules/bare-except"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 58,
            "row": 3
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\go.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import re\n\nfrom swebench.harness.constants import TestStatus\nfrom swebench.harness.test_spec.test_spec import TestSpec\n\n\n",
                "end_location": {
                  "column": 1,
                  "row": 6
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 60,
            "row": 23
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\grading.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "from typing import Any\n\nfrom swebench.harness.constants import (\n    APPLY_PATCH_FAIL,\n    END_TEST_OUTPUT,\n    FAIL_ONLY_REPOS,\n    FAIL_TO_FAIL,\n    FAIL_TO_PASS,\n    KEY_INSTANCE_ID,\n    KEY_PREDICTION,\n    MAP_REPO_VERSION_TO_SPECS,\n    PASS_TO_FAIL,\n    PASS_TO_PASS,\n    RESET_FAILED,\n    START_TEST_OUTPUT,\n    TESTS_ERROR,\n    TESTS_TIMEOUT,\n    EvalType,\n    ResolvedStatus,\n    TestStatus,\n)\nfrom swebench.harness.log_parsers import MAP_REPO_TO_PARSER\nfrom swebench.harness.test_spec.test_spec import TestSpec\n\n\n",
                "end_location": {
                  "column": 1,
                  "row": 26
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 103,
            "row": 88
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\grading.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 88
          },
          "message": "Line too long (102 > 88)",
          "noqa_row": 88,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 99,
            "row": 221
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\grading.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 221
          },
          "message": "Line too long (98 > 88)",
          "noqa_row": 223,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 102,
            "row": 246
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\grading.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 246
          },
          "message": "Line too long (101 > 88)",
          "noqa_row": 252,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 109,
            "row": 247
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\grading.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 247
          },
          "message": "Line too long (108 > 88)",
          "noqa_row": 252,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 103,
            "row": 249
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\grading.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 249
          },
          "message": "Line too long (102 > 88)",
          "noqa_row": 252,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 58,
            "row": 3
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\java.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import re\n\nfrom swebench.harness.constants import TestStatus\nfrom swebench.harness.test_spec.test_spec import TestSpec\n\n\n",
                "end_location": {
                  "column": 1,
                  "row": 6
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 29,
            "row": 10
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\javascript.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import json\nimport re\nfrom pathlib import Path\n\nfrom swebench.harness.constants import (\n    END_TEST_OUTPUT,\n    START_TEST_OUTPUT,\n)\nfrom swebench.harness.test_spec.utils import make_eval_script_list_common\nfrom unidiff import PatchSet\n\n\n",
                "end_location": {
                  "column": 1,
                  "row": 13
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 101,
            "row": 34
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\javascript.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 34
          },
          "message": "Line too long (100 > 88)",
          "noqa_row": 34,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 103,
            "row": 49
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\javascript.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 49
          },
          "message": "Line too long (102 > 88)",
          "noqa_row": 49,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 64,
            "row": 12
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\make_lite.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "from datasets import DatasetDict, disable_caching, load_dataset\n\nfrom criteria import (\n    contains_git_commit_hash,\n    contains_hyperlinks,\n    contains_image,\n    contains_issue_reference,\n    contains_non_modified_files,\n    contains_pytest_match_arg,\n    leq_n_files,\n    leq_n_hunks,\n    leq_n_words,\n)\n\n",
                "end_location": {
                  "column": 1,
                  "row": 14
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 59,
            "row": 44
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "from typing import Any, Optional, Union\n\nimport torch\nimport torch.distributed as dist\nimport torch.nn.functional as F\nimport torch.utils.checkpoint\nfrom flash_attn import flash_attn_kvpacked_func, flash_attn_varlen_kvpacked_func\nfrom flash_attn.bert_padding import pad_input, unpad_input\nfrom swebench.inference.llamao.distributed_attention import DistributedAttention\nfrom torch import nn\nfrom torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\nfrom transformers import GenerationMixin\nfrom transformers.activations import ACT2FN\nfrom transformers.modeling_outputs import (\n    BaseModelOutputWithPast,\n    CausalLMOutputWithPast,\n    SequenceClassifierOutputWithPast,\n)\nfrom transformers.modeling_utils import PreTrainedModel\nfrom transformers.models.llama.configuration_llama import LlamaConfig\nfrom transformers.utils import logging\n\n",
                "end_location": {
                  "column": 1,
                  "row": 46
                },
                "location": {
                  "column": 1,
                  "row": 21
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 21
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 21,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "B904",
          "end_location": {
            "column": 6,
            "row": 51
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 5,
            "row": 49
          },
          "message": "Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling",
          "noqa_row": 49,
          "url": "https://docs.astral.sh/ruff/rules/raise-without-from-inside-except"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 92,
            "row": 112
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 112
          },
          "message": "Line too long (91 > 88)",
          "noqa_row": 125,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 91,
            "row": 114
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 114
          },
          "message": "Line too long (90 > 88)",
          "noqa_row": 125,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 92,
            "row": 116
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 116
          },
          "message": "Line too long (91 > 88)",
          "noqa_row": 125,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 94,
            "row": 117
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 117
          },
          "message": "Line too long (93 > 88)",
          "noqa_row": 125,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 90,
            "row": 118
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 118
          },
          "message": "Line too long (89 > 88)",
          "noqa_row": 125,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 93,
            "row": 120
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 120
          },
          "message": "Line too long (92 > 88)",
          "noqa_row": 125,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 98,
            "row": 170
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 170
          },
          "message": "Line too long (97 > 88)",
          "noqa_row": 170,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 98,
            "row": 171
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 171
          },
          "message": "Line too long (97 > 88)",
          "noqa_row": 171,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 101,
            "row": 172
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 172
          },
          "message": "Line too long (100 > 88)",
          "noqa_row": 172,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 101,
            "row": 176
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 176
          },
          "message": "Line too long (100 > 88)",
          "noqa_row": 176,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 94,
            "row": 177
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 177
          },
          "message": "Line too long (93 > 88)",
          "noqa_row": 177,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 96,
            "row": 218
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 218
          },
          "message": "Line too long (95 > 88)",
          "noqa_row": 220,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "B011",
          "end_location": {
            "column": 25,
            "row": 251
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "raise AssertionError()",
                "end_location": {
                  "column": 25,
                  "row": 251
                },
                "location": {
                  "column": 13,
                  "row": 251
                }
              }
            ],
            "message": "Replace `assert False`"
          },
          "location": {
            "column": 20,
            "row": 251
          },
          "message": "Do not `assert False` (`python -O` removes these calls), raise `AssertionError()`",
          "noqa_row": 251,
          "url": "https://docs.astral.sh/ruff/rules/assert-false"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 114,
            "row": 272
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 272
          },
          "message": "Line too long (113 > 88)",
          "noqa_row": 274,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 93,
            "row": 273
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 273
          },
          "message": "Line too long (92 > 88)",
          "noqa_row": 274,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 101,
            "row": 300
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 300
          },
          "message": "Line too long (100 > 88)",
          "noqa_row": 300,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 95,
            "row": 368
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 368
          },
          "message": "Line too long (94 > 88)",
          "noqa_row": 368,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 113,
            "row": 412
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 412
          },
          "message": "Line too long (112 > 88)",
          "noqa_row": 412,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 94,
            "row": 425
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 425
          },
          "message": "Line too long (93 > 88)",
          "noqa_row": 425,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 107,
            "row": 490
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 490
          },
          "message": "Line too long (106 > 88)",
          "noqa_row": 500,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 115,
            "row": 492
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 492
          },
          "message": "Line too long (114 > 88)",
          "noqa_row": 500,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 112,
            "row": 494
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 494
          },
          "message": "Line too long (111 > 88)",
          "noqa_row": 500,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 119,
            "row": 497
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 497
          },
          "message": "Line too long (118 > 88)",
          "noqa_row": 500,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 113,
            "row": 499
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 499
          },
          "message": "Line too long (112 > 88)",
          "noqa_row": 500,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 111,
            "row": 561
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 561
          },
          "message": "Line too long (110 > 88)",
          "noqa_row": 565,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 103,
            "row": 622
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 622
          },
          "message": "Line too long (102 > 88)",
          "noqa_row": 622,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 113,
            "row": 644
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 644
          },
          "message": "Line too long (112 > 88)",
          "noqa_row": 644,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 94,
            "row": 785
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 785
          },
          "message": "Line too long (93 > 88)",
          "noqa_row": 807,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 110,
            "row": 786
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 786
          },
          "message": "Line too long (109 > 88)",
          "noqa_row": 807,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 119,
            "row": 787
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 787
          },
          "message": "Line too long (118 > 88)",
          "noqa_row": 807,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 113,
            "row": 788
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 788
          },
          "message": "Line too long (112 > 88)",
          "noqa_row": 807,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 114,
            "row": 805
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 805
          },
          "message": "Line too long (113 > 88)",
          "noqa_row": 807,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 97,
            "row": 806
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 806
          },
          "message": "Line too long (96 > 88)",
          "noqa_row": 807,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 109,
            "row": 852
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 852
          },
          "message": "Line too long (108 > 88)",
          "noqa_row": 852,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 93,
            "row": 886
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 886
          },
          "message": "Line too long (92 > 88)",
          "noqa_row": 886,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 109,
            "row": 950
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 950
          },
          "message": "Line too long (108 > 88)",
          "noqa_row": 953,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 118,
            "row": 951
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 951
          },
          "message": "Line too long (117 > 88)",
          "noqa_row": 953,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 58,
            "row": 3
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\php.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import re\n\nfrom swebench.harness.constants import TestStatus\nfrom swebench.harness.test_spec.test_spec import TestSpec\n\n\n",
                "end_location": {
                  "column": 1,
                  "row": 6
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 81,
            "row": 10
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\prepare_images.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import resource\nfrom argparse import ArgumentParser\n\nimport docker\nfrom swebench.harness.constants import KEY_INSTANCE_ID\nfrom swebench.harness.docker_build import build_instance_images\nfrom swebench.harness.docker_utils import list_images\nfrom swebench.harness.test_spec.test_spec import make_test_spec\nfrom swebench.harness.utils import load_swebench_dataset, optional_str, str2bool\n\n\n",
                "end_location": {
                  "column": 1,
                  "row": 13
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 100,
            "row": 50
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\prepare_images.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 50
          },
          "message": "Line too long (99 > 88)",
          "noqa_row": 50,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 138,
            "row": 3
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\print_pulls.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 3
          },
          "message": "Line too long (137 > 88)",
          "noqa_row": 3,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 28,
            "row": 15
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\print_pulls.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "from __future__ import annotations\n\nimport argparse\nimport json\nimport logging\nimport os\nfrom datetime import datetime\nfrom typing import Optional\n\nfrom fastcore.xtras import obj2dict\nfrom swebench.collect.utils import Repo\n\n",
                "end_location": {
                  "column": 1,
                  "row": 17
                },
                "location": {
                  "column": 1,
                  "row": 5
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 5
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 5,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "B010",
          "end_location": {
            "column": 81,
            "row": 44
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\print_pulls.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "pull.resolved_issues = repo.extract_resolved_issues(pull)",
                "end_location": {
                  "column": 81,
                  "row": 44
                },
                "location": {
                  "column": 13,
                  "row": 44
                }
              }
            ],
            "message": "Replace `setattr` with assignment"
          },
          "location": {
            "column": 13,
            "row": 44
          },
          "message": "Do not call `setattr` with a constant attribute value. It is not any safer than normal property access.",
          "noqa_row": 44,
          "url": "https://docs.astral.sh/ruff/rules/set-attr-with-constant"
        },
        {
          "cell": null,
          "code": "B010",
          "end_location": {
            "column": 73,
            "row": 77
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\print_pulls.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "pull.resolved_issues = repo.extract_resolved_issues(pull)",
                "end_location": {
                  "column": 73,
                  "row": 77
                },
                "location": {
                  "column": 5,
                  "row": 77
                }
              }
            ],
            "message": "Replace `setattr` with assignment"
          },
          "location": {
            "column": 5,
            "row": 77
          },
          "message": "Do not call `setattr` with a constant attribute value. It is not any safer than normal property access.",
          "noqa_row": 77,
          "url": "https://docs.astral.sh/ruff/rules/set-attr-with-constant"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 28,
            "row": 19
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import os\nimport posixpath\nimport re\nfrom functools import cache\n\nimport requests\nfrom swebench.harness.constants import (\n    END_TEST_OUTPUT,\n    MAP_REPO_TO_ENV_YML_PATHS,\n    MAP_REPO_TO_INSTALL,\n    MAP_REPO_TO_REQS_PATHS,\n    MAP_REPO_VERSION_TO_SPECS,\n    NON_TEST_EXTS,\n    REPO_BASE_COMMIT_BRANCH,\n    START_TEST_OUTPUT,\n    SWE_BENCH_URL_RAW,\n    SWEbenchInstance,\n)\nfrom swebench.harness.utils import get_modified_files, load_cached_environment_yml\n\n",
                "end_location": {
                  "column": 1,
                  "row": 21
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 142,
            "row": 22
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 22
          },
          "message": "Line too long (141 > 88)",
          "noqa_row": 22,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 124,
            "row": 40
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 40
          },
          "message": "Line too long (123 > 88)",
          "noqa_row": 40,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "F841",
          "end_location": {
            "column": 19,
            "row": 75
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "",
                "end_location": {
                  "column": 22,
                  "row": 75
                },
                "location": {
                  "column": 5,
                  "row": 75
                }
              }
            ],
            "message": "Remove assignment to unused variable `pip_line_start`"
          },
          "location": {
            "column": 5,
            "row": 75
          },
          "message": "Local variable `pip_line_start` is assigned to but never used",
          "noqa_row": 75,
          "url": "https://docs.astral.sh/ruff/rules/unused-variable"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 91,
            "row": 79
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 79
          },
          "message": "Line too long (90 > 88)",
          "noqa_row": 79,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E741",
          "end_location": {
            "column": 33,
            "row": 90
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": null,
          "location": {
            "column": 32,
            "row": 90
          },
          "message": "Ambiguous variable name: `l`",
          "noqa_row": 90,
          "url": "https://docs.astral.sh/ruff/rules/ambiguous-variable-name"
        },
        {
          "cell": null,
          "code": "E711",
          "end_location": {
            "column": 31,
            "row": 99
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "replacement is None",
                "end_location": {
                  "column": 31,
                  "row": 99
                },
                "location": {
                  "column": 12,
                  "row": 99
                }
              }
            ],
            "message": "Replace with `cond is None`"
          },
          "location": {
            "column": 27,
            "row": 99
          },
          "message": "Comparison to `None` should be `cond is None`",
          "noqa_row": 99,
          "url": "https://docs.astral.sh/ruff/rules/none-comparison"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 122,
            "row": 146
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 146
          },
          "message": "Line too long (121 > 88)",
          "noqa_row": 146,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E731",
          "end_location": {
            "column": 6,
            "row": 155
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "def exclude_line(line):\n        return any(\n            [line.strip().startswith(x) for x in [\"-e .\", \"#\", \".[test\"]]\n        )",
                "end_location": {
                  "column": 6,
                  "row": 155
                },
                "location": {
                  "column": 5,
                  "row": 153
                }
              }
            ],
            "message": "Rewrite `exclude_line` as a `def`"
          },
          "location": {
            "column": 5,
            "row": 153
          },
          "message": "Do not assign a `lambda` expression, use a `def`",
          "noqa_row": 153,
          "url": "https://docs.astral.sh/ruff/rules/lambda-assignment"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 95,
            "row": 188
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 188
          },
          "message": "Line too long (94 > 88)",
          "noqa_row": 189,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E711",
          "end_location": {
            "column": 31,
            "row": 191
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "replacement is None",
                "end_location": {
                  "column": 31,
                  "row": 191
                },
                "location": {
                  "column": 12,
                  "row": 191
                }
              }
            ],
            "message": "Replace with `cond is None`"
          },
          "location": {
            "column": 27,
            "row": 191
          },
          "message": "Comparison to `None` should be `cond is None`",
          "noqa_row": 191,
          "url": "https://docs.astral.sh/ruff/rules/none-comparison"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 108,
            "row": 251
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 251
          },
          "message": "Line too long (107 > 88)",
          "noqa_row": 251,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 100,
            "row": 274
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 274
          },
          "message": "Line too long (99 > 88)",
          "noqa_row": 274,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 212,
            "row": 282
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 282
          },
          "message": "Line too long (211 > 88)",
          "noqa_row": 282,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 92,
            "row": 286
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 286
          },
          "message": "Line too long (91 > 88)",
          "noqa_row": 286,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 111,
            "row": 326
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 326
          },
          "message": "Line too long (110 > 88)",
          "noqa_row": 326,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 92,
            "row": 385
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 385
          },
          "message": "Line too long (91 > 88)",
          "noqa_row": 385,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 90,
            "row": 434
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 434
          },
          "message": "Line too long (89 > 88)",
          "noqa_row": 434,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 100,
            "row": 451
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 451
          },
          "message": "Line too long (99 > 88)",
          "noqa_row": 451,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 36,
            "row": 4
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\remove_containers.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import json\nfrom argparse import ArgumentParser\n\nimport docker\n\n",
                "end_location": {
                  "column": 1,
                  "row": 6
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 33,
            "row": 7
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\remove_envs.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import argparse\nimport os\nimport subprocess\nfrom multiprocessing import Pool\n\n\n",
                "end_location": {
                  "column": 1,
                  "row": 10
                },
                "location": {
                  "column": 1,
                  "row": 3
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 3
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 3,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 92,
            "row": 12
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\remove_envs.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 12
          },
          "message": "Line too long (91 > 88)",
          "noqa_row": 16,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "B905",
          "end_location": {
            "column": 89,
            "row": 92
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\remove_envs.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": ", strict=False",
                "end_location": {
                  "column": 88,
                  "row": 92
                },
                "location": {
                  "column": 88,
                  "row": 92
                }
              }
            ],
            "message": "Add explicit value for parameter `strict=`"
          },
          "location": {
            "column": 29,
            "row": 92
          },
          "message": "`zip()` without an explicit `strict=` parameter",
          "noqa_row": 92,
          "url": "https://docs.astral.sh/ruff/rules/zip-without-explicit-strict"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 96,
            "row": 97
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\remove_envs.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 97
          },
          "message": "Line too long (95 > 88)",
          "noqa_row": 97,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 64,
            "row": 14
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\reporting.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import json\nfrom pathlib import Path\nfrom typing import Optional\n\nimport docker\nfrom swebench.harness.constants import (\n    KEY_INSTANCE_ID,\n    KEY_MODEL,\n    KEY_PREDICTION,\n    LOG_REPORT,\n    RUN_EVALUATION_LOG_DIR,\n)\nfrom swebench.harness.docker_utils import list_images\nfrom swebench.harness.test_spec.test_spec import make_test_spec\n\n\n",
                "end_location": {
                  "column": 1,
                  "row": 17
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 140,
            "row": 3
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_api.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 3
          },
          "message": "Line too long (139 > 88)",
          "noqa_row": 5,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 158,
            "row": 4
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_api.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 4
          },
          "message": "Line too long (157 > 88)",
          "noqa_row": 5,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 15,
            "row": 26
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_api.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import json\nimport logging\nimport os\nimport time\nimport traceback\nfrom argparse import ArgumentParser\nfrom pathlib import Path\n\nimport dotenv\nimport numpy as np\nimport openai\nimport tiktoken\nfrom anthropic import AI_PROMPT, HUMAN_PROMPT, Anthropic\nfrom datasets import load_dataset, load_from_disk\nfrom swebench.inference.make_datasets.utils import extract_diff\nfrom tenacity import (\n    retry,\n    stop_after_attempt,\n    wait_random_exponential,\n)\nfrom tqdm.auto import tqdm\n\n",
                "end_location": {
                  "column": 1,
                  "row": 28
                },
                "location": {
                  "column": 1,
                  "row": 7
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 7
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 7,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 91,
            "row": 345
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_api.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 345
          },
          "message": "Line too long (90 > 88)",
          "noqa_row": 345,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 100,
            "row": 411
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_api.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 411
          },
          "message": "Line too long (99 > 88)",
          "noqa_row": 415,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 91,
            "row": 528
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_api.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 528
          },
          "message": "Line too long (90 > 88)",
          "noqa_row": 528,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 98,
            "row": 554
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_api.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 554
          },
          "message": "Line too long (97 > 88)",
          "noqa_row": 554,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 17,
            "row": 7
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "from __future__ import annotations\n\nimport json\nimport platform\nimport threading\nimport traceback\n\nimport docker\n\n",
                "end_location": {
                  "column": 1,
                  "row": 9
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 2,
            "row": 62
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\nfrom pathlib import Path, PurePosixPath\n\nfrom swebench.harness.constants import (\n    APPLY_PATCH_FAIL,\n    APPLY_PATCH_PASS,\n    DOCKER_PATCH,\n    DOCKER_USER,\n    DOCKER_WORKDIR,\n    INSTANCE_IMAGE_BUILD_DIR,\n    KEY_INSTANCE_ID,\n    KEY_MODEL,\n    KEY_PREDICTION,\n    LOG_INSTANCE,\n    LOG_REPORT,\n    LOG_TEST_OUTPUT,\n    RUN_EVALUATION_LOG_DIR,\n    UTF8,\n)\nfrom swebench.harness.docker_build import (\n    BuildImageError,\n    build_container,\n    build_env_images,\n    close_logger,\n    setup_logger,\n)\nfrom swebench.harness.docker_utils import (\n    clean_images,\n    cleanup_container,\n    copy_to_container,\n    exec_run_with_timeout,\n    list_images,\n    remove_image,\n    should_remove,\n)\nfrom swebench.harness.grading import get_eval_report\nfrom swebench.harness.modal_eval import (\n    run_instances_modal,\n    validate_modal_credentials,\n)\nfrom swebench.harness.reporting import make_run_report\nfrom swebench.harness.test_spec.test_spec import TestSpec, make_test_spec\nfrom swebench.harness.utils import (\n    EvaluationError,\n    get_predictions_from_file,\n    load_swebench_dataset,\n    optional_str,\n    run_threadpool,\n    str2bool,\n)\nfrom tqdm.auto import tqdm\n\n",
                "end_location": {
                  "column": 1,
                  "row": 64
                },
                "location": {
                  "column": 1,
                  "row": 12
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 12
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 12,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E722",
          "end_location": {
            "column": 19,
            "row": 137
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation.py",
          "fix": null,
          "location": {
            "column": 13,
            "row": 137
          },
          "message": "Do not use bare `except`",
          "noqa_row": 137,
          "url": "https://docs.astral.sh/ruff/rules/bare-except"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 106,
            "row": 162
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 162
          },
          "message": "Line too long (105 > 88)",
          "noqa_row": 162,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 93,
            "row": 201
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 201
          },
          "message": "Line too long (92 > 88)",
          "noqa_row": 201,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "B012",
          "end_location": {
            "column": 10,
            "row": 273
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation.py",
          "fix": null,
          "location": {
            "column": 9,
            "row": 270
          },
          "message": "`return` inside `finally` blocks cause exceptions to be silenced",
          "noqa_row": 270,
          "url": "https://docs.astral.sh/ruff/rules/jump-statement-in-finally"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 96,
            "row": 498
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation.py",
          "fix": null,
          "location": {
            "column": 90,
            "row": 498
          },
          "message": "Line too long (94 > 88)",
          "noqa_row": 498,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 124,
            "row": 499
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 499
          },
          "message": "Line too long (123 > 88)",
          "noqa_row": 499,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 97,
            "row": 643
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 643
          },
          "message": "Line too long (96 > 88)",
          "noqa_row": 643,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 104,
            "row": 667
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 667
          },
          "message": "Line too long (103 > 88)",
          "noqa_row": 667,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 24,
            "row": 19
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "from __future__ import annotations\n\nimport asyncio\nimport json\nimport time\nimport traceback\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import cast\n\nimport modal\nimport modal.container_process\nimport modal.io_streams\nimport tenacity\nfrom swebench.harness.docker_build import setup_logger\nfrom swebench.harness.reporting import make_run_report\nfrom swebench.harness.utils import EvaluationError\n\n",
                "end_location": {
                  "column": 1,
                  "row": 21
                },
                "location": {
                  "column": 1,
                  "row": 3
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 3
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 3,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E402",
          "end_location": {
            "column": 2,
            "row": 35
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal.py",
          "fix": null,
          "location": {
            "column": 1,
            "row": 31
          },
          "message": "Module level import not at top of file",
          "noqa_row": 31,
          "url": "https://docs.astral.sh/ruff/rules/module-import-not-at-top-of-file"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 74,
            "row": 37
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "from swebench.harness.constants import (\n    APPLY_PATCH_FAIL,\n    APPLY_PATCH_PASS,\n    RUN_EVALUATION_LOG_DIR,\n)\nfrom swebench.harness.grading import get_eval_report\nfrom swebench.harness.test_spec.test_spec import TestSpec, make_test_spec\n\n\n",
                "end_location": {
                  "column": 1,
                  "row": 40
                },
                "location": {
                  "column": 1,
                  "row": 31
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 31
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 31,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E402",
          "end_location": {
            "column": 53,
            "row": 36
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal.py",
          "fix": null,
          "location": {
            "column": 1,
            "row": 36
          },
          "message": "Module level import not at top of file",
          "noqa_row": 36,
          "url": "https://docs.astral.sh/ruff/rules/module-import-not-at-top-of-file"
        },
        {
          "cell": null,
          "code": "E402",
          "end_location": {
            "column": 74,
            "row": 37
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal.py",
          "fix": null,
          "location": {
            "column": 1,
            "row": 37
          },
          "message": "Module level import not at top of file",
          "noqa_row": 37,
          "url": "https://docs.astral.sh/ruff/rules/module-import-not-at-top-of-file"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 128,
            "row": 165
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 165
          },
          "message": "Line too long (127 > 88)",
          "noqa_row": 165,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 121,
            "row": 194
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 194
          },
          "message": "Line too long (120 > 88)",
          "noqa_row": 194,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 115,
            "row": 210
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 210
          },
          "message": "Line too long (114 > 88)",
          "noqa_row": 210,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 94,
            "row": 3
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal_entrypoint.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 3
          },
          "message": "Line too long (93 > 88)",
          "noqa_row": 3,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 94,
            "row": 4
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal_entrypoint.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 4
          },
          "message": "Line too long (93 > 88)",
          "noqa_row": 4,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 91,
            "row": 5
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal_entrypoint.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 5
          },
          "message": "Line too long (90 > 88)",
          "noqa_row": 5,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 96,
            "row": 6
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal_entrypoint.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 6
          },
          "message": "Line too long (95 > 88)",
          "noqa_row": 6,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 16,
            "row": 10
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal_entrypoint.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import argparse\nimport asyncio\nimport sys\n\n",
                "end_location": {
                  "column": 1,
                  "row": 12
                },
                "location": {
                  "column": 1,
                  "row": 8
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 8
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 8,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 121,
            "row": 74
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal_entrypoint.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 74
          },
          "message": "Line too long (120 > 88)",
          "noqa_row": 74,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 36,
            "row": 39
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_live.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import json\nimport logging\nimport os\nimport re\nimport subprocess\nimport time\nfrom argparse import ArgumentParser\nfrom datetime import datetime\nfrom pathlib import Path\n\nfrom ghapi.all import GhApi\nfrom swebench.inference.make_datasets.bm25_retrieval import (\n    DOCUMENT_ENCODING_FUNCTIONS,\n    clone_repo,\n    make_index,\n    search,\n)\nfrom swebench.inference.make_datasets.create_instance import (\n    PROMPT_FUNCTIONS,\n    TOKENIZER_FUNCS,\n    ingest_files,\n    make_code_text,\n)\nfrom swebench.inference.make_datasets.utils import (\n    ContextManager,\n    extract_diff,\n    extract_minimal_patch,\n    string_to_bool,\n)\nfrom swebench.inference.run_api import call_anthropic, call_chat\nfrom tqdm.auto import tqdm\n\n",
                "end_location": {
                  "column": 1,
                  "row": 41
                },
                "location": {
                  "column": 1,
                  "row": 10
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 10
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 10,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "F841",
          "end_location": {
            "column": 14,
            "row": 107
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_live.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "",
                "end_location": {
                  "column": 1,
                  "row": 108
                },
                "location": {
                  "column": 1,
                  "row": 107
                }
              }
            ],
            "message": "Remove assignment to unused variable `thread_id`"
          },
          "location": {
            "column": 5,
            "row": 107
          },
          "message": "Local variable `thread_id` is assigned to but never used",
          "noqa_row": 107,
          "url": "https://docs.astral.sh/ruff/rules/unused-variable"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 94,
            "row": 151
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_live.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 151
          },
          "message": "Line too long (93 > 88)",
          "noqa_row": 151,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "B905",
          "end_location": {
            "column": 58,
            "row": 198
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_live.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": ", strict=False",
                "end_location": {
                  "column": 57,
                  "row": 198
                },
                "location": {
                  "column": 57,
                  "row": 198
                }
              }
            ],
            "message": "Add explicit value for parameter `strict=`"
          },
          "location": {
            "column": 31,
            "row": 198
          },
          "message": "`zip()` without an explicit `strict=` parameter",
          "noqa_row": 198,
          "url": "https://docs.astral.sh/ruff/rules/zip-without-explicit-strict"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 110,
            "row": 228
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_live.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 228
          },
          "message": "Line too long (109 > 88)",
          "noqa_row": 228,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 64,
            "row": 20
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_llama.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import json\nimport logging\nimport re\nfrom argparse import ArgumentParser\nfrom datetime import datetime\nfrom pathlib import Path\n\nimport torch\nfrom datasets import load_dataset, load_from_disk\nfrom peft import PeftConfig, PeftModel\nfrom swebench.inference.llamao.modeling_flash_llama import (\n    LlamaForCausalLM as AutoModelForCausalLM,\n)\nfrom swebench.inference.make_datasets.utils import extract_diff\nfrom tqdm.auto import tqdm\nfrom transformers import (\n    LlamaTokenizer,\n    StoppingCriteria,\n    StoppingCriteriaList,\n)\n\n",
                "end_location": {
                  "column": 1,
                  "row": 22
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 106,
            "row": 111
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 111
          },
          "message": "Line too long (105 > 88)",
          "noqa_row": 118,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 91,
            "row": 122
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 122
          },
          "message": "Line too long (90 > 88)",
          "noqa_row": 122,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "F841",
          "end_location": {
            "column": 23,
            "row": 203
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_llama.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "",
                "end_location": {
                  "column": 26,
                  "row": 203
                },
                "location": {
                  "column": 9,
                  "row": 203
                }
              }
            ],
            "message": "Remove assignment to unused variable `model_nickname`"
          },
          "location": {
            "column": 9,
            "row": 203
          },
          "message": "Local variable `model_nickname` is assigned to but never used",
          "noqa_row": 203,
          "url": "https://docs.astral.sh/ruff/rules/unused-variable"
        },
        {
          "cell": null,
          "code": "E731",
          "end_location": {
            "column": 45,
            "row": 217
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_llama.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "def filter_func(x):\n            return x >= min_len",
                "end_location": {
                  "column": 45,
                  "row": 217
                },
                "location": {
                  "column": 9,
                  "row": 217
                }
              }
            ],
            "message": "Rewrite `filter_func` as a `def`"
          },
          "location": {
            "column": 9,
            "row": 217
          },
          "message": "Do not assign a `lambda` expression, use a `def`",
          "noqa_row": 217,
          "url": "https://docs.astral.sh/ruff/rules/lambda-assignment"
        },
        {
          "cell": null,
          "code": "E731",
          "end_location": {
            "column": 44,
            "row": 219
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_llama.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "def filter_func(x):\n            return x < max_len",
                "end_location": {
                  "column": 44,
                  "row": 219
                },
                "location": {
                  "column": 9,
                  "row": 219
                }
              }
            ],
            "message": "Rewrite `filter_func` as a `def`"
          },
          "location": {
            "column": 9,
            "row": 219
          },
          "message": "Do not assign a `lambda` expression, use a `def`",
          "noqa_row": 219,
          "url": "https://docs.astral.sh/ruff/rules/lambda-assignment"
        },
        {
          "cell": null,
          "code": "E731",
          "end_location": {
            "column": 55,
            "row": 221
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_llama.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "def filter_func(x):\n            return min_len <= x < max_len",
                "end_location": {
                  "column": 55,
                  "row": 221
                },
                "location": {
                  "column": 9,
                  "row": 221
                }
              }
            ],
            "message": "Rewrite `filter_func` as a `def`"
          },
          "location": {
            "column": 9,
            "row": 221
          },
          "message": "Do not assign a `lambda` expression, use a `def`",
          "noqa_row": 221,
          "url": "https://docs.astral.sh/ruff/rules/lambda-assignment"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 147,
            "row": 237
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 237
          },
          "message": "Line too long (146 > 88)",
          "noqa_row": 237,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 112,
            "row": 241
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 241
          },
          "message": "Line too long (111 > 88)",
          "noqa_row": 241,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 116,
            "row": 262
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 262
          },
          "message": "Line too long (115 > 88)",
          "noqa_row": 263,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 117,
            "row": 316
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 316
          },
          "message": "Line too long (116 > 88)",
          "noqa_row": 316,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 99,
            "row": 317
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 317
          },
          "message": "Line too long (98 > 88)",
          "noqa_row": 317,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "B904",
          "end_location": {
            "column": 58,
            "row": 335
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_llama.py",
          "fix": null,
          "location": {
            "column": 21,
            "row": 335
          },
          "message": "Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling",
          "noqa_row": 335,
          "url": "https://docs.astral.sh/ruff/rules/raise-without-from-inside-except"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 133,
            "row": 382
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_llama.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 382
          },
          "message": "Line too long (132 > 88)",
          "noqa_row": 382,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 60,
            "row": 11
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_evaluation.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import collections\nimport json\n\nimport docker\nfrom swebench.harness.constants import (\n    FAIL_TO_PASS,\n    KEY_INSTANCE_ID,\n    KEY_MODEL,\n    PASS_TO_PASS,\n)\nfrom swebench.harness.run_evaluation import make_run_report\n\n",
                "end_location": {
                  "column": 1,
                  "row": 13
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 88,
            "row": 3
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_harness_utils.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import unittest\n\nfrom swebench.harness.test_spec.python import clean_environment_yml, clean_requirements\nfrom swebench.harness.utils import run_threadpool\n\n\n",
                "end_location": {
                  "column": 1,
                  "row": 6
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 99,
            "row": 18
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_harness_utils.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 18
          },
          "message": "Line too long (98 > 88)",
          "noqa_row": 22,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 99,
            "row": 21
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_harness_utils.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 21
          },
          "message": "Line too long (98 > 88)",
          "noqa_row": 22,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 91,
            "row": 89
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_harness_utils.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 89
          },
          "message": "Line too long (90 > 88)",
          "noqa_row": 89,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 2,
            "row": 24
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_spec.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import hashlib\nimport json\nfrom dataclasses import dataclass\nfrom typing import Any, Optional, Union, cast\n\nfrom swebench.harness.constants import (\n    DEFAULT_DOCKER_SPECS,\n    KEY_INSTANCE_ID,\n    LATEST,\n    MAP_REPO_TO_EXT,\n    MAP_REPO_VERSION_TO_SPECS,\n    SWEbenchInstance,\n)\nfrom swebench.harness.dockerfiles import (\n    get_dockerfile_base,\n    get_dockerfile_env,\n    get_dockerfile_instance,\n)\nfrom swebench.harness.test_spec.create_scripts import (\n    make_env_script_list,\n    make_eval_script_list,\n    make_repo_script_list,\n)\n\n\n",
                "end_location": {
                  "column": 1,
                  "row": 27
                },
                "location": {
                  "column": 1,
                  "row": 1
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 1
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 1,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 105,
            "row": 83
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_spec.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 83
          },
          "message": "Line too long (104 > 88)",
          "noqa_row": 83,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 101,
            "row": 84
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_spec.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 84
          },
          "message": "Line too long (100 > 88)",
          "noqa_row": 84,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 95,
            "row": 92
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_spec.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 92
          },
          "message": "Line too long (94 > 88)",
          "noqa_row": 96,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 109,
            "row": 95
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_spec.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 95
          },
          "message": "Line too long (108 > 88)",
          "noqa_row": 96,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 95,
            "row": 104
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_spec.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 104
          },
          "message": "Line too long (94 > 88)",
          "noqa_row": 104,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 92,
            "row": 108
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_spec.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 108
          },
          "message": "Line too long (91 > 88)",
          "noqa_row": 108,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 104,
            "row": 162
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_spec.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 162
          },
          "message": "Line too long (103 > 88)",
          "noqa_row": 163,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "F841",
          "end_location": {
            "column": 22,
            "row": 191
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_spec.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "",
                "end_location": {
                  "column": 25,
                  "row": 191
                },
                "location": {
                  "column": 5,
                  "row": 191
                }
              }
            ],
            "message": "Remove assignment to unused variable `problem_statement`"
          },
          "location": {
            "column": 5,
            "row": 191
          },
          "message": "Local variable `problem_statement` is assigned to but never used",
          "noqa_row": 191,
          "url": "https://docs.astral.sh/ruff/rules/unused-variable"
        },
        {
          "cell": null,
          "code": "F841",
          "end_location": {
            "column": 15,
            "row": 192
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_spec.py",
          "fix": {
            "applicability": "unsafe",
            "edits": [
              {
                "content": "",
                "end_location": {
                  "column": 18,
                  "row": 192
                },
                "location": {
                  "column": 5,
                  "row": 192
                }
              }
            ],
            "message": "Remove assignment to unused variable `hints_text`"
          },
          "location": {
            "column": 5,
            "row": 192
          },
          "message": "Local variable `hints_text` is assigned to but never used",
          "noqa_row": 192,
          "url": "https://docs.astral.sh/ruff/rules/unused-variable"
        },
        {
          "cell": null,
          "code": "E501",
          "end_location": {
            "column": 181,
            "row": 3
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\tokenize_dataset.py",
          "fix": null,
          "location": {
            "column": 89,
            "row": 3
          },
          "message": "Line too long (180 > 88)",
          "noqa_row": 3,
          "url": "https://docs.astral.sh/ruff/rules/line-too-long"
        },
        {
          "cell": null,
          "code": "I001",
          "end_location": {
            "column": 40,
            "row": 13
          },
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\tokenize_dataset.py",
          "fix": {
            "applicability": "safe",
            "edits": [
              {
                "content": "import logging\nimport os\nfrom argparse import ArgumentParser\nfrom pathlib import Path\n\nimport tiktoken\nfrom datasets import disable_caching, load_dataset, load_from_disk\nfrom tqdm.auto import tqdm\nfrom transformers import LlamaTokenizer\n\n",
                "end_location": {
                  "column": 1,
                  "row": 15
                },
                "location": {
                  "column": 1,
                  "row": 5
                }
              }
            ],
            "message": "Organize imports"
          },
          "location": {
            "column": 1,
            "row": 5
          },
          "message": "Import block is un-sorted or un-formatted",
          "noqa_row": 5,
          "url": "https://docs.astral.sh/ruff/rules/unsorted-imports"
        }
      ],
      "stderr": ""
    },
    "pylint": {
      "count": 440,
      "findings": [
        {
          "type": "error",
          "module": "scan_cyeftmaj.default",
          "obj": "",
          "line": 8,
          "column": 0,
          "endLine": 8,
          "endColumn": 27,
          "path": "default.py",
          "symbol": "import-error",
          "message": "Unable to import 'jinja2'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.default",
          "obj": "",
          "line": 10,
          "column": 0,
          "endLine": 10,
          "endColumn": 43,
          "path": "default.py",
          "symbol": "import-error",
          "message": "Unable to import 'minisweagent'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.default",
          "obj": "DefaultAgent.execute_action",
          "line": 117,
          "column": 12,
          "endLine": 119,
          "endColumn": 13,
          "path": "default.py",
          "symbol": "raise-missing-from",
          "message": "Consider explicitly re-raising using 'raise ExecutionTimeoutError(self.render_template(self.config.timeout_template, action=action, output=output)) from e'",
          "message-id": "W0707"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.default",
          "obj": "DefaultAgent.execute_action",
          "line": 121,
          "column": 12,
          "endLine": 121,
          "endColumn": 117,
          "path": "default.py",
          "symbol": "raise-missing-from",
          "message": "Consider explicitly re-raising using 'except TimeoutError as exc' and 'raise ExecutionTimeoutError(self.render_template(self.config.timeout_template, action=action, output='')) from exc'",
          "message-id": "W0707"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.build_dataset",
          "obj": "",
          "line": 9,
          "column": 0,
          "endLine": 13,
          "endColumn": 1,
          "path": "build_dataset.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.collect.utils'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.build_dataset",
          "obj": "main",
          "line": 124,
          "column": 13,
          "endLine": 124,
          "endColumn": 29,
          "path": "build_dataset.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.build_dataset",
          "obj": "main",
          "line": 137,
          "column": 4,
          "endLine": 139,
          "endColumn": 5,
          "path": "build_dataset.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.build_dataset",
          "obj": "main",
          "line": 143,
          "column": 9,
          "endLine": 143,
          "endColumn": 41,
          "path": "build_dataset.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.build_dataset",
          "obj": "main",
          "line": 146,
          "column": 13,
          "endLine": 146,
          "endColumn": 37,
          "path": "build_dataset.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.build_dataset",
          "obj": "main",
          "line": 147,
          "column": 38,
          "endLine": 147,
          "endColumn": 51,
          "path": "build_dataset.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.build_dataset",
          "obj": "main",
          "line": 151,
          "column": 20,
          "endLine": 154,
          "endColumn": 21,
          "path": "build_dataset.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.build_dataset",
          "obj": "main",
          "line": 182,
          "column": 4,
          "endLine": 184,
          "endColumn": 5,
          "path": "build_dataset.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.build_dataset",
          "obj": "main",
          "line": 185,
          "column": 4,
          "endLine": 187,
          "endColumn": 5,
          "path": "build_dataset.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.build_dataset_ft",
          "obj": "main",
          "line": 34,
          "column": 13,
          "endLine": 34,
          "endColumn": 20,
          "path": "build_dataset_ft.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.build_dataset_ft",
          "obj": "main",
          "line": 39,
          "column": 9,
          "endLine": 39,
          "endColumn": 31,
          "path": "build_dataset_ft.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.build_dataset_ft",
          "obj": "main",
          "line": 44,
          "column": 17,
          "endLine": 44,
          "endColumn": 35,
          "path": "build_dataset_ft.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_tasks_pipeline",
          "obj": "",
          "line": 9,
          "column": 0,
          "endLine": 9,
          "endColumn": 30,
          "path": "get_tasks_pipeline.py",
          "symbol": "import-error",
          "message": "Unable to import 'dotenv'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_tasks_pipeline",
          "obj": "",
          "line": 11,
          "column": 0,
          "endLine": 11,
          "endColumn": 64,
          "path": "get_tasks_pipeline.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.collect.build_dataset'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_tasks_pipeline",
          "obj": "",
          "line": 12,
          "column": 0,
          "endLine": 12,
          "endColumn": 60,
          "path": "get_tasks_pipeline.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.collect.print_pulls'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_tasks_pipeline",
          "obj": "construct_data_files",
          "line": 89,
          "column": 15,
          "endLine": 89,
          "endColumn": 24,
          "path": "get_tasks_pipeline.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_tasks_pipeline",
          "obj": "main",
          "line": 120,
          "column": 8,
          "endLine": 122,
          "endColumn": 9,
          "path": "get_tasks_pipeline.py",
          "symbol": "broad-exception-raised",
          "message": "Raising too general exception: Exception",
          "message-id": "W0719"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_top_pypi",
          "obj": "",
          "line": 7,
          "column": 0,
          "endLine": 7,
          "endColumn": 29,
          "path": "get_top_pypi.py",
          "symbol": "import-error",
          "message": "Unable to import 'bs4'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_top_pypi",
          "obj": "",
          "line": 8,
          "column": 0,
          "endLine": 8,
          "endColumn": 28,
          "path": "get_top_pypi.py",
          "symbol": "import-error",
          "message": "Unable to import 'ghapi.core'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_top_pypi",
          "obj": "",
          "line": 9,
          "column": 0,
          "endLine": 9,
          "endColumn": 30,
          "path": "get_top_pypi.py",
          "symbol": "import-error",
          "message": "Unable to import 'selenium'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_top_pypi",
          "obj": "",
          "line": 10,
          "column": 0,
          "endLine": 10,
          "endColumn": 43,
          "path": "get_top_pypi.py",
          "symbol": "import-error",
          "message": "Unable to import 'selenium.webdriver.common.by'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_top_pypi",
          "obj": "get_package_stats",
          "line": 49,
          "column": 12,
          "endLine": 49,
          "endColumn": 16,
          "path": "get_top_pypi.py",
          "symbol": "redefined-outer-name",
          "message": "Redefining name 'soup' from outer scope (line 109)",
          "message-id": "W0621"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_top_pypi",
          "obj": "get_package_stats",
          "line": 32,
          "column": 13,
          "endLine": 32,
          "endColumn": 20,
          "path": "get_top_pypi.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_top_pypi",
          "obj": "get_package_stats",
          "line": 38,
          "column": 9,
          "endLine": 38,
          "endColumn": 29,
          "path": "get_top_pypi.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_top_pypi",
          "obj": "get_package_stats",
          "line": 48,
          "column": 12,
          "endLine": 48,
          "endColumn": 18,
          "path": "get_top_pypi.py",
          "symbol": "possibly-used-before-assignment",
          "message": "Possibly using variable 'driver' before assignment",
          "message-id": "E0606"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_top_pypi",
          "obj": "get_package_stats",
          "line": 74,
          "column": 16,
          "endLine": 75,
          "endColumn": 24,
          "path": "get_top_pypi.py",
          "symbol": "bare-except",
          "message": "No exception type(s) specified",
          "message-id": "W0702"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.print_pulls",
          "obj": "",
          "line": 13,
          "column": 0,
          "endLine": 13,
          "endColumn": 35,
          "path": "print_pulls.py",
          "symbol": "import-error",
          "message": "Unable to import 'fastcore.xtras'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.print_pulls",
          "obj": "",
          "line": 14,
          "column": 0,
          "endLine": 14,
          "endColumn": 39,
          "path": "print_pulls.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.collect.utils'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.print_pulls",
          "obj": "log_all_pulls",
          "line": 42,
          "column": 9,
          "endLine": 42,
          "endColumn": 26,
          "path": "print_pulls.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.print_pulls",
          "obj": "log_single_pull",
          "line": 65,
          "column": 4,
          "endLine": 65,
          "endColumn": 76,
          "path": "print_pulls.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.print_pulls",
          "obj": "log_single_pull",
          "line": 73,
          "column": 8,
          "endLine": 73,
          "endColumn": 80,
          "path": "print_pulls.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.print_pulls",
          "obj": "log_single_pull",
          "line": 80,
          "column": 9,
          "endLine": 80,
          "endColumn": 26,
          "path": "print_pulls.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.print_pulls",
          "obj": "log_single_pull",
          "line": 83,
          "column": 4,
          "endLine": 83,
          "endColumn": 55,
          "path": "print_pulls.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.print_pulls",
          "obj": "log_single_pull",
          "line": 84,
          "column": 4,
          "endLine": 84,
          "endColumn": 59,
          "path": "print_pulls.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.utils",
          "obj": "get_instances",
          "line": 15,
          "column": 13,
          "endLine": 15,
          "endColumn": 32,
          "path": "utils.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.utils",
          "obj": "get_instances",
          "line": 20,
          "column": 9,
          "endLine": 20,
          "endColumn": 28,
          "path": "utils.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.delete_gh_workflows",
          "obj": "main",
          "line": 16,
          "column": 23,
          "endLine": 18,
          "endColumn": 5,
          "path": "delete_gh_workflows.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.delete_gh_workflows",
          "obj": "main",
          "line": 21,
          "column": 4,
          "endLine": 25,
          "endColumn": 5,
          "path": "delete_gh_workflows.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.delete_gh_workflows",
          "obj": "main",
          "line": 33,
          "column": 8,
          "endLine": 33,
          "endColumn": 51,
          "path": "delete_gh_workflows.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.delete_gh_workflows",
          "obj": "main",
          "line": 39,
          "column": 12,
          "endLine": 39,
          "endColumn": 57,
          "path": "delete_gh_workflows.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.delete_gh_workflows",
          "obj": "main",
          "line": 40,
          "column": 12,
          "endLine": 40,
          "endColumn": 48,
          "path": "delete_gh_workflows.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.delete_gh_workflows",
          "obj": "main",
          "line": 41,
          "column": 12,
          "endLine": 41,
          "endColumn": 86,
          "path": "delete_gh_workflows.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.delete_gh_workflows",
          "obj": "main",
          "line": 42,
          "column": 12,
          "endLine": 42,
          "endColumn": 43,
          "path": "delete_gh_workflows.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.delete_gh_workflows",
          "obj": "main",
          "line": 47,
          "column": 4,
          "endLine": 47,
          "endColumn": 46,
          "path": "delete_gh_workflows.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.remove_envs",
          "obj": "delete_folders_with_prefix",
          "line": 40,
          "column": 4,
          "endLine": 40,
          "endColumn": 38,
          "path": "remove_envs.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.remove_envs",
          "obj": "remove_environment",
          "line": 50,
          "column": 14,
          "endLine": 50,
          "endColumn": 26,
          "path": "remove_envs.py",
          "symbol": "possibly-used-before-assignment",
          "message": "Possibly using variable 'conda_source' before assignment",
          "message-id": "E0606"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.remove_envs",
          "obj": "",
          "line": 63,
          "column": 4,
          "endLine": 65,
          "endColumn": 7,
          "path": "remove_envs.py",
          "symbol": "pointless-string-statement",
          "message": "String statement has no effect",
          "message-id": "W0105"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.criteria",
          "obj": "",
          "line": 4,
          "column": 0,
          "endLine": 4,
          "endColumn": 46,
          "path": "criteria.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.collect.utils'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.criteria",
          "obj": "",
          "line": 5,
          "column": 0,
          "endLine": 5,
          "endColumn": 28,
          "path": "criteria.py",
          "symbol": "import-error",
          "message": "Unable to import 'unidiff'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.criteria",
          "obj": "contains_hyperlinks",
          "line": 30,
          "column": 23,
          "endLine": 32,
          "endColumn": 9,
          "path": "criteria.py",
          "symbol": "duplicate-string-formatting-argument",
          "message": "Duplicate string formatting argument 'pattern_repo', consider passing as named argument",
          "message-id": "W1308"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.criteria",
          "obj": "contains_issue_reference",
          "line": 101,
          "column": 11,
          "endLine": 101,
          "endColumn": 28,
          "path": "criteria.py",
          "symbol": "missing-timeout",
          "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
          "message-id": "W3101"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.make_lite",
          "obj": "",
          "line": 1,
          "column": 0,
          "endLine": 11,
          "endColumn": 1,
          "path": "make_lite.py",
          "symbol": "import-error",
          "message": "Unable to import 'criteria'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.make_lite",
          "obj": "",
          "line": 12,
          "column": 0,
          "endLine": 12,
          "endColumn": 63,
          "path": "make_lite.py",
          "symbol": "import-error",
          "message": "Unable to import 'datasets'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.make_lite",
          "obj": "apply_filters",
          "line": 49,
          "column": 18,
          "endLine": 49,
          "endColumn": 22,
          "path": "make_lite.py",
          "symbol": "redefined-outer-name",
          "message": "Redefining name 'dset' from outer scope (line 85)",
          "message-id": "W0621"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.make_lite",
          "obj": "take_subset",
          "line": 61,
          "column": 16,
          "endLine": 61,
          "endColumn": 20,
          "path": "make_lite.py",
          "symbol": "redefined-outer-name",
          "message": "Redefining name 'dset' from outer scope (line 85)",
          "message-id": "W0621"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.call_make_repo",
          "obj": "",
          "line": 9,
          "column": 15,
          "endLine": 14,
          "endColumn": 5,
          "path": "call_make_repo.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "",
          "line": 3,
          "column": 0,
          "endLine": 3,
          "endColumn": 13,
          "path": "docker_build.py",
          "symbol": "import-error",
          "message": "Unable to import 'docker'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "",
          "line": 4,
          "column": 0,
          "endLine": 4,
          "endColumn": 20,
          "path": "docker_build.py",
          "symbol": "import-error",
          "message": "Unable to import 'docker.errors'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "",
          "line": 11,
          "column": 0,
          "endLine": 17,
          "endColumn": 1,
          "path": "docker_build.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "",
          "line": 18,
          "column": 0,
          "endLine": 18,
          "endColumn": 73,
          "path": "docker_build.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.docker_utils'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "",
          "line": 19,
          "column": 0,
          "endLine": 23,
          "endColumn": 1,
          "path": "docker_build.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "",
          "line": 24,
          "column": 0,
          "endLine": 24,
          "endColumn": 62,
          "path": "docker_build.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.utils'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "build_image",
          "line": 99,
          "column": 4,
          "endLine": 103,
          "endColumn": 5,
          "path": "docker_build.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "build_image",
          "line": 106,
          "column": 8,
          "endLine": 106,
          "endColumn": 75,
          "path": "docker_build.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "build_image",
          "line": 111,
          "column": 17,
          "endLine": 111,
          "endColumn": 45,
          "path": "docker_build.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "build_image",
          "line": 114,
          "column": 16,
          "endLine": 116,
          "endColumn": 17,
          "path": "docker_build.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "build_image",
          "line": 120,
          "column": 13,
          "endLine": 120,
          "endColumn": 39,
          "path": "docker_build.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "build_image",
          "line": 124,
          "column": 8,
          "endLine": 126,
          "endColumn": 9,
          "path": "docker_build.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "build_image",
          "line": 147,
          "column": 16,
          "endLine": 147,
          "endColumn": 86,
          "path": "docker_build.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "build_image",
          "line": 153,
          "column": 8,
          "endLine": 153,
          "endColumn": 74,
          "path": "docker_build.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "build_image",
          "line": 156,
          "column": 8,
          "endLine": 156,
          "endColumn": 63,
          "path": "docker_build.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "get_env_configs_to_build",
          "line": 248,
          "column": 12,
          "endLine": 251,
          "endColumn": 13,
          "path": "docker_build.py",
          "symbol": "raise-missing-from",
          "message": "Consider explicitly re-raising using 'except Exception as exc' and 'raise Exception(f'Base image {test_spec.base_image_key} not found for {test_spec.env_image_key}\\n.Please build the base images first.') from exc'",
          "message-id": "W0707"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "get_env_configs_to_build",
          "line": 248,
          "column": 12,
          "endLine": 251,
          "endColumn": 13,
          "path": "docker_build.py",
          "symbol": "broad-exception-raised",
          "message": "Raising too general exception: Exception",
          "message-id": "W0719"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "get_env_configs_to_build",
          "line": 246,
          "column": 12,
          "endLine": 246,
          "endColumn": 22,
          "path": "docker_build.py",
          "symbol": "unused-variable",
          "message": "Unused variable 'base_image'",
          "message-id": "W0612"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "get_env_configs_to_build",
          "line": 256,
          "column": 12,
          "endLine": 256,
          "endColumn": 21,
          "path": "docker_build.py",
          "symbol": "unused-variable",
          "message": "Unused variable 'env_image'",
          "message-id": "W0612"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "build_instance_image",
          "line": 437,
          "column": 4,
          "endLine": 440,
          "endColumn": 5,
          "path": "docker_build.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "build_instance_image",
          "line": 464,
          "column": 8,
          "endLine": 464,
          "endColumn": 74,
          "path": "docker_build.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "build_instance_image",
          "line": 430,
          "column": 8,
          "endLine": 430,
          "endColumn": 17,
          "path": "docker_build.py",
          "symbol": "unused-variable",
          "message": "Unused variable 'env_image'",
          "message-id": "W0612"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "build_container",
          "line": 503,
          "column": 16,
          "endLine": 505,
          "endColumn": 17,
          "path": "docker_build.py",
          "symbol": "raise-missing-from",
          "message": "Consider explicitly re-raising using 'raise Exception(f'Error occurred while pulling image {test_spec.base_image_key}: {str(e)}') from e'",
          "message-id": "W0707"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_build",
          "obj": "build_container",
          "line": 503,
          "column": 16,
          "endLine": 505,
          "endColumn": 17,
          "path": "docker_build.py",
          "symbol": "broad-exception-raised",
          "message": "Raising too general exception: Exception",
          "message-id": "W0719"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.docker_utils",
          "obj": "",
          "line": 3,
          "column": 0,
          "endLine": 3,
          "endColumn": 13,
          "path": "docker_utils.py",
          "symbol": "import-error",
          "message": "Unable to import 'docker'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.docker_utils",
          "obj": "",
          "line": 4,
          "column": 0,
          "endLine": 4,
          "endColumn": 20,
          "path": "docker_utils.py",
          "symbol": "import-error",
          "message": "Unable to import 'docker.errors'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.docker_utils",
          "obj": "",
          "line": 13,
          "column": 0,
          "endLine": 13,
          "endColumn": 46,
          "path": "docker_utils.py",
          "symbol": "import-error",
          "message": "Unable to import 'docker.models.containers'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_utils",
          "obj": "remove_image",
          "line": 94,
          "column": 11,
          "endLine": 94,
          "endColumn": 20,
          "path": "docker_utils.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_utils",
          "obj": "cleanup_container",
          "line": 136,
          "column": 11,
          "endLine": 136,
          "endColumn": 20,
          "path": "docker_utils.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_utils",
          "obj": "cleanup_container",
          "line": 153,
          "column": 15,
          "endLine": 153,
          "endColumn": 24,
          "path": "docker_utils.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.docker_utils",
          "obj": "cleanup_container",
          "line": 150,
          "column": 29,
          "endLine": 150,
          "endColumn": 43,
          "path": "docker_utils.py",
          "symbol": "no-member",
          "message": "Module 'signal' has no 'SIGKILL' member; maybe 'SIGILL'?",
          "message-id": "E1101"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_utils",
          "obj": "cleanup_container",
          "line": 166,
          "column": 11,
          "endLine": 166,
          "endColumn": 20,
          "path": "docker_utils.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_utils",
          "obj": "exec_run_with_timeout.run_command",
          "line": 198,
          "column": 15,
          "endLine": 198,
          "endColumn": 24,
          "path": "docker_utils.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.docker_utils",
          "obj": "clean_images",
          "line": 289,
          "column": 19,
          "endLine": 289,
          "endColumn": 28,
          "path": "docker_utils.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.grading",
          "obj": "",
          "line": 60,
          "column": 9,
          "endLine": null,
          "endColumn": null,
          "path": "grading.py",
          "symbol": "fixme",
          "message": "TODO fix constant here",
          "message-id": "W0511"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.grading",
          "obj": "",
          "line": 210,
          "column": 9,
          "endLine": null,
          "endColumn": null,
          "path": "grading.py",
          "symbol": "fixme",
          "message": "TODO: Don't factor in p2p metrics",
          "message-id": "W0511"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.grading",
          "obj": "",
          "line": 3,
          "column": 0,
          "endLine": 21,
          "endColumn": 1,
          "path": "grading.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.grading",
          "obj": "",
          "line": 22,
          "column": 0,
          "endLine": 22,
          "endColumn": 57,
          "path": "grading.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.grading",
          "obj": "",
          "line": 23,
          "column": 0,
          "endLine": 23,
          "endColumn": 59,
          "path": "grading.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.log_parsers'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.grading",
          "obj": "get_logs_eval",
          "line": 58,
          "column": 9,
          "endLine": 58,
          "endColumn": 21,
          "path": "grading.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.prepare_images",
          "obj": "",
          "line": 1,
          "column": 0,
          "endLine": 1,
          "endColumn": 13,
          "path": "prepare_images.py",
          "symbol": "import-error",
          "message": "Unable to import 'docker'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.prepare_images",
          "obj": "",
          "line": 2,
          "column": 0,
          "endLine": 2,
          "endColumn": 15,
          "path": "prepare_images.py",
          "symbol": "import-error",
          "message": "Unable to import 'resource'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.prepare_images",
          "obj": "",
          "line": 6,
          "column": 0,
          "endLine": 6,
          "endColumn": 54,
          "path": "prepare_images.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.prepare_images",
          "obj": "",
          "line": 7,
          "column": 0,
          "endLine": 7,
          "endColumn": 63,
          "path": "prepare_images.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.docker_build'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.prepare_images",
          "obj": "",
          "line": 8,
          "column": 0,
          "endLine": 8,
          "endColumn": 53,
          "path": "prepare_images.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.docker_utils'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.prepare_images",
          "obj": "",
          "line": 9,
          "column": 0,
          "endLine": 9,
          "endColumn": 63,
          "path": "prepare_images.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.prepare_images",
          "obj": "",
          "line": 10,
          "column": 0,
          "endLine": 10,
          "endColumn": 80,
          "path": "prepare_images.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.utils'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.remove_containers",
          "obj": "",
          "line": 1,
          "column": 0,
          "endLine": 1,
          "endColumn": 13,
          "path": "remove_containers.py",
          "symbol": "import-error",
          "message": "Unable to import 'docker'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.remove_containers",
          "obj": "",
          "line": 6,
          "column": 0,
          "endLine": 8,
          "endColumn": 3,
          "path": "remove_containers.py",
          "symbol": "pointless-string-statement",
          "message": "String statement has no effect",
          "message-id": "W0105"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.remove_containers",
          "obj": "main",
          "line": 11,
          "column": 9,
          "endLine": 11,
          "endColumn": 21,
          "path": "remove_containers.py",
          "symbol": "redefined-outer-name",
          "message": "Redefining name 'instance_ids' from outer scope (line 51)",
          "message-id": "W0621"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.remove_containers",
          "obj": "main",
          "line": 14,
          "column": 13,
          "endLine": 14,
          "endColumn": 40,
          "path": "remove_containers.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.remove_containers",
          "obj": "main",
          "line": 35,
          "column": 15,
          "endLine": 35,
          "endColumn": 24,
          "path": "remove_containers.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.reporting",
          "obj": "",
          "line": 1,
          "column": 0,
          "endLine": 1,
          "endColumn": 13,
          "path": "reporting.py",
          "symbol": "import-error",
          "message": "Unable to import 'docker'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.reporting",
          "obj": "",
          "line": 6,
          "column": 0,
          "endLine": 12,
          "endColumn": 1,
          "path": "reporting.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.reporting",
          "obj": "",
          "line": 13,
          "column": 0,
          "endLine": 13,
          "endColumn": 53,
          "path": "reporting.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.docker_utils'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.reporting",
          "obj": "",
          "line": 14,
          "column": 0,
          "endLine": 14,
          "endColumn": 63,
          "path": "reporting.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.reporting",
          "obj": "make_run_report",
          "line": 157,
          "column": 9,
          "endLine": 157,
          "endColumn": 31,
          "path": "reporting.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "",
          "line": 3,
          "column": 0,
          "endLine": 3,
          "endColumn": 13,
          "path": "run_evaluation.py",
          "symbol": "import-error",
          "message": "Unable to import 'docker'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "",
          "line": 10,
          "column": 4,
          "endLine": 10,
          "endColumn": 19,
          "path": "run_evaluation.py",
          "symbol": "import-error",
          "message": "Unable to import 'resource'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "",
          "line": 16,
          "column": 0,
          "endLine": 31,
          "endColumn": 1,
          "path": "run_evaluation.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "",
          "line": 32,
          "column": 0,
          "endLine": 40,
          "endColumn": 1,
          "path": "run_evaluation.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.docker_utils'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "",
          "line": 41,
          "column": 0,
          "endLine": 47,
          "endColumn": 1,
          "path": "run_evaluation.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.docker_build'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "",
          "line": 48,
          "column": 0,
          "endLine": 48,
          "endColumn": 52,
          "path": "run_evaluation.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.grading'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "",
          "line": 49,
          "column": 0,
          "endLine": 49,
          "endColumn": 54,
          "path": "run_evaluation.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.reporting'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "",
          "line": 50,
          "column": 0,
          "endLine": 53,
          "endColumn": 1,
          "path": "run_evaluation.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.modal_eval'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "",
          "line": 54,
          "column": 0,
          "endLine": 54,
          "endColumn": 73,
          "path": "run_evaluation.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "",
          "line": 55,
          "column": 0,
          "endLine": 62,
          "endColumn": 1,
          "path": "run_evaluation.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.utils'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "run_instance",
          "line": 112,
          "column": 13,
          "endLine": 112,
          "endColumn": 35,
          "path": "run_evaluation.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "run_instance",
          "line": 137,
          "column": 12,
          "endLine": 139,
          "endColumn": 20,
          "path": "run_evaluation.py",
          "symbol": "bare-except",
          "message": "No exception type(s) specified",
          "message-id": "W0702"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "run_instance",
          "line": 270,
          "column": 8,
          "endLine": 273,
          "endColumn": 9,
          "path": "run_evaluation.py",
          "symbol": "return-in-finally",
          "message": "'return' shadowed by the 'finally' clause.",
          "message-id": "W0134"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "run_instance",
          "line": 257,
          "column": 11,
          "endLine": 257,
          "endColumn": 20,
          "path": "run_evaluation.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "run_instance",
          "line": 160,
          "column": 8,
          "endLine": 160,
          "endColumn": 57,
          "path": "run_evaluation.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "run_instance",
          "line": 199,
          "column": 8,
          "endLine": 199,
          "endColumn": 51,
          "path": "run_evaluation.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "run_instance",
          "line": 211,
          "column": 13,
          "endLine": 211,
          "endColumn": 40,
          "path": "run_evaluation.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "run_instance",
          "line": 250,
          "column": 13,
          "endLine": 250,
          "endColumn": 35,
          "path": "run_evaluation.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "run_instance",
          "line": 270,
          "column": 8,
          "endLine": 273,
          "endColumn": 9,
          "path": "run_evaluation.py",
          "symbol": "lost-exception",
          "message": "return statement in finally block may swallow exception",
          "message-id": "W0150"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation",
          "obj": "run_instances.run_evaluation_with_progress",
          "line": 356,
          "column": 0,
          "endLine": null,
          "endColumn": null,
          "path": "run_evaluation.py",
          "symbol": "redefined-outer-name",
          "message": "Redefining name 'args' from outer scope (line 676)",
          "message-id": "W0621"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.c",
          "obj": "",
          "line": 4,
          "column": 0,
          "endLine": 4,
          "endColumn": 49,
          "path": "c.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.c",
          "obj": "",
          "line": 5,
          "column": 0,
          "endLine": 5,
          "endColumn": 57,
          "path": "c.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.c",
          "obj": "parse_log_redis",
          "line": 8,
          "column": 30,
          "endLine": 8,
          "endColumn": 49,
          "path": "c.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'test_spec'",
          "message-id": "W0613"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.c",
          "obj": "parse_log_jq",
          "line": 35,
          "column": 27,
          "endLine": 35,
          "endColumn": 46,
          "path": "c.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'test_spec'",
          "message-id": "W0613"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.c",
          "obj": "parse_log_doctest",
          "line": 57,
          "column": 32,
          "endLine": 57,
          "endColumn": 51,
          "path": "c.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'test_spec'",
          "message-id": "W0613"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.c",
          "obj": "parse_log_micropython_test",
          "line": 94,
          "column": 41,
          "endLine": 94,
          "endColumn": 60,
          "path": "c.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'test_spec'",
          "message-id": "W0613"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.c",
          "obj": "parse_log_googletest",
          "line": 113,
          "column": 35,
          "endLine": 113,
          "endColumn": 54,
          "path": "c.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'test_spec'",
          "message-id": "W0613"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.go",
          "obj": "",
          "line": 2,
          "column": 0,
          "endLine": 2,
          "endColumn": 49,
          "path": "go.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.go",
          "obj": "",
          "line": 3,
          "column": 0,
          "endLine": 3,
          "endColumn": 57,
          "path": "go.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.go",
          "obj": "parse_log_gotest",
          "line": 6,
          "column": 31,
          "endLine": 6,
          "endColumn": 50,
          "path": "go.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'test_spec'",
          "message-id": "W0613"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.java",
          "obj": "",
          "line": 2,
          "column": 0,
          "endLine": 2,
          "endColumn": 49,
          "path": "java.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.java",
          "obj": "",
          "line": 3,
          "column": 0,
          "endLine": 3,
          "endColumn": 57,
          "path": "java.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.java",
          "obj": "parse_log_maven",
          "line": 6,
          "column": 30,
          "endLine": 6,
          "endColumn": 49,
          "path": "java.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'test_spec'",
          "message-id": "W0613"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.java",
          "obj": "parse_log_ant",
          "line": 42,
          "column": 28,
          "endLine": 42,
          "endColumn": 47,
          "path": "java.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'test_spec'",
          "message-id": "W0613"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.java",
          "obj": "parse_log_gradle_custom",
          "line": 59,
          "column": 38,
          "endLine": 59,
          "endColumn": 57,
          "path": "java.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'test_spec'",
          "message-id": "W0613"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.javascript",
          "obj": "",
          "line": 5,
          "column": 0,
          "endLine": 8,
          "endColumn": 1,
          "path": "javascript.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.javascript",
          "obj": "",
          "line": 9,
          "column": 0,
          "endLine": 9,
          "endColumn": 73,
          "path": "javascript.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.utils'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.javascript",
          "obj": "",
          "line": 10,
          "column": 0,
          "endLine": 10,
          "endColumn": 28,
          "path": "javascript.py",
          "symbol": "import-error",
          "message": "Unable to import 'unidiff'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.php",
          "obj": "",
          "line": 2,
          "column": 0,
          "endLine": 2,
          "endColumn": 49,
          "path": "php.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.php",
          "obj": "",
          "line": 3,
          "column": 0,
          "endLine": 3,
          "endColumn": 57,
          "path": "php.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.php",
          "obj": "parse_log_phpunit",
          "line": 6,
          "column": 32,
          "endLine": 6,
          "endColumn": 51,
          "path": "php.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'test_spec'",
          "message-id": "W0613"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.python",
          "obj": "",
          "line": 6,
          "column": 0,
          "endLine": 17,
          "endColumn": 1,
          "path": "python.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.python",
          "obj": "",
          "line": 18,
          "column": 0,
          "endLine": 18,
          "endColumn": 82,
          "path": "python.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.utils'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.python",
          "obj": "get_environment_yml_by_commit",
          "line": 35,
          "column": 15,
          "endLine": 35,
          "endColumn": 54,
          "path": "python.py",
          "symbol": "missing-timeout",
          "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
          "message-id": "W3101"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.python",
          "obj": "clean_environment_yml",
          "line": 75,
          "column": 4,
          "endLine": 75,
          "endColumn": 18,
          "path": "python.py",
          "symbol": "unused-variable",
          "message": "Unused variable 'pip_line_start'",
          "message-id": "W0612"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.python",
          "obj": "get_requirements_by_commit",
          "line": 141,
          "column": 15,
          "endLine": 141,
          "endColumn": 54,
          "path": "python.py",
          "symbol": "missing-timeout",
          "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
          "message-id": "W3101"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.python",
          "obj": "get_requirements_by_commit",
          "line": 168,
          "column": 19,
          "endLine": 168,
          "endColumn": 58,
          "path": "python.py",
          "symbol": "missing-timeout",
          "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
          "message-id": "W3101"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.python",
          "obj": "make_env_script_list_py_from_conda",
          "line": 321,
          "column": 4,
          "endLine": 321,
          "endColumn": 12,
          "path": "python.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'instance'",
          "message-id": "W0613"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.python",
          "obj": "make_env_script_list_py_from_conda",
          "line": 321,
          "column": 14,
          "endLine": 321,
          "endColumn": 19,
          "path": "python.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'specs'",
          "message-id": "W0613"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.ruby",
          "obj": "",
          "line": 3,
          "column": 0,
          "endLine": 3,
          "endColumn": 49,
          "path": "ruby.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.ruby",
          "obj": "",
          "line": 4,
          "column": 0,
          "endLine": 4,
          "endColumn": 57,
          "path": "ruby.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.ruby",
          "obj": "parse_log_minitest",
          "line": 7,
          "column": 33,
          "endLine": 7,
          "endColumn": 52,
          "path": "ruby.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'test_spec'",
          "message-id": "W0613"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.ruby",
          "obj": "parse_log_cucumber",
          "line": 30,
          "column": 33,
          "endLine": 30,
          "endColumn": 52,
          "path": "ruby.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'test_spec'",
          "message-id": "W0613"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.ruby",
          "obj": "parse_log_ruby_unit",
          "line": 50,
          "column": 34,
          "endLine": 50,
          "endColumn": 53,
          "path": "ruby.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'test_spec'",
          "message-id": "W0613"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.ruby",
          "obj": "parse_log_rspec_transformed_json",
          "line": 69,
          "column": 47,
          "endLine": 69,
          "endColumn": 66,
          "path": "ruby.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'test_spec'",
          "message-id": "W0613"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.rust",
          "obj": "",
          "line": 3,
          "column": 0,
          "endLine": 3,
          "endColumn": 49,
          "path": "rust.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.rust",
          "obj": "",
          "line": 4,
          "column": 0,
          "endLine": 4,
          "endColumn": 57,
          "path": "rust.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.rust",
          "obj": "parse_log_cargo",
          "line": 7,
          "column": 30,
          "endLine": 7,
          "endColumn": 49,
          "path": "rust.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'test_spec'",
          "message-id": "W0613"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "",
          "line": 7,
          "column": 0,
          "endLine": 7,
          "endColumn": 12,
          "path": "run_evaluation_modal.py",
          "symbol": "import-error",
          "message": "Unable to import 'modal'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "",
          "line": 8,
          "column": 0,
          "endLine": 8,
          "endColumn": 30,
          "path": "run_evaluation_modal.py",
          "symbol": "import-error",
          "message": "Unable to import 'modal.container_process'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "",
          "line": 9,
          "column": 0,
          "endLine": 9,
          "endColumn": 23,
          "path": "run_evaluation_modal.py",
          "symbol": "import-error",
          "message": "Unable to import 'modal.io_streams'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "",
          "line": 10,
          "column": 0,
          "endLine": 10,
          "endColumn": 15,
          "path": "run_evaluation_modal.py",
          "symbol": "import-error",
          "message": "Unable to import 'tenacity'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "",
          "line": 16,
          "column": 0,
          "endLine": 16,
          "endColumn": 54,
          "path": "run_evaluation_modal.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.docker_build'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "",
          "line": 17,
          "column": 0,
          "endLine": 17,
          "endColumn": 54,
          "path": "run_evaluation_modal.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.reporting'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "",
          "line": 18,
          "column": 0,
          "endLine": 18,
          "endColumn": 50,
          "path": "run_evaluation_modal.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.utils'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "",
          "line": 31,
          "column": 0,
          "endLine": 35,
          "endColumn": 1,
          "path": "run_evaluation_modal.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "",
          "line": 36,
          "column": 0,
          "endLine": 36,
          "endColumn": 52,
          "path": "run_evaluation_modal.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.grading'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "",
          "line": 37,
          "column": 0,
          "endLine": 37,
          "endColumn": 73,
          "path": "run_evaluation_modal.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.test_spec'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "ModalSandboxRuntime._read_stream",
          "line": 98,
          "column": 15,
          "endLine": 98,
          "endColumn": 24,
          "path": "run_evaluation_modal.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "ModalSandboxRuntime.exec",
          "line": 134,
          "column": 15,
          "endLine": 134,
          "endColumn": 24,
          "path": "run_evaluation_modal.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "ModalSandboxRuntime.__exit__",
          "line": 154,
          "column": 19,
          "endLine": 154,
          "endColumn": 28,
          "path": "run_evaluation_modal.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "ModalSandboxRuntime.__exit__",
          "line": 150,
          "column": 31,
          "endLine": 150,
          "endColumn": 40,
          "path": "run_evaluation_modal.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "ModalSandboxRuntime.get_instance_image",
          "line": 172,
          "column": 8,
          "endLine": 172,
          "endColumn": 59,
          "path": "run_evaluation_modal.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "ModalSandboxRuntime.get_instance_image",
          "line": 173,
          "column": 8,
          "endLine": 173,
          "endColumn": 61,
          "path": "run_evaluation_modal.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "run_instance_modal",
          "line": 376,
          "column": 11,
          "endLine": 376,
          "endColumn": 20,
          "path": "run_evaluation_modal.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "run_instance_modal",
          "line": 323,
          "column": 13,
          "endLine": 323,
          "endColumn": 40,
          "path": "run_evaluation_modal.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "run_instances_modal",
          "line": 448,
          "column": 25,
          "endLine": 448,
          "endColumn": 64,
          "path": "run_evaluation_modal.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "run_instances_modal",
          "line": 450,
          "column": 25,
          "endLine": 450,
          "endColumn": 63,
          "path": "run_evaluation_modal.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "run_instances_modal",
          "line": 452,
          "column": 25,
          "endLine": 452,
          "endColumn": 58,
          "path": "run_evaluation_modal.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "run_instances_modal",
          "line": 454,
          "column": 25,
          "endLine": 454,
          "endColumn": 59,
          "path": "run_evaluation_modal.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation_modal",
          "obj": "run_instances_modal",
          "line": 458,
          "column": 31,
          "endLine": 458,
          "endColumn": 40,
          "path": "run_evaluation_modal.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_evaluation_modal_entrypoint",
          "obj": "exec",
          "line": 16,
          "column": 0,
          "endLine": 16,
          "endColumn": 14,
          "path": "run_evaluation_modal_entrypoint.py",
          "symbol": "redefined-builtin",
          "message": "Redefining built-in 'exec'",
          "message-id": "W0622"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.create_scripts",
          "obj": "",
          "line": 1,
          "column": 0,
          "endLine": 1,
          "endColumn": 54,
          "path": "create_scripts.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.create_scripts",
          "obj": "",
          "line": 2,
          "column": 0,
          "endLine": 4,
          "endColumn": 1,
          "path": "create_scripts.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.javascript'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.create_scripts",
          "obj": "",
          "line": 5,
          "column": 0,
          "endLine": 9,
          "endColumn": 1,
          "path": "create_scripts.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.python'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.create_scripts",
          "obj": "",
          "line": 10,
          "column": 0,
          "endLine": 14,
          "endColumn": 1,
          "path": "create_scripts.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.utils'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.test_spec",
          "obj": "",
          "line": 7,
          "column": 0,
          "endLine": 14,
          "endColumn": 1,
          "path": "test_spec.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.test_spec",
          "obj": "",
          "line": 15,
          "column": 0,
          "endLine": 19,
          "endColumn": 1,
          "path": "test_spec.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.dockerfiles'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.test_spec",
          "obj": "",
          "line": 20,
          "column": 0,
          "endLine": 24,
          "endColumn": 1,
          "path": "test_spec.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.create_scripts'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.test_spec",
          "obj": "make_test_spec",
          "line": 191,
          "column": 4,
          "endLine": 191,
          "endColumn": 21,
          "path": "test_spec.py",
          "symbol": "unused-variable",
          "message": "Unused variable 'problem_statement'",
          "message-id": "W0612"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.test_spec",
          "obj": "make_test_spec",
          "line": 192,
          "column": 4,
          "endLine": 192,
          "endColumn": 14,
          "path": "test_spec.py",
          "symbol": "unused-variable",
          "message": "Unused variable 'hints_text'",
          "message-id": "W0612"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_api",
          "obj": "",
          "line": 10,
          "column": 0,
          "endLine": 10,
          "endColumn": 13,
          "path": "run_api.py",
          "symbol": "import-error",
          "message": "Unable to import 'dotenv'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_api",
          "obj": "",
          "line": 15,
          "column": 0,
          "endLine": 15,
          "endColumn": 15,
          "path": "run_api.py",
          "symbol": "import-error",
          "message": "Unable to import 'tiktoken'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_api",
          "obj": "",
          "line": 17,
          "column": 0,
          "endLine": 17,
          "endColumn": 56,
          "path": "run_api.py",
          "symbol": "import-error",
          "message": "Unable to import 'anthropic'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_api",
          "obj": "",
          "line": 18,
          "column": 0,
          "endLine": 22,
          "endColumn": 1,
          "path": "run_api.py",
          "symbol": "import-error",
          "message": "Unable to import 'tenacity'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_api",
          "obj": "",
          "line": 23,
          "column": 0,
          "endLine": 23,
          "endColumn": 49,
          "path": "run_api.py",
          "symbol": "import-error",
          "message": "Unable to import 'datasets'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_api",
          "obj": "",
          "line": 24,
          "column": 0,
          "endLine": 24,
          "endColumn": 63,
          "path": "run_api.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.inference.make_datasets.utils'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_api",
          "obj": "calc_cost",
          "line": 107,
          "column": 4,
          "endLine": 109,
          "endColumn": 5,
          "path": "run_api.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_api",
          "obj": "openai_inference",
          "line": 219,
          "column": 9,
          "endLine": 219,
          "endColumn": 32,
          "path": "run_api.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_api",
          "obj": "call_anthropic",
          "line": 274,
          "column": 11,
          "endLine": 274,
          "endColumn": 20,
          "path": "run_api.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_api",
          "obj": "call_anthropic",
          "line": 276,
          "column": 8,
          "endLine": 276,
          "endColumn": 41,
          "path": "run_api.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_api",
          "obj": "call_anthropic_v2",
          "line": 315,
          "column": 11,
          "endLine": 315,
          "endColumn": 20,
          "path": "run_api.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_api",
          "obj": "call_anthropic_v2",
          "line": 317,
          "column": 8,
          "endLine": 317,
          "endColumn": 41,
          "path": "run_api.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_api",
          "obj": "call_anthropic_v2",
          "line": 284,
          "column": 0,
          "endLine": null,
          "endColumn": null,
          "path": "run_api.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'model_args'",
          "message-id": "W0613"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_api",
          "obj": "anthropic_inference",
          "line": 367,
          "column": 9,
          "endLine": 367,
          "endColumn": 32,
          "path": "run_api.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_api",
          "obj": "anthropic_inference",
          "line": 389,
          "column": 19,
          "endLine": 389,
          "endColumn": 28,
          "path": "run_api.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_api",
          "obj": "main",
          "line": 453,
          "column": 8,
          "endLine": 455,
          "endColumn": 9,
          "path": "run_api.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_api",
          "obj": "main",
          "line": 457,
          "column": 8,
          "endLine": 457,
          "endColumn": 88,
          "path": "run_api.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_api",
          "obj": "main",
          "line": 468,
          "column": 4,
          "endLine": 468,
          "endColumn": 47,
          "path": "run_api.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_api",
          "obj": "main",
          "line": 471,
          "column": 13,
          "endLine": 471,
          "endColumn": 30,
          "path": "run_api.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_api",
          "obj": "main",
          "line": 476,
          "column": 4,
          "endLine": 476,
          "endColumn": 85,
          "path": "run_api.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_live",
          "obj": "",
          "line": 13,
          "column": 0,
          "endLine": 13,
          "endColumn": 27,
          "path": "run_live.py",
          "symbol": "import-error",
          "message": "Unable to import 'ghapi.all'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_live",
          "obj": "",
          "line": 19,
          "column": 0,
          "endLine": 24,
          "endColumn": 1,
          "path": "run_live.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.inference.make_datasets.utils'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_live",
          "obj": "",
          "line": 25,
          "column": 0,
          "endLine": 30,
          "endColumn": 1,
          "path": "run_live.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.inference.make_datasets.create_instance'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_live",
          "obj": "",
          "line": 31,
          "column": 0,
          "endLine": 36,
          "endColumn": 1,
          "path": "run_live.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.inference.make_datasets.bm25_retrieval'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_live",
          "obj": "",
          "line": 37,
          "column": 0,
          "endLine": 37,
          "endColumn": 64,
          "path": "run_live.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.inference.run_api'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_live",
          "obj": "make_instance",
          "line": 109,
          "column": 4,
          "endLine": 109,
          "endColumn": 47,
          "path": "run_live.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_live",
          "obj": "make_instance",
          "line": 117,
          "column": 4,
          "endLine": 117,
          "endColumn": 77,
          "path": "run_live.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_live",
          "obj": "make_instance",
          "line": 129,
          "column": 4,
          "endLine": 129,
          "endColumn": 51,
          "path": "run_live.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_live",
          "obj": "make_instance",
          "line": 137,
          "column": 35,
          "endLine": 137,
          "endColumn": 53,
          "path": "run_live.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_live",
          "obj": "make_instance",
          "line": 150,
          "column": 8,
          "endLine": 153,
          "endColumn": 9,
          "path": "run_live.py",
          "symbol": "logging-not-lazy",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1201"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_live",
          "obj": "make_instance",
          "line": 107,
          "column": 4,
          "endLine": 107,
          "endColumn": 13,
          "path": "run_live.py",
          "symbol": "unused-variable",
          "message": "Unused variable 'thread_id'",
          "message-id": "W0612"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_live",
          "obj": "main",
          "line": 192,
          "column": 8,
          "endLine": 192,
          "endColumn": 71,
          "path": "run_live.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_live",
          "obj": "main",
          "line": 202,
          "column": 8,
          "endLine": 202,
          "endColumn": 55,
          "path": "run_live.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_live",
          "obj": "main",
          "line": 219,
          "column": 8,
          "endLine": 219,
          "endColumn": 50,
          "path": "run_live.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_live",
          "obj": "main",
          "line": 227,
          "column": 12,
          "endLine": 229,
          "endColumn": 13,
          "path": "run_live.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_live",
          "obj": "main",
          "line": 231,
          "column": 12,
          "endLine": 231,
          "endColumn": 43,
          "path": "run_live.py",
          "symbol": "import-error",
          "message": "Unable to import 'anthropic'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_live",
          "obj": "main",
          "line": 256,
          "column": 9,
          "endLine": 256,
          "endColumn": 32,
          "path": "run_live.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_live",
          "obj": "main",
          "line": 259,
          "column": 4,
          "endLine": 259,
          "endColumn": 49,
          "path": "run_live.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "",
          "line": 8,
          "column": 0,
          "endLine": 8,
          "endColumn": 12,
          "path": "run_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'torch'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "",
          "line": 9,
          "column": 0,
          "endLine": 9,
          "endColumn": 49,
          "path": "run_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'datasets'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "",
          "line": 10,
          "column": 0,
          "endLine": 10,
          "endColumn": 38,
          "path": "run_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'peft'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "",
          "line": 12,
          "column": 0,
          "endLine": 16,
          "endColumn": 1,
          "path": "run_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'transformers'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "",
          "line": 17,
          "column": 0,
          "endLine": 19,
          "endColumn": 1,
          "path": "run_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.inference.llamao.modeling_flash_llama'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "",
          "line": 20,
          "column": 0,
          "endLine": 20,
          "endColumn": 63,
          "path": "run_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.inference.make_datasets.utils'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "",
          "line": 25,
          "column": 24,
          "endLine": 25,
          "endColumn": 82,
          "path": "run_llama.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "load_model",
          "line": 119,
          "column": 4,
          "endLine": 119,
          "endColumn": 64,
          "path": "run_llama.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "load_model",
          "line": 127,
          "column": 4,
          "endLine": 127,
          "endColumn": 49,
          "path": "run_llama.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "load_model",
          "line": 136,
          "column": 4,
          "endLine": 136,
          "endColumn": 49,
          "path": "run_llama.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "load_model",
          "line": 146,
          "column": 4,
          "endLine": 146,
          "endColumn": 58,
          "path": "run_llama.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "load_tokenizer",
          "line": 158,
          "column": 4,
          "endLine": 158,
          "endColumn": 58,
          "path": "run_llama.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "load_data",
          "line": 193,
          "column": 4,
          "endLine": 193,
          "endColumn": 55,
          "path": "run_llama.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "load_data",
          "line": 236,
          "column": 8,
          "endLine": 238,
          "endColumn": 9,
          "path": "run_llama.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "load_data",
          "line": 240,
          "column": 8,
          "endLine": 242,
          "endColumn": 9,
          "path": "run_llama.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "load_data",
          "line": 201,
          "column": 8,
          "endLine": 201,
          "endColumn": 22,
          "path": "run_llama.py",
          "symbol": "unused-variable",
          "message": "Unused variable 'model_nickname'",
          "message-id": "W0612"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "generate",
          "line": 330,
          "column": 19,
          "endLine": 330,
          "endColumn": 28,
          "path": "run_llama.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "generate",
          "line": 300,
          "column": 16,
          "endLine": 300,
          "endColumn": 71,
          "path": "run_llama.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "generate",
          "line": 335,
          "column": 20,
          "endLine": 335,
          "endColumn": 57,
          "path": "run_llama.py",
          "symbol": "raise-missing-from",
          "message": "Consider explicitly re-raising using 'raise ValueError('too many failures') from e'",
          "message-id": "W0707"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "get_all_existing_ids",
          "line": 351,
          "column": 8,
          "endLine": 351,
          "endColumn": 69,
          "path": "run_llama.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "get_all_existing_ids",
          "line": 352,
          "column": 13,
          "endLine": 352,
          "endColumn": 27,
          "path": "run_llama.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "get_all_existing_ids",
          "line": 356,
          "column": 4,
          "endLine": 356,
          "endColumn": 58,
          "path": "run_llama.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "main",
          "line": 381,
          "column": 12,
          "endLine": 383,
          "endColumn": 13,
          "path": "run_llama.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "main",
          "line": 397,
          "column": 4,
          "endLine": 397,
          "endColumn": 49,
          "path": "run_llama.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.run_llama",
          "obj": "main",
          "line": 413,
          "column": 9,
          "endLine": 413,
          "endColumn": 31,
          "path": "run_llama.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.distributed_attention",
          "obj": "",
          "line": 6,
          "column": 0,
          "endLine": 6,
          "endColumn": 12,
          "path": "distributed_attention.py",
          "symbol": "import-error",
          "message": "Unable to import 'torch'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.distributed_attention",
          "obj": "",
          "line": 9,
          "column": 0,
          "endLine": 9,
          "endColumn": 24,
          "path": "distributed_attention.py",
          "symbol": "import-error",
          "message": "Unable to import 'torch'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.distributed_attention",
          "obj": "",
          "line": 10,
          "column": 0,
          "endLine": 10,
          "endColumn": 27,
          "path": "distributed_attention.py",
          "symbol": "import-error",
          "message": "Unable to import 'torch.nn'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.distributed_attention",
          "obj": "",
          "line": 12,
          "column": 0,
          "endLine": 12,
          "endColumn": 32,
          "path": "distributed_attention.py",
          "symbol": "import-error",
          "message": "Unable to import 'torch.distributed'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.distributed_attention",
          "obj": "SeqAllToAll.forward",
          "line": 18,
          "column": 18,
          "endLine": 18,
          "endColumn": 31,
          "path": "distributed_attention.py",
          "symbol": "redefined-builtin",
          "message": "Redefining built-in 'input'",
          "message-id": "W0622"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "",
          "line": 23,
          "column": 0,
          "endLine": 23,
          "endColumn": 12,
          "path": "modeling_flash_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'torch'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "",
          "line": 24,
          "column": 0,
          "endLine": 24,
          "endColumn": 31,
          "path": "modeling_flash_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'torch.nn.functional'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "",
          "line": 25,
          "column": 0,
          "endLine": 25,
          "endColumn": 29,
          "path": "modeling_flash_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'torch.utils.checkpoint'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "",
          "line": 26,
          "column": 0,
          "endLine": 26,
          "endColumn": 20,
          "path": "modeling_flash_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'torch'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "",
          "line": 27,
          "column": 0,
          "endLine": 27,
          "endColumn": 65,
          "path": "modeling_flash_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'torch.nn'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "",
          "line": 29,
          "column": 0,
          "endLine": 29,
          "endColumn": 32,
          "path": "modeling_flash_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'torch.distributed'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "",
          "line": 31,
          "column": 0,
          "endLine": 31,
          "endColumn": 40,
          "path": "modeling_flash_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'transformers'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "",
          "line": 32,
          "column": 0,
          "endLine": 32,
          "endColumn": 43,
          "path": "modeling_flash_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'transformers.activations'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "",
          "line": 33,
          "column": 0,
          "endLine": 37,
          "endColumn": 1,
          "path": "modeling_flash_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'transformers.modeling_outputs'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "",
          "line": 38,
          "column": 0,
          "endLine": 38,
          "endColumn": 55,
          "path": "modeling_flash_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'transformers.modeling_utils'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "",
          "line": 39,
          "column": 0,
          "endLine": 39,
          "endColumn": 38,
          "path": "modeling_flash_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'transformers.utils'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "",
          "line": 40,
          "column": 0,
          "endLine": 40,
          "endColumn": 69,
          "path": "modeling_flash_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'transformers.models.llama.configuration_llama'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "",
          "line": 42,
          "column": 0,
          "endLine": 42,
          "endColumn": 80,
          "path": "modeling_flash_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.inference.llamao.distributed_attention'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "",
          "line": 43,
          "column": 0,
          "endLine": 43,
          "endColumn": 80,
          "path": "modeling_flash_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'flash_attn'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "",
          "line": 44,
          "column": 0,
          "endLine": 44,
          "endColumn": 58,
          "path": "modeling_flash_llama.py",
          "symbol": "import-error",
          "message": "Unable to import 'flash_attn.bert_padding'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "",
          "line": 49,
          "column": 4,
          "endLine": 51,
          "endColumn": 5,
          "path": "modeling_flash_llama.py",
          "symbol": "raise-missing-from",
          "message": "Consider explicitly re-raising using 'except ImportError as exc' and 'raise ImportError('Please install RoPE kernels: `pip install git+https://github.com/HazyResearch/flash-attention.git#subdirectory=csrc/rotary`') from exc'",
          "message-id": "W0707"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "LlamaModel.forward",
          "line": 671,
          "column": 49,
          "endLine": 671,
          "endColumn": 62,
          "path": "modeling_flash_llama.py",
          "symbol": "possibly-used-before-assignment",
          "message": "Possibly using variable 'unpad_indices' before assignment",
          "message-id": "E0606"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "LlamaModel.forward",
          "line": 625,
          "column": 12,
          "endLine": 625,
          "endColumn": 22,
          "path": "modeling_flash_llama.py",
          "symbol": "unused-variable",
          "message": "Unused variable 'batch_size'",
          "message-id": "W0612"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "LlamaModel.forward",
          "line": 625,
          "column": 24,
          "endLine": 625,
          "endColumn": 34,
          "path": "modeling_flash_llama.py",
          "symbol": "unused-variable",
          "message": "Unused variable 'seq_length'",
          "message-id": "W0612"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.modeling_flash_llama",
          "obj": "LlamaForCausalLM.forward",
          "line": 779,
          "column": 8,
          "endLine": 779,
          "endColumn": 40,
          "path": "modeling_flash_llama.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'unpadded_lengths'",
          "message-id": "W0613"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "",
          "line": 4,
          "column": 0,
          "endLine": 4,
          "endColumn": 11,
          "path": "bm25_retrieval.py",
          "symbol": "import-error",
          "message": "Unable to import 'jedi'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "",
          "line": 8,
          "column": 0,
          "endLine": 8,
          "endColumn": 29,
          "path": "bm25_retrieval.py",
          "symbol": "import-error",
          "message": "Unable to import 'filelock'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "",
          "line": 10,
          "column": 0,
          "endLine": 10,
          "endColumn": 49,
          "path": "bm25_retrieval.py",
          "symbol": "import-error",
          "message": "Unable to import 'datasets'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "",
          "line": 11,
          "column": 0,
          "endLine": 11,
          "endColumn": 49,
          "path": "bm25_retrieval.py",
          "symbol": "import-error",
          "message": "Unable to import 'pyserini.search.lucene'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "",
          "line": 12,
          "column": 0,
          "endLine": 12,
          "endColumn": 20,
          "path": "bm25_retrieval.py",
          "symbol": "import-error",
          "message": "Unable to import 'git'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "",
          "line": 17,
          "column": 0,
          "endLine": 17,
          "endColumn": 77,
          "path": "bm25_retrieval.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.inference.make_datasets.utils'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "ContextManager.__enter__",
          "line": 59,
          "column": 12,
          "endLine": 59,
          "endColumn": 67,
          "path": "bm25_retrieval.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "ContextManager.get_readme_files.<lambda>",
          "line": 66,
          "column": 28,
          "endLine": 66,
          "endColumn": 55,
          "path": "bm25_retrieval.py",
          "symbol": "unnecessary-lambda",
          "message": "Lambda may not be necessary",
          "message-id": "W0108"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "file_name_and_contents",
          "line": 76,
          "column": 9,
          "endLine": 76,
          "endColumn": 23,
          "path": "bm25_retrieval.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "file_name_and_documentation",
          "line": 96,
          "column": 11,
          "endLine": 96,
          "endColumn": 20,
          "path": "bm25_retrieval.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "file_name_and_documentation",
          "line": 84,
          "column": 13,
          "endLine": 84,
          "endColumn": 27,
          "path": "bm25_retrieval.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "file_name_and_documentation",
          "line": 98,
          "column": 8,
          "endLine": 98,
          "endColumn": 88,
          "path": "bm25_retrieval.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "file_name_and_documentation",
          "line": 99,
          "column": 13,
          "endLine": 99,
          "endColumn": 27,
          "path": "bm25_retrieval.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "file_name_and_docs_jedi",
          "line": 106,
          "column": 9,
          "endLine": 106,
          "endColumn": 23,
          "path": "bm25_retrieval.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "file_name_and_docs_jedi",
          "line": 138,
          "column": 11,
          "endLine": 138,
          "endColumn": 20,
          "path": "bm25_retrieval.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "file_name_and_docs_jedi",
          "line": 136,
          "column": 12,
          "endLine": 137,
          "endColumn": 24,
          "path": "bm25_retrieval.py",
          "symbol": "bare-except",
          "message": "No exception type(s) specified",
          "message-id": "W0702"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "file_name_and_docs_jedi",
          "line": 140,
          "column": 8,
          "endLine": 140,
          "endColumn": 88,
          "path": "bm25_retrieval.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "file_name_and_docs_jedi",
          "line": 115,
          "column": 8,
          "endLine": 115,
          "endColumn": 15,
          "path": "bm25_retrieval.py",
          "symbol": "unused-variable",
          "message": "Unused variable 'abspath'",
          "message-id": "W0612"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "clone_repo",
          "line": 169,
          "column": 8,
          "endLine": 169,
          "endColumn": 52,
          "path": "bm25_retrieval.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "make_index",
          "line": 228,
          "column": 9,
          "endLine": 228,
          "endColumn": 34,
          "path": "bm25_retrieval.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "make_index",
          "line": 263,
          "column": 8,
          "endLine": 263,
          "endColumn": 31,
          "path": "bm25_retrieval.py",
          "symbol": "raise-missing-from",
          "message": "Consider explicitly re-raising using 'except KeyboardInterrupt as exc' and 'raise KeyboardInterrupt from exc'",
          "message-id": "W0707"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "make_index",
          "line": 265,
          "column": 8,
          "endLine": 265,
          "endColumn": 64,
          "path": "bm25_retrieval.py",
          "symbol": "logging-not-lazy",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1201"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "make_index",
          "line": 268,
          "column": 8,
          "endLine": 268,
          "endColumn": 55,
          "path": "bm25_retrieval.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "make_index",
          "line": 269,
          "column": 8,
          "endLine": 272,
          "endColumn": 9,
          "path": "bm25_retrieval.py",
          "symbol": "broad-exception-raised",
          "message": "Raising too general exception: Exception",
          "message-id": "W0719"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "make_index",
          "line": 199,
          "column": 4,
          "endLine": 199,
          "endColumn": 9,
          "path": "bm25_retrieval.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'query'",
          "message-id": "W0613"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "make_index",
          "line": 260,
          "column": 8,
          "endLine": 260,
          "endColumn": 14,
          "path": "bm25_retrieval.py",
          "symbol": "unused-variable",
          "message": "Unused variable 'output'",
          "message-id": "W0612"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "get_remaining_instances",
          "line": 291,
          "column": 17,
          "endLine": 291,
          "endColumn": 34,
          "path": "bm25_retrieval.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "get_remaining_instances",
          "line": 296,
          "column": 12,
          "endLine": 298,
          "endColumn": 13,
          "path": "bm25_retrieval.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "search",
          "line": 343,
          "column": 11,
          "endLine": 343,
          "endColumn": 20,
          "path": "bm25_retrieval.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "search",
          "line": 332,
          "column": 19,
          "endLine": 332,
          "endColumn": 28,
          "path": "bm25_retrieval.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "search",
          "line": 344,
          "column": 8,
          "endLine": 344,
          "endColumn": 56,
          "path": "bm25_retrieval.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "search_indexes",
          "line": 367,
          "column": 17,
          "endLine": 367,
          "endColumn": 39,
          "path": "bm25_retrieval.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "get_missing_ids",
          "line": 372,
          "column": 9,
          "endLine": 372,
          "endColumn": 26,
          "path": "bm25_retrieval.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "get_index_paths_worker",
          "line": 409,
          "column": 4,
          "endLine": 411,
          "endColumn": 44,
          "path": "bm25_retrieval.py",
          "symbol": "bare-except",
          "message": "No exception type(s) specified",
          "message-id": "W0702"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "get_index_paths_worker",
          "line": 410,
          "column": 8,
          "endLine": 410,
          "endColumn": 83,
          "path": "bm25_retrieval.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "get_index_paths",
          "line": 421,
          "column": 4,
          "endLine": 421,
          "endColumn": 20,
          "path": "bm25_retrieval.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'output_file'",
          "message-id": "W0613"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "main",
          "line": 486,
          "column": 13,
          "endLine": 486,
          "endColumn": 76,
          "path": "bm25_retrieval.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "main",
          "line": 505,
          "column": 8,
          "endLine": 505,
          "endColumn": 46,
          "path": "bm25_retrieval.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "main",
          "line": 512,
          "column": 4,
          "endLine": 512,
          "endColumn": 70,
          "path": "bm25_retrieval.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "main",
          "line": 515,
          "column": 4,
          "endLine": 515,
          "endColumn": 72,
          "path": "bm25_retrieval.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "main",
          "line": 516,
          "column": 4,
          "endLine": 516,
          "endColumn": 60,
          "path": "bm25_retrieval.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.bm25_retrieval",
          "obj": "main",
          "line": 518,
          "column": 4,
          "endLine": 518,
          "endColumn": 42,
          "path": "bm25_retrieval.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.create_instance",
          "obj": "",
          "line": 8,
          "column": 0,
          "endLine": 8,
          "endColumn": 14,
          "path": "create_instance.py",
          "symbol": "import-error",
          "message": "Unable to import 'unidiff'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.create_instance",
          "obj": "",
          "line": 11,
          "column": 0,
          "endLine": 11,
          "endColumn": 77,
          "path": "create_instance.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.inference.make_datasets.tokenize_dataset'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.create_instance",
          "obj": "",
          "line": 12,
          "column": 0,
          "endLine": 15,
          "endColumn": 1,
          "path": "create_instance.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.inference.make_datasets.utils'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_instance",
          "obj": "make_code_text_edits_only",
          "line": 139,
          "column": 49,
          "endLine": 139,
          "endColumn": 65,
          "path": "create_instance.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'add_line_numbers'",
          "message-id": "W0613"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_instance",
          "obj": "ingest_files",
          "line": 290,
          "column": 13,
          "endLine": 290,
          "endColumn": 27,
          "path": "create_instance.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_instance",
          "obj": "add_retrieval_results",
          "line": 312,
          "column": 54,
          "endLine": 312,
          "endColumn": 82,
          "path": "create_instance.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_instance",
          "obj": "add_retrieval_results",
          "line": 322,
          "column": 12,
          "endLine": 322,
          "endColumn": 84,
          "path": "create_instance.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_instance",
          "obj": "add_retrieval_results",
          "line": 304,
          "column": 62,
          "endLine": 304,
          "endColumn": 73,
          "path": "create_instance.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'file_source'",
          "message-id": "W0613"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_instance",
          "obj": "add_text_inputs",
          "line": 373,
          "column": 13,
          "endLine": 373,
          "endColumn": 32,
          "path": "create_instance.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_instance",
          "obj": "add_text_inputs",
          "line": 377,
          "column": 8,
          "endLine": 377,
          "endColumn": 78,
          "path": "create_instance.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_instance",
          "obj": "add_text_inputs",
          "line": 378,
          "column": 31,
          "endLine": 378,
          "endColumn": 55,
          "path": "create_instance.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_instance",
          "obj": "add_text_inputs",
          "line": 380,
          "column": 31,
          "endLine": 380,
          "endColumn": 55,
          "path": "create_instance.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_instance",
          "obj": "add_text_inputs",
          "line": 398,
          "column": 8,
          "endLine": 398,
          "endColumn": 72,
          "path": "create_instance.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_instance",
          "obj": "add_text_inputs",
          "line": 484,
          "column": 23,
          "endLine": 484,
          "endColumn": 32,
          "path": "create_instance.py",
          "symbol": "broad-exception-caught",
          "message": "Catching too general exception Exception",
          "message-id": "W0718"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.create_text_dataset",
          "obj": "",
          "line": 12,
          "column": 0,
          "endLine": 12,
          "endColumn": 71,
          "path": "create_text_dataset.py",
          "symbol": "import-error",
          "message": "Unable to import 'datasets'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.create_text_dataset",
          "obj": "",
          "line": 15,
          "column": 0,
          "endLine": 18,
          "endColumn": 1,
          "path": "create_text_dataset.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.inference.make_datasets.create_instance'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.create_text_dataset",
          "obj": "",
          "line": 19,
          "column": 0,
          "endLine": 19,
          "endColumn": 77,
          "path": "create_text_dataset.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.inference.make_datasets.tokenize_dataset'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_text_dataset",
          "obj": "load_jsonl_file",
          "line": 29,
          "column": 13,
          "endLine": 29,
          "endColumn": 27,
          "path": "create_text_dataset.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_text_dataset",
          "obj": "load_jsonl_file",
          "line": 32,
          "column": 13,
          "endLine": 32,
          "endColumn": 27,
          "path": "create_text_dataset.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_text_dataset",
          "obj": "get_training_and_eval_instances",
          "line": 53,
          "column": 4,
          "endLine": 53,
          "endColumn": 61,
          "path": "create_text_dataset.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_text_dataset",
          "obj": "get_training_and_eval_instances",
          "line": 54,
          "column": 4,
          "endLine": 54,
          "endColumn": 56,
          "path": "create_text_dataset.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_text_dataset",
          "obj": "extract_fields",
          "line": 61,
          "column": 8,
          "endLine": 61,
          "endColumn": 52,
          "path": "create_text_dataset.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_text_dataset",
          "obj": "extract_fields",
          "line": 65,
          "column": 8,
          "endLine": 65,
          "endColumn": 54,
          "path": "create_text_dataset.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_text_dataset",
          "obj": "main",
          "line": 146,
          "column": 20,
          "endLine": 148,
          "endColumn": 21,
          "path": "create_text_dataset.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_text_dataset",
          "obj": "main",
          "line": 158,
          "column": 4,
          "endLine": 158,
          "endColumn": 54,
          "path": "create_text_dataset.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_text_dataset",
          "obj": "main",
          "line": 183,
          "column": 8,
          "endLine": 183,
          "endColumn": 48,
          "path": "create_text_dataset.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_text_dataset",
          "obj": "main",
          "line": 210,
          "column": 13,
          "endLine": 210,
          "endColumn": 40,
          "path": "create_text_dataset.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_text_dataset",
          "obj": "main",
          "line": 222,
          "column": 12,
          "endLine": 224,
          "endColumn": 13,
          "path": "create_text_dataset.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_text_dataset",
          "obj": "main",
          "line": 238,
          "column": 8,
          "endLine": 238,
          "endColumn": 75,
          "path": "create_text_dataset.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.create_text_dataset",
          "obj": "main",
          "line": 253,
          "column": 4,
          "endLine": 253,
          "endColumn": 52,
          "path": "create_text_dataset.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.eval_retrieval",
          "obj": "",
          "line": 7,
          "column": 0,
          "endLine": 7,
          "endColumn": 66,
          "path": "eval_retrieval.py",
          "symbol": "import-error",
          "message": "Unable to import 'datasets'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.eval_retrieval",
          "obj": "main",
          "line": 21,
          "column": 4,
          "endLine": 22,
          "endColumn": 65,
          "path": "eval_retrieval.py",
          "symbol": "bare-except",
          "message": "No exception type(s) specified",
          "message-id": "W0702"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.tokenize_dataset",
          "obj": "",
          "line": 10,
          "column": 0,
          "endLine": 10,
          "endColumn": 15,
          "path": "tokenize_dataset.py",
          "symbol": "import-error",
          "message": "Unable to import 'tiktoken'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.tokenize_dataset",
          "obj": "",
          "line": 11,
          "column": 0,
          "endLine": 11,
          "endColumn": 66,
          "path": "tokenize_dataset.py",
          "symbol": "import-error",
          "message": "Unable to import 'datasets'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.tokenize_dataset",
          "obj": "",
          "line": 13,
          "column": 0,
          "endLine": 13,
          "endColumn": 39,
          "path": "tokenize_dataset.py",
          "symbol": "import-error",
          "message": "Unable to import 'transformers'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.tokenize_dataset",
          "obj": "extract_test_fields",
          "line": 74,
          "column": 34,
          "endLine": 74,
          "endColumn": 48,
          "path": "tokenize_dataset.py",
          "symbol": "unused-argument",
          "message": "Unused argument 'tokenizer_name'",
          "message-id": "W0613"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.tokenize_dataset",
          "obj": "main.<lambda>",
          "line": 148,
          "column": 20,
          "endLine": 148,
          "endColumn": 34,
          "path": "tokenize_dataset.py",
          "symbol": "possibly-used-before-assignment",
          "message": "Possibly using variable 'tokenizer_func' before assignment",
          "message-id": "E0606"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.tokenize_dataset",
          "obj": "main.<lambda>",
          "line": 149,
          "column": 20,
          "endLine": 149,
          "endColumn": 29,
          "path": "tokenize_dataset.py",
          "symbol": "possibly-used-before-assignment",
          "message": "Possibly using variable 'eos_token' before assignment",
          "message-id": "E0606"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.tokenize_dataset",
          "obj": "main",
          "line": 171,
          "column": 12,
          "endLine": 171,
          "endColumn": 69,
          "path": "tokenize_dataset.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.tokenize_dataset",
          "obj": "main",
          "line": 207,
          "column": 4,
          "endLine": 207,
          "endColumn": 45,
          "path": "tokenize_dataset.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "",
          "line": 12,
          "column": 0,
          "endLine": 16,
          "endColumn": 1,
          "path": "get_versions.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.versioning.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "",
          "line": 17,
          "column": 0,
          "endLine": 17,
          "endColumn": 68,
          "path": "get_versions.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.versioning.utils'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "get_version",
          "line": 84,
          "column": 16,
          "endLine": 84,
          "endColumn": 71,
          "path": "get_versions.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "get_version",
          "line": 85,
          "column": 21,
          "endLine": 85,
          "endColumn": 42,
          "path": "get_versions.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "get_version",
          "line": 94,
          "column": 24,
          "endLine": 94,
          "endColumn": 41,
          "path": "get_versions.py",
          "symbol": "missing-timeout",
          "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
          "message-id": "W3101"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "get_versions_from_build",
          "line": 167,
          "column": 20,
          "endLine": 171,
          "endColumn": 9,
          "path": "get_versions.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "get_versions_from_build",
          "line": 173,
          "column": 12,
          "endLine": 173,
          "endColumn": 72,
          "path": "get_versions.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "get_versions_from_build",
          "line": 177,
          "column": 22,
          "endLine": 181,
          "endColumn": 9,
          "path": "get_versions.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "get_versions_from_build",
          "line": 183,
          "column": 12,
          "endLine": 183,
          "endColumn": 76,
          "path": "get_versions.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "get_versions_from_build",
          "line": 189,
          "column": 8,
          "endLine": 189,
          "endColumn": 84,
          "path": "get_versions.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "get_versions_from_build",
          "line": 192,
          "column": 9,
          "endLine": 192,
          "endColumn": 29,
          "path": "get_versions.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "get_versions_from_web",
          "line": 212,
          "column": 12,
          "endLine": 212,
          "endColumn": 88,
          "path": "get_versions.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "get_versions_from_web",
          "line": 214,
          "column": 12,
          "endLine": 214,
          "endColumn": 74,
          "path": "get_versions.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "get_versions_from_web",
          "line": 216,
          "column": 9,
          "endLine": 216,
          "endColumn": 29,
          "path": "get_versions.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "merge_results",
          "line": 234,
          "column": 13,
          "endLine": 234,
          "endColumn": 41,
          "path": "get_versions.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "merge_results",
          "line": 244,
          "column": 9,
          "endLine": 244,
          "endColumn": 43,
          "path": "get_versions.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "merge_results",
          "line": 246,
          "column": 4,
          "endLine": 248,
          "endColumn": 5,
          "path": "get_versions.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "main",
          "line": 252,
          "column": 9,
          "endLine": 252,
          "endColumn": 13,
          "path": "get_versions.py",
          "symbol": "redefined-outer-name",
          "message": "Redefining name 'args' from outer scope (line 426)",
          "message-id": "W0621"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "main",
          "line": 261,
          "column": 4,
          "endLine": 263,
          "endColumn": 5,
          "path": "get_versions.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "main",
          "line": 264,
          "column": 4,
          "endLine": 266,
          "endColumn": 5,
          "path": "get_versions.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "main",
          "line": 301,
          "column": 12,
          "endLine": 301,
          "endColumn": 67,
          "path": "get_versions.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "main",
          "line": 303,
          "column": 12,
          "endLine": 305,
          "endColumn": 13,
          "path": "get_versions.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "main",
          "line": 318,
          "column": 12,
          "endLine": 320,
          "endColumn": 13,
          "path": "get_versions.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "main",
          "line": 326,
          "column": 12,
          "endLine": 328,
          "endColumn": 13,
          "path": "get_versions.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "main",
          "line": 332,
          "column": 12,
          "endLine": 332,
          "endColumn": 82,
          "path": "get_versions.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions",
          "obj": "main",
          "line": 338,
          "column": 12,
          "endLine": 340,
          "endColumn": 13,
          "path": "get_versions.py",
          "symbol": "logging-fstring-interpolation",
          "message": "Use lazy % formatting in logging functions",
          "message-id": "W1203"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_versions_astropy",
          "obj": "",
          "line": 10,
          "column": 0,
          "endLine": 10,
          "endColumn": 31,
          "path": "get_versions_astropy.py",
          "symbol": "import-error",
          "message": "Unable to import 'utils'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions_astropy",
          "obj": "",
          "line": 18,
          "column": 7,
          "endLine": 18,
          "endColumn": 72,
          "path": "get_versions_astropy.py",
          "symbol": "missing-timeout",
          "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
          "message-id": "W3101"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions_astropy",
          "obj": "",
          "line": 66,
          "column": 39,
          "endLine": 66,
          "endColumn": 40,
          "path": "get_versions_astropy.py",
          "symbol": "undefined-loop-variable",
          "message": "Using possibly undefined loop variable 't'",
          "message-id": "W0631"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions_astropy",
          "obj": "",
          "line": 69,
          "column": 5,
          "endLine": 72,
          "endColumn": 1,
          "path": "get_versions_astropy.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_versions_matplotlib",
          "obj": "",
          "line": 10,
          "column": 0,
          "endLine": 10,
          "endColumn": 31,
          "path": "get_versions_matplotlib.py",
          "symbol": "import-error",
          "message": "Unable to import 'utils'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions_matplotlib",
          "obj": "",
          "line": 18,
          "column": 7,
          "endLine": 18,
          "endColumn": 86,
          "path": "get_versions_matplotlib.py",
          "symbol": "missing-timeout",
          "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
          "message-id": "W3101"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions_matplotlib",
          "obj": "",
          "line": 53,
          "column": 5,
          "endLine": 56,
          "endColumn": 1,
          "path": "get_versions_matplotlib.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_versions_pvlib-python",
          "obj": "",
          "line": 9,
          "column": 0,
          "endLine": 9,
          "endColumn": 31,
          "path": "get_versions_pvlib-python.py",
          "symbol": "import-error",
          "message": "Unable to import 'utils'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions_pvlib-python",
          "obj": "",
          "line": 23,
          "column": 7,
          "endLine": 23,
          "endColumn": 28,
          "path": "get_versions_pvlib-python.py",
          "symbol": "missing-timeout",
          "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
          "message-id": "W3101"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions_pvlib-python",
          "obj": "",
          "line": 67,
          "column": 39,
          "endLine": 67,
          "endColumn": 40,
          "path": "get_versions_pvlib-python.py",
          "symbol": "undefined-loop-variable",
          "message": "Using possibly undefined loop variable 't'",
          "message-id": "W0631"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions_pvlib-python",
          "obj": "",
          "line": 70,
          "column": 5,
          "endLine": 70,
          "endColumn": 34,
          "path": "get_versions_pvlib-python.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_versions_pydicom",
          "obj": "",
          "line": 5,
          "column": 0,
          "endLine": 5,
          "endColumn": 29,
          "path": "get_versions_pydicom.py",
          "symbol": "import-error",
          "message": "Unable to import 'bs4'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_versions_pydicom",
          "obj": "",
          "line": 8,
          "column": 0,
          "endLine": 8,
          "endColumn": 31,
          "path": "get_versions_pydicom.py",
          "symbol": "import-error",
          "message": "Unable to import 'utils'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions_pydicom",
          "obj": "",
          "line": 14,
          "column": 7,
          "endLine": 14,
          "endColumn": 75,
          "path": "get_versions_pydicom.py",
          "symbol": "missing-timeout",
          "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
          "message-id": "W3101"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_versions_pydicom",
          "obj": "",
          "line": 27,
          "column": 19,
          "endLine": 27,
          "endColumn": 36,
          "path": "get_versions_pydicom.py",
          "symbol": "no-member",
          "message": "Module 'datetime' has no 'strptime' member",
          "message-id": "E1101"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions_pydicom",
          "obj": "",
          "line": 43,
          "column": 5,
          "endLine": 43,
          "endColumn": 36,
          "path": "get_versions_pydicom.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_versions_sqlfluff",
          "obj": "",
          "line": 5,
          "column": 0,
          "endLine": 5,
          "endColumn": 28,
          "path": "get_versions_sqlfluff.py",
          "symbol": "import-error",
          "message": "Unable to import 'ghapi.core'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_versions_sqlfluff",
          "obj": "",
          "line": 8,
          "column": 0,
          "endLine": 8,
          "endColumn": 31,
          "path": "get_versions_sqlfluff.py",
          "symbol": "import-error",
          "message": "Unable to import 'utils'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions_sqlfluff",
          "obj": "process",
          "line": 38,
          "column": 8,
          "endLine": 38,
          "endColumn": 15,
          "path": "get_versions_sqlfluff.py",
          "symbol": "redefined-outer-name",
          "message": "Redefining name 'version' from outer scope (line 58)",
          "message-id": "W0621"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions_sqlfluff",
          "obj": "",
          "line": 85,
          "column": 5,
          "endLine": 88,
          "endColumn": 1,
          "path": "get_versions_sqlfluff.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions_sqlfluff",
          "obj": "",
          "line": 92,
          "column": 22,
          "endLine": 92,
          "endColumn": 70,
          "path": "get_versions_sqlfluff.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.get_versions_xarray",
          "obj": "",
          "line": 10,
          "column": 0,
          "endLine": 10,
          "endColumn": 31,
          "path": "get_versions_xarray.py",
          "symbol": "import-error",
          "message": "Unable to import 'utils'",
          "message-id": "E0401"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions_xarray",
          "obj": "",
          "line": 18,
          "column": 7,
          "endLine": 18,
          "endColumn": 71,
          "path": "get_versions_xarray.py",
          "symbol": "missing-timeout",
          "message": "Missing timeout argument for method 'requests.get' can cause your program to hang indefinitely",
          "message-id": "W3101"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions_xarray",
          "obj": "",
          "line": 40,
          "column": 8,
          "endLine": 41,
          "endColumn": 20,
          "path": "get_versions_xarray.py",
          "symbol": "bare-except",
          "message": "No exception type(s) specified",
          "message-id": "W0702"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.get_versions_xarray",
          "obj": "",
          "line": 58,
          "column": 5,
          "endLine": 61,
          "endColumn": 1,
          "path": "get_versions_xarray.py",
          "symbol": "unspecified-encoding",
          "message": "Using open without explicitly specifying an encoding",
          "message-id": "W1514"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.test_cli",
          "obj": "test_smoke_test",
          "line": 6,
          "column": 13,
          "endLine": 6,
          "endColumn": 53,
          "path": "test_cli.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.test_cli",
          "obj": "test_one_instance",
          "line": 26,
          "column": 13,
          "endLine": 26,
          "endColumn": 53,
          "path": "test_cli.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.test_collect_cli",
          "obj": "test_collect_smoke_test",
          "line": 7,
          "column": 13,
          "endLine": 7,
          "endColumn": 53,
          "path": "test_collect_cli.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.test_collect_cli",
          "obj": "test_collect_one",
          "line": 24,
          "column": 13,
          "endLine": 24,
          "endColumn": 53,
          "path": "test_collect_cli.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.test_collect_cli",
          "obj": "test_collect_ds",
          "line": 39,
          "column": 13,
          "endLine": 39,
          "endColumn": 53,
          "path": "test_collect_cli.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "warning",
          "module": "scan_cyeftmaj.test_collect_cli",
          "obj": "test_collect_get_issues",
          "line": 57,
          "column": 13,
          "endLine": 57,
          "endColumn": 53,
          "path": "test_collect_cli.py",
          "symbol": "subprocess-run-check",
          "message": "'subprocess.run' used without explicitly defining the value for 'check'.",
          "message-id": "W1510"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.test_evaluation",
          "obj": "",
          "line": 3,
          "column": 0,
          "endLine": 3,
          "endColumn": 13,
          "path": "test_evaluation.py",
          "symbol": "import-error",
          "message": "Unable to import 'docker'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.test_evaluation",
          "obj": "",
          "line": 5,
          "column": 0,
          "endLine": 10,
          "endColumn": 1,
          "path": "test_evaluation.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.constants'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.test_evaluation",
          "obj": "",
          "line": 11,
          "column": 0,
          "endLine": 11,
          "endColumn": 59,
          "path": "test_evaluation.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.run_evaluation'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.test_harness_utils",
          "obj": "",
          "line": 2,
          "column": 0,
          "endLine": 2,
          "endColumn": 49,
          "path": "test_harness_utils.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.utils'",
          "message-id": "E0401"
        },
        {
          "type": "error",
          "module": "scan_cyeftmaj.test_harness_utils",
          "obj": "",
          "line": 3,
          "column": 0,
          "endLine": 3,
          "endColumn": 87,
          "path": "test_harness_utils.py",
          "symbol": "import-error",
          "message": "Unable to import 'swebench.harness.test_spec.python'",
          "message-id": "E0401"
        }
      ],
      "stderr": ""
    },
    "mypy": {
      "count": 1,
      "findings": [
        "__init__.py: error: Duplicate module named \"scan_cyeftmaj\" (also at \"C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\__init__.py\")"
      ],
      "stderr": ""
    },
    "bandit": {
      "count": 121,
      "findings": [
        {
          "code": "6 import traceback\n7 import subprocess\n8 from filelock import FileLock\n",
          "col_offset": 0,
          "end_col_offset": 17,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Consider possible security implications associated with the subprocess module.",
          "line_number": 7,
          "line_range": [
            7
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/blacklists/blacklist_imports.html#b404-import-subprocess",
          "test_id": "B404",
          "test_name": "blacklist"
        },
        {
          "code": "135                     text += f\"{docstring}\\n\\n\"\n136             except:\n137                 continue\n138     except Exception as e:\n",
          "col_offset": 12,
          "end_col_offset": 24,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Try, Except, Continue detected.",
          "line_number": 136,
          "line_range": [
            136,
            137
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b112_try_except_continue.html",
          "test_id": "B112",
          "test_name": "try_except_continue"
        },
        {
          "code": "253     try:\n254         proc = subprocess.Popen(\n255             cmd,\n256             stdout=subprocess.PIPE,\n257             stderr=subprocess.PIPE,\n258             universal_newlines=True,\n259         )\n260         output, error = proc.communicate()\n",
          "col_offset": 15,
          "end_col_offset": 9,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 254,
          "line_range": [
            254,
            255,
            256,
            257,
            258,
            259
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "475     else:\n476         dataset = load_dataset(dataset_name_or_path)\n477         dataset_name = dataset_name_or_path.replace(\"/\", \"__\")\n",
          "col_offset": 18,
          "end_col_offset": 52,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 494,
            "link": "https://cwe.mitre.org/data/definitions/494.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
          "line_number": 476,
          "line_range": [
            476
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b615_huggingface_unsafe_download.html",
          "test_id": "B615",
          "test_name": "huggingface_unsafe_download"
        },
        {
          "code": "485         instances += list(dataset[split])\n486     python = subprocess.run(\"which python\", shell=True, capture_output=True)\n487     python = python.stdout.decode(\"utf-8\").strip()\n",
          "col_offset": 13,
          "end_col_offset": 76,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Starting a process with a partial executable path",
          "line_number": 486,
          "line_range": [
            486
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b607_start_process_with_partial_path.html",
          "test_id": "B607",
          "test_name": "start_process_with_partial_path"
        },
        {
          "code": "485         instances += list(dataset[split])\n486     python = subprocess.run(\"which python\", shell=True, capture_output=True)\n487     python = python.stdout.decode(\"utf-8\").strip()\n",
          "col_offset": 13,
          "end_col_offset": 76,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\bm25_retrieval.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call with shell=True seems safe, but may be changed in the future, consider rewriting without shell",
          "line_number": 486,
          "line_range": [
            486
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b602_subprocess_popen_with_shell_equals_true.html",
          "test_id": "B602",
          "test_name": "subprocess_popen_with_shell_equals_true"
        },
        {
          "code": "1 import re\n2 import xml.etree.ElementTree as ET\n3 \n",
          "col_offset": 0,
          "end_col_offset": 34,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\c.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 20,
            "link": "https://cwe.mitre.org/data/definitions/20.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Using xml.etree.ElementTree to parse untrusted XML data is known to be vulnerable to XML attacks. Replace xml.etree.ElementTree with the equivalent defusedxml package, or make sure defusedxml.defuse_stdlib() is called.",
          "line_number": 2,
          "line_range": [
            2
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/blacklists/blacklist_imports.html#b405-import-xml-etree",
          "test_id": "B405",
          "test_name": "blacklist"
        },
        {
          "code": "72         xml_string = log[start_index:end_index]\n73         root = ET.fromstring(xml_string)\n74 \n",
          "col_offset": 15,
          "end_col_offset": 40,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\c.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 20,
            "link": "https://cwe.mitre.org/data/definitions/20.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Using xml.etree.ElementTree.fromstring to parse untrusted XML data is known to be vulnerable to XML attacks. Replace xml.etree.ElementTree.fromstring with its defusedxml equivalent function or make sure defusedxml.defuse_stdlib() is called",
          "line_number": 73,
          "line_range": [
            73
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/blacklists/blacklist_calls.html#b313-b320-xml-bad-elementtree",
          "test_id": "B314",
          "test_name": "blacklist"
        },
        {
          "code": "2 \n3 import subprocess\n4 \n",
          "col_offset": 0,
          "end_col_offset": 17,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\call_make_repo.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Consider possible security implications associated with the subprocess module.",
          "line_number": 3,
          "line_range": [
            3
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/blacklists/blacklist_imports.html#b404-import-subprocess",
          "test_id": "B404",
          "test_name": "blacklist"
        },
        {
          "code": "10         f\"./make_repo.sh {repo}\",\n11         shell=True,\n12         stdout=subprocess.DEVNULL,\n13         stderr=subprocess.DEVNULL,\n14     )\n15     if out_make.returncode != 0:\n16         print(f\"Error making mirror repo for {repo}\")\n17     else:\n",
          "col_offset": 15,
          "end_col_offset": 5,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\call_make_repo.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "HIGH",
          "issue_text": "subprocess call with shell=True identified, security issue.",
          "line_number": 11,
          "line_range": [
            9,
            10,
            11,
            12,
            13,
            14
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b602_subprocess_popen_with_shell_equals_true.html",
          "test_id": "B602",
          "test_name": "subprocess_popen_with_shell_equals_true"
        },
        {
          "code": "308     retrieval_results_path = Path(retrieval_file)\n309     assert retrieval_results_path.exists(), (\n310         f\"Retrieval results not found at {retrieval_results_path}\"\n311     )\n312     retrieval_results = [json.loads(line) for line in open(retrieval_results_path)]\n",
          "col_offset": 4,
          "end_col_offset": 5,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 309,
          "line_range": [
            309,
            310,
            311
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "361     \"\"\"\n362     assert progress_file is not None, \"progress_file is required\"\n363 \n",
          "col_offset": 4,
          "end_col_offset": 65,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 362,
          "line_range": [
            362
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "383         if max_context_len is not None:\n384             assert tokenizer_name is not None, (\n385                 \"Must specify tokenizer_name if using max_context_len\"\n386             )\n387             tokenizer, tokenizer_func = TOKENIZER_FUNCS[tokenizer_name]\n",
          "col_offset": 12,
          "end_col_offset": 13,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 384,
          "line_range": [
            384,
            385,
            386
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "401         with TemporaryDirectory(\n402             dir=\"/scratch\" if os.path.exists(\"/scratch\") else \"/tmp\"\n403         ) as root_dir:\n",
          "col_offset": 62,
          "end_col_offset": 68,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_instance.py",
          "issue_confidence": "MEDIUM",
          "issue_cwe": {
            "id": 377,
            "link": "https://cwe.mitre.org/data/definitions/377.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Probable insecure usage of temp file/directory.",
          "line_number": 402,
          "line_range": [
            402
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b108_hardcoded_tmp_directory.html",
          "test_id": "B108",
          "test_name": "hardcoded_tmp_directory"
        },
        {
          "code": "76         hub_token = os.environ.get(\"HUGGING_FACE_HUB_TOKEN\", None)\n77         assert hub_token is not None, (\n78             \"Must provide HUGGING_FACE_HUB_TOKEN to push to the Hub\"\n79         )\n80         assert output_dir is None, \"Cannot provide output_dir if pushing to the Hub\"\n",
          "col_offset": 8,
          "end_col_offset": 9,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_text_dataset.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 77,
          "line_range": [
            77,
            78,
            79
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "79         )\n80         assert output_dir is None, \"Cannot provide output_dir if pushing to the Hub\"\n81     if max_context_len is not None:\n",
          "col_offset": 8,
          "end_col_offset": 84,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_text_dataset.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 80,
          "line_range": [
            80
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "81     if max_context_len is not None:\n82         assert tokenizer_name is not None\n83     if push_to_hub_user is None and not Path(output_dir).exists():\n",
          "col_offset": 8,
          "end_col_offset": 41,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_text_dataset.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 82,
          "line_range": [
            82
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "85     if max_context_len is not None:\n86         assert file_source not in {\"all\", \"oracle\"}, (\n87             \"Cannot use max_context_len with oracle or all file sources\"\n88         )\n89         assert tokenizer_name is not None, (\n",
          "col_offset": 8,
          "end_col_offset": 9,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_text_dataset.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 86,
          "line_range": [
            86,
            87,
            88
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "88         )\n89         assert tokenizer_name is not None, (\n90             \"Must provide tokenizer_name if max_context_len is not None\"\n91         )\n92     if k is not None:\n",
          "col_offset": 8,
          "end_col_offset": 9,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_text_dataset.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 89,
          "line_range": [
            89,
            90,
            91
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "92     if k is not None:\n93         assert file_source not in {\"all\", \"oracle\"}, (\n94             \"Cannot use max_context_len with oracle or all file sources\"\n95         )\n96     return hub_token if push_to_hub_user is not None else None\n",
          "col_offset": 8,
          "end_col_offset": 9,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_text_dataset.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 93,
          "line_range": [
            93,
            94,
            95
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "155         if Path(dataset_name_or_path).exists()\n156         else load_dataset(dataset_name_or_path)\n157     )\n",
          "col_offset": 13,
          "end_col_offset": 47,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\create_text_dataset.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 494,
            "link": "https://cwe.mitre.org/data/definitions/494.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
          "line_number": 156,
          "line_range": [
            156
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b615_huggingface_unsafe_download.html",
          "test_id": "B615",
          "test_name": "huggingface_unsafe_download"
        },
        {
          "code": "100             url = f\"https://code.djangoproject.com/ticket/{match[1:]}\"\n101         if requests.get(url).status_code == 200:\n102             return True\n",
          "col_offset": 11,
          "end_col_offset": 28,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\criteria.py",
          "issue_confidence": "LOW",
          "issue_cwe": {
            "id": 400,
            "link": "https://cwe.mitre.org/data/definitions/400.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Call to requests without timeout",
          "line_number": 101,
          "line_range": [
            101
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b113_request_without_timeout.html",
          "test_id": "B113",
          "test_name": "request_without_timeout"
        },
        {
          "code": "3 import re\n4 import subprocess\n5 from collections.abc import Callable\n",
          "col_offset": 0,
          "end_col_offset": 17,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\default.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Consider possible security implications associated with the subprocess module.",
          "line_number": 4,
          "line_range": [
            4
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/blacklists/blacklist_imports.html#b404-import-subprocess",
          "test_id": "B404",
          "test_name": "blacklist"
        },
        {
          "code": "4 import os\n5 import subprocess\n6 \n",
          "col_offset": 0,
          "end_col_offset": 17,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\delete_gh_workflows.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Consider possible security implications associated with the subprocess module.",
          "line_number": 5,
          "line_range": [
            5
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/blacklists/blacklist_imports.html#b404-import-subprocess",
          "test_id": "B404",
          "test_name": "blacklist"
        },
        {
          "code": "15     # Get list of remote branches\n16     branches_command = subprocess.run(\n17         [\"git\", \"ls-remote\", \"--heads\", repo_url], capture_output=True, text=True\n18     )\n19     branches = branches_command.stdout.strip().split(\"\\n\")\n",
          "col_offset": 23,
          "end_col_offset": 5,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\delete_gh_workflows.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Starting a process with a partial executable path",
          "line_number": 16,
          "line_range": [
            16,
            17,
            18
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b607_start_process_with_partial_path.html",
          "test_id": "B607",
          "test_name": "start_process_with_partial_path"
        },
        {
          "code": "15     # Get list of remote branches\n16     branches_command = subprocess.run(\n17         [\"git\", \"ls-remote\", \"--heads\", repo_url], capture_output=True, text=True\n18     )\n19     branches = branches_command.stdout.strip().split(\"\\n\")\n",
          "col_offset": 23,
          "end_col_offset": 5,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\delete_gh_workflows.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 16,
          "line_range": [
            16,
            17,
            18
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "20     branches = [branch.split()[1] for branch in branches]\n21     subprocess.run(\n22         [\"git\", \"clone\", repo_url, \"temp_repo\"],\n23         stderr=subprocess.DEVNULL,\n24         stdout=subprocess.DEVNULL,\n25     )\n26 \n",
          "col_offset": 4,
          "end_col_offset": 5,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\delete_gh_workflows.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Starting a process with a partial executable path",
          "line_number": 21,
          "line_range": [
            21,
            22,
            23,
            24,
            25
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b607_start_process_with_partial_path.html",
          "test_id": "B607",
          "test_name": "start_process_with_partial_path"
        },
        {
          "code": "20     branches = [branch.split()[1] for branch in branches]\n21     subprocess.run(\n22         [\"git\", \"clone\", repo_url, \"temp_repo\"],\n23         stderr=subprocess.DEVNULL,\n24         stdout=subprocess.DEVNULL,\n25     )\n26 \n",
          "col_offset": 4,
          "end_col_offset": 5,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\delete_gh_workflows.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 21,
          "line_range": [
            21,
            22,
            23,
            24,
            25
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "32         branch = branch.split(\"/\")[-1]\n33         subprocess.run([\"git\", \"checkout\", branch])\n34 \n",
          "col_offset": 8,
          "end_col_offset": 51,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\delete_gh_workflows.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Starting a process with a partial executable path",
          "line_number": 33,
          "line_range": [
            33
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b607_start_process_with_partial_path.html",
          "test_id": "B607",
          "test_name": "start_process_with_partial_path"
        },
        {
          "code": "32         branch = branch.split(\"/\")[-1]\n33         subprocess.run([\"git\", \"checkout\", branch])\n34 \n",
          "col_offset": 8,
          "end_col_offset": 51,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\delete_gh_workflows.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 33,
          "line_range": [
            33
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "38             print(f\"Deleting .github/workflows folder from branch: {branch}\")\n39             subprocess.run([\"rm\", \"-rf\", workflows_path])\n40             subprocess.run([\"git\", \"add\", \"-A\"])\n",
          "col_offset": 12,
          "end_col_offset": 57,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\delete_gh_workflows.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Starting a process with a partial executable path",
          "line_number": 39,
          "line_range": [
            39
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b607_start_process_with_partial_path.html",
          "test_id": "B607",
          "test_name": "start_process_with_partial_path"
        },
        {
          "code": "38             print(f\"Deleting .github/workflows folder from branch: {branch}\")\n39             subprocess.run([\"rm\", \"-rf\", workflows_path])\n40             subprocess.run([\"git\", \"add\", \"-A\"])\n",
          "col_offset": 12,
          "end_col_offset": 57,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\delete_gh_workflows.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 39,
          "line_range": [
            39
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "39             subprocess.run([\"rm\", \"-rf\", workflows_path])\n40             subprocess.run([\"git\", \"add\", \"-A\"])\n41             subprocess.run([\"git\", \"commit\", \"-m\", \"Remove .github/workflows folder\"])\n",
          "col_offset": 12,
          "end_col_offset": 48,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\delete_gh_workflows.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Starting a process with a partial executable path",
          "line_number": 40,
          "line_range": [
            40
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b607_start_process_with_partial_path.html",
          "test_id": "B607",
          "test_name": "start_process_with_partial_path"
        },
        {
          "code": "39             subprocess.run([\"rm\", \"-rf\", workflows_path])\n40             subprocess.run([\"git\", \"add\", \"-A\"])\n41             subprocess.run([\"git\", \"commit\", \"-m\", \"Remove .github/workflows folder\"])\n",
          "col_offset": 12,
          "end_col_offset": 48,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\delete_gh_workflows.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 40,
          "line_range": [
            40
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "40             subprocess.run([\"git\", \"add\", \"-A\"])\n41             subprocess.run([\"git\", \"commit\", \"-m\", \"Remove .github/workflows folder\"])\n42             subprocess.run([\"git\", \"push\"])\n",
          "col_offset": 12,
          "end_col_offset": 86,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\delete_gh_workflows.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Starting a process with a partial executable path",
          "line_number": 41,
          "line_range": [
            41
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b607_start_process_with_partial_path.html",
          "test_id": "B607",
          "test_name": "start_process_with_partial_path"
        },
        {
          "code": "40             subprocess.run([\"git\", \"add\", \"-A\"])\n41             subprocess.run([\"git\", \"commit\", \"-m\", \"Remove .github/workflows folder\"])\n42             subprocess.run([\"git\", \"push\"])\n",
          "col_offset": 12,
          "end_col_offset": 86,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\delete_gh_workflows.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 41,
          "line_range": [
            41
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "41             subprocess.run([\"git\", \"commit\", \"-m\", \"Remove .github/workflows folder\"])\n42             subprocess.run([\"git\", \"push\"])\n43         else:\n",
          "col_offset": 12,
          "end_col_offset": 43,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\delete_gh_workflows.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Starting a process with a partial executable path",
          "line_number": 42,
          "line_range": [
            42
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b607_start_process_with_partial_path.html",
          "test_id": "B607",
          "test_name": "start_process_with_partial_path"
        },
        {
          "code": "41             subprocess.run([\"git\", \"commit\", \"-m\", \"Remove .github/workflows folder\"])\n42             subprocess.run([\"git\", \"push\"])\n43         else:\n",
          "col_offset": 12,
          "end_col_offset": 43,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\delete_gh_workflows.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 42,
          "line_range": [
            42
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "46     os.chdir(\"..\")\n47     subprocess.run([\"rm\", \"-rf\", \"temp_repo\"])\n48 \n",
          "col_offset": 4,
          "end_col_offset": 46,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\delete_gh_workflows.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Starting a process with a partial executable path",
          "line_number": 47,
          "line_range": [
            47
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b607_start_process_with_partial_path.html",
          "test_id": "B607",
          "test_name": "start_process_with_partial_path"
        },
        {
          "code": "46     os.chdir(\"..\")\n47     subprocess.run([\"rm\", \"-rf\", \"temp_repo\"])\n48 \n",
          "col_offset": 4,
          "end_col_offset": 46,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\delete_gh_workflows.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 47,
          "line_range": [
            47
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "21     except:\n22         dataset = load_dataset(dataset_name_or_path, split=split)\n23     print(\n",
          "col_offset": 18,
          "end_col_offset": 65,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\eval_retrieval.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 494,
            "link": "https://cwe.mitre.org/data/definitions/494.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
          "line_number": 22,
          "line_range": [
            22
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b615_huggingface_unsafe_download.html",
          "test_id": "B615",
          "test_name": "huggingface_unsafe_download"
        },
        {
          "code": "73                     pulls_count = int(issues[0][\"number\"])\n74                 except:\n75                     pass\n76 \n",
          "col_offset": 16,
          "end_col_offset": 24,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_top_pypi.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Try, Except, Pass detected.",
          "line_number": 74,
          "line_range": [
            74,
            75
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b110_try_except_pass.html",
          "test_id": "B110",
          "test_name": "try_except_pass"
        },
        {
          "code": "7 import requests\n8 import subprocess\n9 \n",
          "col_offset": 0,
          "end_col_offset": 17,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Consider possible security implications associated with the subprocess module.",
          "line_number": 8,
          "line_range": [
            8
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/blacklists/blacklist_imports.html#b404-import-subprocess",
          "test_id": "B404",
          "test_name": "blacklist"
        },
        {
          "code": "93             )\n94             init_text = requests.get(url).text\n95         version = _find_version_in_text(init_text, instance)\n",
          "col_offset": 24,
          "end_col_offset": 41,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "LOW",
          "issue_cwe": {
            "id": 400,
            "link": "https://cwe.mitre.org/data/definitions/400.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Call to requests without timeout",
          "line_number": 94,
          "line_range": [
            94
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b113_request_without_timeout.html",
          "test_id": "B113",
          "test_name": "request_without_timeout"
        },
        {
          "code": "157         # Reset repo to base commit\n158         subprocess.run(\n159             \"git restore .\", check=True, shell=True, stdout=subprocess.DEVNULL\n160         )\n161         subprocess.run(\n",
          "col_offset": 8,
          "end_col_offset": 9,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Starting a process with a partial executable path",
          "line_number": 158,
          "line_range": [
            158,
            159,
            160
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b607_start_process_with_partial_path.html",
          "test_id": "B607",
          "test_name": "start_process_with_partial_path"
        },
        {
          "code": "158         subprocess.run(\n159             \"git restore .\", check=True, shell=True, stdout=subprocess.DEVNULL\n160         )\n161         subprocess.run(\n162             \"git reset HEAD .\", check=True, shell=True, stdout=subprocess.DEVNULL\n",
          "col_offset": 8,
          "end_col_offset": 9,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call with shell=True seems safe, but may be changed in the future, consider rewriting without shell",
          "line_number": 159,
          "line_range": [
            158,
            159,
            160
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b602_subprocess_popen_with_shell_equals_true.html",
          "test_id": "B602",
          "test_name": "subprocess_popen_with_shell_equals_true"
        },
        {
          "code": "160         )\n161         subprocess.run(\n162             \"git reset HEAD .\", check=True, shell=True, stdout=subprocess.DEVNULL\n163         )\n164         subprocess.run(\n",
          "col_offset": 8,
          "end_col_offset": 9,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Starting a process with a partial executable path",
          "line_number": 161,
          "line_range": [
            161,
            162,
            163
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b607_start_process_with_partial_path.html",
          "test_id": "B607",
          "test_name": "start_process_with_partial_path"
        },
        {
          "code": "161         subprocess.run(\n162             \"git reset HEAD .\", check=True, shell=True, stdout=subprocess.DEVNULL\n163         )\n164         subprocess.run(\n165             \"git clean -fd\", shell=True, check=True, stdout=subprocess.DEVNULL\n",
          "col_offset": 8,
          "end_col_offset": 9,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call with shell=True seems safe, but may be changed in the future, consider rewriting without shell",
          "line_number": 162,
          "line_range": [
            161,
            162,
            163
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b602_subprocess_popen_with_shell_equals_true.html",
          "test_id": "B602",
          "test_name": "subprocess_popen_with_shell_equals_true"
        },
        {
          "code": "163         )\n164         subprocess.run(\n165             \"git clean -fd\", shell=True, check=True, stdout=subprocess.DEVNULL\n166         )\n167         out_check = subprocess.run(\n",
          "col_offset": 8,
          "end_col_offset": 9,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Starting a process with a partial executable path",
          "line_number": 164,
          "line_range": [
            164,
            165,
            166
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b607_start_process_with_partial_path.html",
          "test_id": "B607",
          "test_name": "start_process_with_partial_path"
        },
        {
          "code": "164         subprocess.run(\n165             \"git clean -fd\", shell=True, check=True, stdout=subprocess.DEVNULL\n166         )\n167         out_check = subprocess.run(\n168             f\"git -c advice.detachedHead=false checkout {instance['base_commit']}\",\n",
          "col_offset": 8,
          "end_col_offset": 9,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call with shell=True seems safe, but may be changed in the future, consider rewriting without shell",
          "line_number": 165,
          "line_range": [
            164,
            165,
            166
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b602_subprocess_popen_with_shell_equals_true.html",
          "test_id": "B602",
          "test_name": "subprocess_popen_with_shell_equals_true"
        },
        {
          "code": "168             f\"git -c advice.detachedHead=false checkout {instance['base_commit']}\",\n169             shell=True,\n170             stdout=subprocess.DEVNULL,\n171         )\n172         if out_check.returncode != 0:\n173             logger.error(f\"[{instance['instance_id']}] Checkout failed\")\n174             continue\n",
          "col_offset": 20,
          "end_col_offset": 9,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "HIGH",
          "issue_text": "subprocess call with shell=True identified, security issue.",
          "line_number": 169,
          "line_range": [
            167,
            168,
            169,
            170,
            171
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b602_subprocess_popen_with_shell_equals_true.html",
          "test_id": "B602",
          "test_name": "subprocess_popen_with_shell_equals_true"
        },
        {
          "code": "178             f\"{cmd_source}; {cmd_activate} {conda_env}; {cmd_install}\",\n179             shell=True,\n180             stdout=subprocess.DEVNULL,\n181         )\n182         if out_install.returncode != 0:\n183             logger.error(f\"[{instance['instance_id']}] Installation failed\")\n184             continue\n",
          "col_offset": 22,
          "end_col_offset": 9,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "HIGH",
          "issue_text": "subprocess call with shell=True identified, security issue.",
          "line_number": 179,
          "line_range": [
            177,
            178,
            179,
            180,
            181
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b602_subprocess_popen_with_shell_equals_true.html",
          "test_id": "B602",
          "test_name": "subprocess_popen_with_shell_equals_true"
        },
        {
          "code": "292             # If retrieval method is just GitHub, then merge results and return\n293             assert len(data_tasks) == merge_results(\n294                 args.instances_path, repo_prefix, args.output_dir\n295             )\n296             return\n",
          "col_offset": 12,
          "end_col_offset": 13,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 293,
          "line_range": [
            293,
            294,
            295
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "307     # Check that all required arguments for installing task instances are present\n308     assert any([x == args.retrieval_method for x in [\"build\", \"mix\"]])\n309     assert all([x in args for x in [\"testbed\", \"path_conda\", \"conda_env\"]])\n",
          "col_offset": 4,
          "end_col_offset": 70,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 308,
          "line_range": [
            308
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "308     assert any([x == args.retrieval_method for x in [\"build\", \"mix\"]])\n309     assert all([x in args for x in [\"testbed\", \"path_conda\", \"conda_env\"]])\n310     conda_exec = os.path.join(args.path_conda, \"bin/conda\")\n",
          "col_offset": 4,
          "end_col_offset": 75,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 309,
          "line_range": [
            309
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "323             )\n324             subprocess.run(cmd_clone, shell=True, check=True, stdout=subprocess.DEVNULL)\n325         else:\n",
          "col_offset": 12,
          "end_col_offset": 88,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "HIGH",
          "issue_text": "subprocess call with shell=True identified, security issue.",
          "line_number": 324,
          "line_range": [
            324
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b602_subprocess_popen_with_shell_equals_true.html",
          "test_id": "B602",
          "test_name": "subprocess_popen_with_shell_equals_true"
        },
        {
          "code": "334             subprocess.run(\n335                 cmd_clone_env, shell=True, check=True, stdout=subprocess.DEVNULL\n336             )\n337         else:\n338             logger.info(\n",
          "col_offset": 12,
          "end_col_offset": 13,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "HIGH",
          "issue_text": "subprocess call with shell=True identified, security issue.",
          "line_number": 335,
          "line_range": [
            334,
            335,
            336
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b602_subprocess_popen_with_shell_equals_true.html",
          "test_id": "B602",
          "test_name": "subprocess_popen_with_shell_equals_true"
        },
        {
          "code": "364     if args.retrieval_method == \"mix\":\n365         assert (\n366             len(data_tasks)\n367             == merge_results(args.instances_path, repo_prefix, args.output_dir)\n368             + total_web\n369         )\n370     elif args.retrieval_method == \"build\":\n",
          "col_offset": 8,
          "end_col_offset": 9,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 365,
          "line_range": [
            365,
            366,
            367,
            368,
            369
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "370     elif args.retrieval_method == \"build\":\n371         assert len(data_tasks) == merge_results(\n372             args.instances_path, repo_prefix, args.output_dir\n373         )\n374 \n",
          "col_offset": 8,
          "end_col_offset": 9,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 371,
          "line_range": [
            371,
            372,
            373
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "381             testbed_repo_name = f\"{repo_prefix}__{x}\"\n382             subprocess.run(f\"rm -rf {testbed_repo_name}\", shell=True, check=True)\n383 \n",
          "col_offset": 12,
          "end_col_offset": 81,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "HIGH",
          "issue_text": "subprocess call with shell=True identified, security issue.",
          "line_number": 382,
          "line_range": [
            382
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b602_subprocess_popen_with_shell_equals_true.html",
          "test_id": "B602",
          "test_name": "subprocess_popen_with_shell_equals_true"
        },
        {
          "code": "387             )\n388             subprocess.run(cmd_rm_env, shell=True, check=True)\n389         os.chdir(cwd)\n",
          "col_offset": 12,
          "end_col_offset": 62,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "HIGH",
          "issue_text": "subprocess call with shell=True identified, security issue.",
          "line_number": 388,
          "line_range": [
            388
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b602_subprocess_popen_with_shell_equals_true.html",
          "test_id": "B602",
          "test_name": "subprocess_popen_with_shell_equals_true"
        },
        {
          "code": "17 # Get version to date from astropy homepage\n18 resp = requests.get(\"https://docs.astropy.org/en/latest/changelog.html\")\n19 pattern = (\n",
          "col_offset": 7,
          "end_col_offset": 72,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_astropy.py",
          "issue_confidence": "LOW",
          "issue_cwe": {
            "id": 400,
            "link": "https://cwe.mitre.org/data/definitions/400.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Call to requests without timeout",
          "line_number": 18,
          "line_range": [
            18
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b113_request_without_timeout.html",
          "test_id": "B113",
          "test_name": "request_without_timeout"
        },
        {
          "code": "17 # Get version to date from matplotlib home page\n18 resp = requests.get(\"https://matplotlib.org/stable/users/release_notes#past-versions\")\n19 pattern = r'<a class=\"reference internal\" href=\"prev_whats_new/whats_new_(.*).html\">What\\'s new in Matplotlib (.*)</a>'\n",
          "col_offset": 7,
          "end_col_offset": 86,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_matplotlib.py",
          "issue_confidence": "LOW",
          "issue_cwe": {
            "id": 400,
            "link": "https://cwe.mitre.org/data/definitions/400.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Call to requests without timeout",
          "line_number": 18,
          "line_range": [
            18
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b113_request_without_timeout.html",
          "test_id": "B113",
          "test_name": "request_without_timeout"
        },
        {
          "code": "22 # Get version to date from astropy homepage\n23 resp = requests.get(WEBPAGE)\n24 matches = re.findall(PATTERN, resp.text)\n",
          "col_offset": 7,
          "end_col_offset": 28,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_pvlib-python.py",
          "issue_confidence": "LOW",
          "issue_cwe": {
            "id": 400,
            "link": "https://cwe.mitre.org/data/definitions/400.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Call to requests without timeout",
          "line_number": 23,
          "line_range": [
            23
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b113_request_without_timeout.html",
          "test_id": "B113",
          "test_name": "request_without_timeout"
        },
        {
          "code": "13 data_tasks = get_instances(PATH_TASKS_PYDICOM)\n14 resp = requests.get(\"https://pydicom.github.io/pydicom/dev/faq/index.html\")\n15 soup = BeautifulSoup(resp.text, \"html.parser\")\n",
          "col_offset": 7,
          "end_col_offset": 75,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_pydicom.py",
          "issue_confidence": "LOW",
          "issue_cwe": {
            "id": 400,
            "link": "https://cwe.mitre.org/data/definitions/400.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Call to requests without timeout",
          "line_number": 14,
          "line_range": [
            14
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b113_request_without_timeout.html",
          "test_id": "B113",
          "test_name": "request_without_timeout"
        },
        {
          "code": "9 \n10 GITHUB_TOKEN = \"<your GitHub token>\"\n11 PATH_TASKS_SQLFLUFF = \"<path to sqlfluff task instances>\"\n",
          "col_offset": 15,
          "end_col_offset": 36,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_sqlfluff.py",
          "issue_confidence": "MEDIUM",
          "issue_cwe": {
            "id": 259,
            "link": "https://cwe.mitre.org/data/definitions/259.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Possible hardcoded password: '<your GitHub token>'",
          "line_number": 10,
          "line_range": [
            10
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b105_hardcoded_password_string.html",
          "test_id": "B105",
          "test_name": "hardcoded_password_string"
        },
        {
          "code": "17 # Get version to date from xarray home page\n18 resp = requests.get(\"https://docs.xarray.dev/en/stable/whats-new.html\")\n19 pattern = (\n",
          "col_offset": 7,
          "end_col_offset": 71,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_xarray.py",
          "issue_confidence": "LOW",
          "issue_cwe": {
            "id": 400,
            "link": "https://cwe.mitre.org/data/definitions/400.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Call to requests without timeout",
          "line_number": 18,
          "line_range": [
            18
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b113_request_without_timeout.html",
          "test_id": "B113",
          "test_name": "request_without_timeout"
        },
        {
          "code": "39             times.append((date_obj.strftime(\"%Y-%m-%d\"), version))\n40         except:\n41             continue\n42         break\n",
          "col_offset": 8,
          "end_col_offset": 20,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\get_versions_xarray.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Try, Except, Continue detected.",
          "line_number": 40,
          "line_range": [
            40,
            41
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b112_try_except_continue.html",
          "test_id": "B112",
          "test_name": "try_except_continue"
        },
        {
          "code": "74     # Load the dataset\n75     dev = load_dataset(\"SWE-bench/SWE-bench\")[\"dev\"]\n76     test = load_dataset(\"SWE-bench/SWE-bench\")[\"test\"]\n",
          "col_offset": 10,
          "end_col_offset": 45,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\make_lite.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 494,
            "link": "https://cwe.mitre.org/data/definitions/494.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
          "line_number": 75,
          "line_range": [
            75
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b615_huggingface_unsafe_download.html",
          "test_id": "B615",
          "test_name": "huggingface_unsafe_download"
        },
        {
          "code": "75     dev = load_dataset(\"SWE-bench/SWE-bench\")[\"dev\"]\n76     test = load_dataset(\"SWE-bench/SWE-bench\")[\"test\"]\n77 \n",
          "col_offset": 11,
          "end_col_offset": 46,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\make_lite.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 494,
            "link": "https://cwe.mitre.org/data/definitions/494.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
          "line_number": 76,
          "line_range": [
            76
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b615_huggingface_unsafe_download.html",
          "test_id": "B615",
          "test_name": "huggingface_unsafe_download"
        },
        {
          "code": "250         else:\n251             assert False\n252 \n",
          "col_offset": 12,
          "end_col_offset": 24,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 251,
          "line_range": [
            251
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "328             scaling_factor = self.config.rope_scaling[\"factor\"]\n329             assert scaling_type == \"linear\"\n330         theta = getattr(self.config, \"rope_theta\", 10000)\n",
          "col_offset": 12,
          "end_col_offset": 43,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 329,
          "line_range": [
            329
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "412             # NOTE: we assume that padding tokens are at the end of the sequence and may ignore `attention_mask`\n413             assert output_attentions is False\n414             attn_outputs = self.distributed_attn_func(\n",
          "col_offset": 12,
          "end_col_offset": 45,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 413,
          "line_range": [
            413
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "425                 # varlen, ignore padding tokens, efficient for large batch with many paddings\n426                 assert attention_mask is not None\n427                 cu_seqlens, max_seqlen = unpadded_lengths\n",
          "col_offset": 16,
          "end_col_offset": 49,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\modeling_flash_llama.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 426,
          "line_range": [
            426
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "34         reqs_url = posixpath.join(SWE_BENCH_URL_RAW, repo, commit, req_path)\n35         reqs = requests.get(reqs_url, headers=HEADERS)\n36         if reqs.status_code == 200:\n",
          "col_offset": 15,
          "end_col_offset": 54,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "issue_confidence": "LOW",
          "issue_cwe": {
            "id": 400,
            "link": "https://cwe.mitre.org/data/definitions/400.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Call to requests without timeout",
          "line_number": 35,
          "line_range": [
            35
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b113_request_without_timeout.html",
          "test_id": "B113",
          "test_name": "request_without_timeout"
        },
        {
          "code": "140         reqs_url = posixpath.join(SWE_BENCH_URL_RAW, repo, commit, req_path)\n141         reqs = requests.get(reqs_url, headers=HEADERS)\n142         if reqs.status_code == 200:\n",
          "col_offset": 15,
          "end_col_offset": 54,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "issue_confidence": "LOW",
          "issue_cwe": {
            "id": 400,
            "link": "https://cwe.mitre.org/data/definitions/400.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Call to requests without timeout",
          "line_number": 141,
          "line_range": [
            141
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b113_request_without_timeout.html",
          "test_id": "B113",
          "test_name": "request_without_timeout"
        },
        {
          "code": "167             )\n168             reqs = requests.get(reqs_url, headers=HEADERS)\n169             if reqs.status_code == 200:\n",
          "col_offset": 19,
          "end_col_offset": 58,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\python.py",
          "issue_confidence": "LOW",
          "issue_cwe": {
            "id": 400,
            "link": "https://cwe.mitre.org/data/definitions/400.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Call to requests without timeout",
          "line_number": 168,
          "line_range": [
            168
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b113_request_without_timeout.html",
          "test_id": "B113",
          "test_name": "request_without_timeout"
        },
        {
          "code": "4 import os\n5 import subprocess\n6 \n",
          "col_offset": 0,
          "end_col_offset": 17,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\remove_envs.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Consider possible security implications associated with the subprocess module.",
          "line_number": 5,
          "line_range": [
            5
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/blacklists/blacklist_imports.html#b404-import-subprocess",
          "test_id": "B404",
          "test_name": "blacklist"
        },
        {
          "code": "39     command = f'find {envs_folder} -type d -name \"{prefix}*\" -exec rm -rf {{}} +'\n40     subprocess.run(command.split(\" \"))\n41 \n",
          "col_offset": 4,
          "end_col_offset": 38,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\remove_envs.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 40,
          "line_range": [
            40
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "51         try:\n52             conda_create_output = subprocess.run(\n53                 cmd.split(), check=True, capture_output=True, text=True\n54             )\n55         except subprocess.CalledProcessError as e:\n",
          "col_offset": 34,
          "end_col_offset": 13,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\remove_envs.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 52,
          "line_range": [
            52,
            53,
            54
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "78     try:\n79         conda_envs = subprocess.run(\n80             check_env.split(\" \"), check=True, capture_output=True\n81         )\n82     except subprocess.CalledProcessError as e:\n",
          "col_offset": 21,
          "end_col_offset": 9,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\remove_envs.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 79,
          "line_range": [
            79,
            80,
            81
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "479     else:\n480         dataset = load_dataset(dataset_name_or_path)\n481     if split not in dataset:\n",
          "col_offset": 18,
          "end_col_offset": 52,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_api.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 494,
            "link": "https://cwe.mitre.org/data/definitions/494.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
          "line_number": 480,
          "line_range": [
            480
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b615_huggingface_unsafe_download.html",
          "test_id": "B615",
          "test_name": "huggingface_unsafe_download"
        },
        {
          "code": "136                 )\n137             except:\n138                 # some error, idk why\n139                 pass\n140 \n",
          "col_offset": 12,
          "end_col_offset": 20,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Try, Except, Pass detected.",
          "line_number": 137,
          "line_range": [
            137,
            138,
            139
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b110_try_except_pass.html",
          "test_id": "B110",
          "test_name": "try_except_pass"
        },
        {
          "code": "503     # set open file limit\n504     assert len(run_id) > 0, \"Run ID must be provided\"\n505     if report_dir is not None:\n",
          "col_offset": 4,
          "end_col_offset": 53,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 504,
          "line_range": [
            504
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "149                             pass\n150                         except Exception:\n151                             pass\n152 \n",
          "col_offset": 24,
          "end_col_offset": 32,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Try, Except, Pass detected.",
          "line_number": 150,
          "line_range": [
            150,
            151
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b110_try_except_pass.html",
          "test_id": "B110",
          "test_name": "try_except_pass"
        },
        {
          "code": "153                 self.sandbox.terminate()\n154             except Exception:\n155                 pass\n156             finally:\n",
          "col_offset": 12,
          "end_col_offset": 20,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Try, Except, Pass detected.",
          "line_number": 154,
          "line_range": [
            154,
            155
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b110_try_except_pass.html",
          "test_id": "B110",
          "test_name": "try_except_pass"
        },
        {
          "code": "268     try:\n269         patch_file = \"/tmp/patch.diff\"\n270         runner.write_file(patch_file, patch_diff)\n",
          "col_offset": 21,
          "end_col_offset": 38,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal.py",
          "issue_confidence": "MEDIUM",
          "issue_cwe": {
            "id": 377,
            "link": "https://cwe.mitre.org/data/definitions/377.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Probable insecure usage of temp file/directory.",
          "line_number": 269,
          "line_range": [
            269
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b108_hardcoded_tmp_directory.html",
          "test_id": "B108",
          "test_name": "hardcoded_tmp_directory"
        },
        {
          "code": "111 async def main(command: str):\n112     returncode = await exec(command)\n113     exit(returncode)\n",
          "col_offset": 23,
          "end_col_offset": 36,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_evaluation_modal_entrypoint.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Use of exec detected.",
          "line_number": 112,
          "line_range": [
            112
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b102_exec_used.html",
          "test_id": "B102",
          "test_name": "exec_used"
        },
        {
          "code": "10 import json\n11 import subprocess\n12 from pathlib import Path\n",
          "col_offset": 0,
          "end_col_offset": 17,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_live.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Consider possible security implications associated with the subprocess module.",
          "line_number": 11,
          "line_range": [
            11
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/blacklists/blacklist_imports.html#b404-import-subprocess",
          "test_id": "B404",
          "test_name": "blacklist"
        },
        {
          "code": "112         commit = (\n113             subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=repo_dir)\n114             .decode(\"utf-8\")\n",
          "col_offset": 12,
          "end_col_offset": 79,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_live.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Starting a process with a partial executable path",
          "line_number": 113,
          "line_range": [
            113
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b607_start_process_with_partial_path.html",
          "test_id": "B607",
          "test_name": "start_process_with_partial_path"
        },
        {
          "code": "112         commit = (\n113             subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=repo_dir)\n114             .decode(\"utf-8\")\n",
          "col_offset": 12,
          "end_col_offset": 79,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_live.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 113,
          "line_range": [
            113
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "195     document_encoding_func = DOCUMENT_ENCODING_FUNCTIONS[document_encoding_func]\n196     python = subprocess.check_output([\"which\", \"python\"]).decode(\"utf-8\").strip()\n197     outputs = list()\n",
          "col_offset": 13,
          "end_col_offset": 57,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_live.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Starting a process with a partial executable path",
          "line_number": 196,
          "line_range": [
            196
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b607_start_process_with_partial_path.html",
          "test_id": "B607",
          "test_name": "start_process_with_partial_path"
        },
        {
          "code": "195     document_encoding_func = DOCUMENT_ENCODING_FUNCTIONS[document_encoding_func]\n196     python = subprocess.check_output([\"which\", \"python\"]).decode(\"utf-8\").strip()\n197     outputs = list()\n",
          "col_offset": 13,
          "end_col_offset": 57,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_live.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 196,
          "line_range": [
            196
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "158     logger.info(f\"Loading tokenizer {model_name_or_path}\")\n159     tokenizer = LlamaTokenizer.from_pretrained(model_name_or_path)\n160     return tokenizer\n",
          "col_offset": 16,
          "end_col_offset": 66,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_llama.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 494,
            "link": "https://cwe.mitre.org/data/definitions/494.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Unsafe Hugging Face Hub download without revision pinning in from_pretrained()",
          "line_number": 159,
          "line_range": [
            159
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b615_huggingface_unsafe_download.html",
          "test_id": "B615",
          "test_name": "huggingface_unsafe_download"
        },
        {
          "code": "194     if not Path(dataset_path).exists():\n195         dataset = load_dataset(dataset_path, split=split)\n196     elif Path(dataset_path, split).exists():\n",
          "col_offset": 18,
          "end_col_offset": 57,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_llama.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 494,
            "link": "https://cwe.mitre.org/data/definitions/494.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
          "line_number": 195,
          "line_range": [
            195
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b615_huggingface_unsafe_download.html",
          "test_id": "B615",
          "test_name": "huggingface_unsafe_download"
        },
        {
          "code": "198     else:\n199         dataset = load_dataset(dataset_path)[split]\n200     if peft_path is not None:\n",
          "col_offset": 18,
          "end_col_offset": 44,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\run_llama.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 494,
            "link": "https://cwe.mitre.org/data/definitions/494.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
          "line_number": 199,
          "line_range": [
            199
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b615_huggingface_unsafe_download.html",
          "test_id": "B615",
          "test_name": "huggingface_unsafe_download"
        },
        {
          "code": "1 import subprocess\n2 \n3 \n",
          "col_offset": 0,
          "end_col_offset": 17,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_cli.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Consider possible security implications associated with the subprocess module.",
          "line_number": 1,
          "line_range": [
            1
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/blacklists/blacklist_imports.html#b404-import-subprocess",
          "test_id": "B404",
          "test_name": "blacklist"
        },
        {
          "code": "5     cmd = [\"python\", \"-m\", \"swebench.harness.run_evaluation\", \"--help\"]\n6     result = subprocess.run(cmd, capture_output=True)\n7     print(result.stdout)\n",
          "col_offset": 13,
          "end_col_offset": 53,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_cli.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 6,
          "line_range": [
            6
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "8     print(result.stderr)\n9     assert result.returncode == 0\n10 \n",
          "col_offset": 4,
          "end_col_offset": 33,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_cli.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 9,
          "line_range": [
            9
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "25     ]\n26     result = subprocess.run(cmd, capture_output=True)\n27     print(result.stdout)\n",
          "col_offset": 13,
          "end_col_offset": 53,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_cli.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 26,
          "line_range": [
            26
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "28     print(result.stderr)\n29     assert result.returncode == 0\n",
          "col_offset": 4,
          "end_col_offset": 33,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_cli.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 29,
          "line_range": [
            29
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "1 import json\n2 import subprocess\n3 \n",
          "col_offset": 0,
          "end_col_offset": 17,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_collect_cli.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Consider possible security implications associated with the subprocess module.",
          "line_number": 2,
          "line_range": [
            2
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/blacklists/blacklist_imports.html#b404-import-subprocess",
          "test_id": "B404",
          "test_name": "blacklist"
        },
        {
          "code": "6     cmd = [\"python\", \"-m\", \"swebench.collect.print_pulls\", \"--help\"]\n7     result = subprocess.run(cmd, capture_output=True)\n8     print(result.stdout)\n",
          "col_offset": 13,
          "end_col_offset": 53,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_collect_cli.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 7,
          "line_range": [
            7
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "9     print(result.stderr)\n10     assert result.returncode == 0\n11 \n",
          "col_offset": 4,
          "end_col_offset": 33,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_collect_cli.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 10,
          "line_range": [
            10
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "23     print(\" \".join(cmd))\n24     result = subprocess.run(cmd, capture_output=True)\n25     print(result.stdout)\n",
          "col_offset": 13,
          "end_col_offset": 53,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_collect_cli.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 24,
          "line_range": [
            24
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "26     print(result.stderr)\n27     assert result.returncode == 0\n28 \n",
          "col_offset": 4,
          "end_col_offset": 33,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_collect_cli.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 27,
          "line_range": [
            27
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "38     print(\" \".join(cmd))\n39     result = subprocess.run(cmd, capture_output=True)\n40     print(result.stdout)\n",
          "col_offset": 13,
          "end_col_offset": 53,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_collect_cli.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 39,
          "line_range": [
            39
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "41     print(result.stderr)\n42     assert result.returncode == 0\n43 \n",
          "col_offset": 4,
          "end_col_offset": 33,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_collect_cli.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 42,
          "line_range": [
            42
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "56     print(\" \".join(cmd))\n57     result = subprocess.run(cmd, capture_output=True)\n58     print(result.stdout)\n",
          "col_offset": 13,
          "end_col_offset": 53,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_collect_cli.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 78,
            "link": "https://cwe.mitre.org/data/definitions/78.html"
          },
          "issue_severity": "LOW",
          "issue_text": "subprocess call - check for execution of untrusted input.",
          "line_number": 57,
          "line_range": [
            57
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b603_subprocess_without_shell_equals_true.html",
          "test_id": "B603",
          "test_name": "subprocess_without_shell_equals_true"
        },
        {
          "code": "59     print(result.stderr)\n60     assert result.returncode == 0\n61     data = json.loads((tmp_path / \"output_pr_26371.json\").read_text())\n",
          "col_offset": 4,
          "end_col_offset": 33,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_collect_cli.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 60,
          "line_range": [
            60
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "61     data = json.loads((tmp_path / \"output_pr_26371.json\").read_text())\n62     assert len(data[\"resolved_issues\"]) == 2\n63     assert sorted(data[\"resolved_issues\"]) == [\"26194\", \"26230\"]\n",
          "col_offset": 4,
          "end_col_offset": 44,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_collect_cli.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 62,
          "line_range": [
            62
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "62     assert len(data[\"resolved_issues\"]) == 2\n63     assert sorted(data[\"resolved_issues\"]) == [\"26194\", \"26230\"]\n",
          "col_offset": 4,
          "end_col_offset": 64,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_collect_cli.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 63,
          "line_range": [
            63
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "28         )\n29         assert output_path.is_file()\n30         report = json.loads(output_path.read_text())\n",
          "col_offset": 8,
          "end_col_offset": 36,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_evaluation.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 29,
          "line_range": [
            29
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "30         report = json.loads(output_path.read_text())\n31         assert report[\"schema_version\"] == 2\n",
          "col_offset": 8,
          "end_col_offset": 44,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_evaluation.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 31,
          "line_range": [
            31
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "183         return instance\n184     assert base_image_tag is not None, \"base_image_tag cannot be None\"\n185     assert env_image_tag is not None, \"env_image_tag cannot be None\"\n",
          "col_offset": 4,
          "end_col_offset": 70,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_spec.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 184,
          "line_range": [
            184
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "184     assert base_image_tag is not None, \"base_image_tag cannot be None\"\n185     assert env_image_tag is not None, \"env_image_tag cannot be None\"\n186     assert instance_image_tag is not None, \"instance_image_tag cannot be None\"\n",
          "col_offset": 4,
          "end_col_offset": 68,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_spec.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 185,
          "line_range": [
            185
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "185     assert env_image_tag is not None, \"env_image_tag cannot be None\"\n186     assert instance_image_tag is not None, \"instance_image_tag cannot be None\"\n187     instance_id = instance[KEY_INSTANCE_ID]\n",
          "col_offset": 4,
          "end_col_offset": 78,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\test_spec.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 186,
          "line_range": [
            186
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "32     \"cl100k\": (tiktoken.get_encoding(\"cl100k_base\"), cl100k),\n33     \"llama\": (LlamaTokenizer.from_pretrained(\"togethercomputer/LLaMA-2-7B-32K\"), llama),\n34 }\n",
          "col_offset": 14,
          "end_col_offset": 79,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\tokenize_dataset.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 494,
            "link": "https://cwe.mitre.org/data/definitions/494.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Unsafe Hugging Face Hub download without revision pinning in from_pretrained()",
          "line_number": 33,
          "line_range": [
            33
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b615_huggingface_unsafe_download.html",
          "test_id": "B615",
          "test_name": "huggingface_unsafe_download"
        },
        {
          "code": "54         idx = label_ids.index(13)\n55         assert idx <= 2, (\n56             \"Expected newline token id (13) to be one of the first three tokens\"\n57         )\n58         label_ids = label_ids[idx + 1 :]  # remove newline tokens\n",
          "col_offset": 8,
          "end_col_offset": 9,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\tokenize_dataset.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 55,
          "line_range": [
            55,
            56,
            57
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "63     labels = [-100] * cond_len + label_ids\n64     assert len(inputs) == len(labels)\n65     return {\n",
          "col_offset": 4,
          "end_col_offset": 37,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\tokenize_dataset.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 703,
            "link": "https://cwe.mitre.org/data/definitions/703.html"
          },
          "issue_severity": "LOW",
          "issue_text": "Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.",
          "line_number": 64,
          "line_range": [
            64
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html",
          "test_id": "B101",
          "test_name": "assert_used"
        },
        {
          "code": "134     else:\n135         dataset = load_dataset(dataset_name_or_path)\n136     dataset = dataset.filter(\n",
          "col_offset": 18,
          "end_col_offset": 52,
          "filename": "C:\\Users\\dell\\AppData\\Local\\Temp\\scan_cyeftmaj\\tokenize_dataset.py",
          "issue_confidence": "HIGH",
          "issue_cwe": {
            "id": 494,
            "link": "https://cwe.mitre.org/data/definitions/494.html"
          },
          "issue_severity": "MEDIUM",
          "issue_text": "Unsafe Hugging Face Hub download without revision pinning in load_dataset()",
          "line_number": 135,
          "line_range": [
            135
          ],
          "more_info": "https://bandit.readthedocs.io/en/1.8.6/plugins/b615_huggingface_unsafe_download.html",
          "test_id": "B615",
          "test_name": "huggingface_unsafe_download"
        }
      ],
      "stderr": ""
    },
    "semgrep": {
      "count": 0,
      "findings": []
    }
  },
  "dynamic_errors": [],
  "fixes": [
    {
      "file": "default.py",
      "path": "fixed_files\\default.py",
      "fixed_content": "\"\"\"Basic agent class. See https://mini-swe-agent.com/latest/advanced/control_flow/ for visual explanation.\"\"\"\n\nimport re\nimport subprocess\nfrom collections.abc import Callable\nfrom dataclasses import asdict, dataclass\n\nfrom jinja2 import Template\n\nfrom minisweagent import Environment, Model\n\n\n@dataclass\nclass AgentConfig:\n    # The default settings are the bare minimum to run the agent. Take a look at the config files for improved settings.\n    system_template: str = \"You are a helpful assistant that can do anything.\"\n    instance_template: str = (\n        \"Your task: {{task}}. Please reply with a single shell command in triple backticks. \"\n        \"To finish, the first line of the output of the shell command must be 'COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT'.\"\n    )\n    timeout_template: str = (\n        \"The last command <command>{{action['action']}}</command> timed out and has been killed.\\n\"\n        \"The output of the command was:\\n <output>\\n{{output}}\\n</output>\\n\"\n        \"Please try another command and make sure to avoid those requiring interactive input.\"\n    )\n    format_error_template: str = \"Please always provide EXACTLY ONE action in triple backticks.\"\n    action_observation_template: str = \"Observation: {{output}}\"\n    step_limit: int = 0\n    cost_limit: float = 3.0\n\n\nclass NonTerminatingException(Exception):\n    \"\"\"Raised for conditions that can be handled by the agent.\"\"\"\n\n\nclass FormatError(NonTerminatingException):\n    \"\"\"Raised when the LM's output is not in the expected format.\"\"\"\n\n\nclass ExecutionTimeoutError(NonTerminatingException):\n    \"\"\"Raised when the action execution timed out.\"\"\"\n\n\nclass TerminatingException(Exception):\n    \"\"\"Raised for conditions that terminate the agent.\"\"\"\n\n\nclass Submitted(TerminatingException):\n    \"\"\"Raised when the LM declares that the agent has finished its task.\"\"\"\n\n\nclass LimitsExceeded(TerminatingException):\n    \"\"\"Raised when the agent has reached its cost or step limit.\"\"\"\n\n\nclass DefaultAgent:\n    def __init__(self, model: Model, env: Environment, *, config_class: Callable = AgentConfig, **kwargs):\n        self.config = config_class(**kwargs)\n        self.messages: list[dict] = []\n        self.model = model\n        self.env = env\n        self.extra_template_vars = {}\n\n    def render_template(self, template: str, **kwargs) -> str:\n        template_vars = asdict(self.config) | self.env.get_template_vars() | self.model.get_template_vars()\n        return Template(template).render(**kwargs, **template_vars, **self.extra_template_vars)\n\n    def add_message(self, role: str, content: str, **kwargs):\n        self.messages.append({\"role\": role, \"content\": content, **kwargs})\n\n    def run(self, task: str, **kwargs) -> tuple[str, str]:\n        \"\"\"Run step() until agent is finished. Return exit status & message\"\"\"\n        self.extra_template_vars |= {\"task\": task, **kwargs}\n        self.messages = []\n        self.add_message(\"system\", self.render_template(self.config.system_template))\n        self.add_message(\"user\", self.render_template(self.config.instance_template))\n        while True:\n            try:\n                self.step()\n            except NonTerminatingException as e:\n                self.add_message(\"user\", str(e))\n            except TerminatingException as e:\n                self.add_message(\"user\", str(e))\n                return type(e).__name__, str(e)\n\n    def step(self) -> dict:\n        \"\"\"Query the LM, execute the action, return the observation.\"\"\"\n        return self.get_observation(self.query())\n\n    def query(self) -> dict:\n        \"\"\"Query the model and return the response.\"\"\"\n        if 0 < self.config.step_limit <= self.model.n_calls or 0 < self.config.cost_limit <= self.model.cost:\n            raise LimitsExceeded()\n        response = self.model.query(self.messages)\n        self.add_message(\"assistant\", **response)\n        return response\n\n    def get_observation(self, response: dict) -> dict:\n        \"\"\"Execute the action and return the observation.\"\"\"\n        output = self.execute_action(self.parse_action(response))\n        observation = self.render_template(self.config.action_observation_template, output=output)\n        self.add_message(\"user\", observation)\n        return output\n\n    def parse_action(self, response: dict) -> dict:\n        \"\"\"Parse the action from the message. Returns the action.\"\"\"\n        actions = re.findall(r\"",
      "original_issues": [
        {
          "file": "default.py",
          "line": 120,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'TimeoutError'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "get_top_pypi.py",
      "path": "fixed_files\\get_top_pypi.py",
      "fixed_content": "#!/usr/bin/env python3\n\nimport os\nimport json\nimport argparse\n\nfrom bs4 import BeautifulSoup\nfrom ghapi.core import GhApi\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\n\n\ngh_token = os.environ.get(\"GITHUB_TOKEN\")\nif not gh_token:\n    msg = \"Please set the GITHUB_TOKEN environment variable.\"\n    raise ValueError(msg)\napi = GhApi(token=gh_token)\n\n\ndef get_package_stats(data_tasks, f):\n    \"\"\"\n    Get package stats from pypi page\n\n    Args:\n        data_tasks (list): List of packages + HTML\n        f (str): File to write to\n    \"\"\"\n    # Adjust access type if file already exists\n    content = None\n    access_type = \"w\"\n    if os.path.exists(f):\n        with open(f) as fp_:\n            content = fp_.read()\n            access_type = \"a\"\n\n    # Extra package title, pypi URL, stars, pulls, and github URL\n    with open(f, access_type) as fp_, webdriver.Chrome() as driver:\n        for idx, chunk in enumerate(data_tasks):\n            # Get package name and pypi URL\n            package_name = chunk[\"title\"]\n            package_url = chunk[\"href\"]\n            if content is not None and package_url in content:\n                continue\n\n            # Get github URL\n            package_github = None\n            driver.get(package_url)\n            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n            for link in soup.find_all(\"a\", class_=\"vertical-tabs__tab--with-icon\"):\n                found = False\n                for x in [\"Source\", \"Code\", \"Homepage\"]:\n                    if (\n                        x.lower() in link.get_text().lower()\n                        and \"github\" in link[\"href\"].lower()\n                    ):\n                        package_github = link[\"href\"]\n                        found = True\n                        break\n                if found:\n                    break\n\n            # Get stars and pulls from github API\n            stars_count, pulls_count = None, None\n            if package_github is not None:\n                repo_parts = package_github.split(\"/\")[-2:]\n                owner, name = repo_parts[0], repo_parts[1]\n\n                try:\n                    repo = api.repos.get(owner, name)\n                    stars_count = int(repo[\"stargazers_count\"])\n                    issues = api.issues.list_for_repo(owner, name)\n                    pulls_count = int(issues[0][\"number\"])\n                except Exception as e:\n                    pass\n\n            # Write to file\n            print(\n                json.dumps(\n                    {\n                        \"rank\": idx,\n                        \"name\": package_name,\n                        \"url\": package_url,\n                        \"github\": package_github,\n                        \"stars\": stars_count,\n                        \"pulls\": pulls_count,\n                    }\n                ),\n                file=fp_,\n                flush=True,\n            )\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--max-repos\", help=\"Maximum number of repos to get\", type=int, default=5000\n    )\n    args = parser.parse_args()\n\n    # Start selenium driver to get top 5000 pypi page\n    url_top_pypi = \"https://hugovk.github.io/top-pypi-packages/\"\n    with webdriver.Chrome() as driver:\n        driver.get(url_top_pypi)\n        button = driver.find_element(By.CSS_SELECTOR, 'button[ng-click=\"show(8000)\"]')\n        button.click()\n\n        # Retrieve HTML for packages from page\n        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n        package_list = soup.find(\"div\", {\"class\": \"list\"})\n        packages = package_list.find_all(\"a\", class_=\"ng-scope\")\n\n    get_package_stats(packages[: args.max_repos], \"pypi_rankings.jsonl\")\n",
      "original_issues": [
        {
          "file": "get_top_pypi.py",
          "line": 48,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'driver'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "get_top_pypi.py",
          "line": 49,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'driver'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "get_top_pypi.py",
          "line": 43,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "get_top_pypi.py",
          "line": 65,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "get_top_pypi.py",
          "line": 74,
          "severity": "LOW",
          "rule_id": "PY010",
          "message": "使用裸 except，建议捕获具体异常类型。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "utils.py",
      "path": "fixed_files\\utils.py",
      "fixed_content": "import json\n\n\ndef get_instances(instance_path: str) -> list:\n    \"\"\"\n    Get task instances from given path\n\n    Args:\n        instance_path (str): Path to task instances\n    Returns:\n        task_instances (list): List of task instances\n    \"\"\"\n    if any([instance_path.endswith(x) for x in [\".jsonl\", \".jsonl.all\"]]):\n        task_instances = list()\n        with open(instance_path) as f:\n            for line in f.readlines():\n                task_instances.append(json.loads(line))\n        return task_instances\n\n    with open(instance_path) as f:\n        task_instances = json.load(f)\n    return task_instances\n\n\ndef split_instances(input_list: list, n: int) -> list:\n    \"\"\"\n    Split a list into n approximately equal length sublists\n\n    Args:\n        input_list (list): List to split\n        n (int): Number of sublists to split into\n    Returns:\n        result (list): List of sublists\n    \"\"\"\n    avg_length = len(input_list) // n\n    remainder = len(input_list) % n\n    result, start = [], 0\n\n    for i in range(n):\n        length = avg_length + 1 if i < remainder else avg_length\n        sublist = input_list[start : start + length]\n        result.append(sublist)\n        start += length\n\n    return result\n",
      "original_issues": [
        {
          "file": "utils.py",
          "line": 247,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'extract_problem_statement_and_hints_django'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "utils.py",
          "line": 263,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 '_extract_hints'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "utils.py",
          "line": 328,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'test_word'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "utils.py",
          "line": 27,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'super'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "utils.py",
          "line": 36,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'super'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "utils.py",
          "line": 44,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'load_swebench_dataset'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "utils.py",
          "line": 149,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "utils.py",
          "line": 257,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "utils.py",
          "line": 387,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "utils.py",
          "line": 387,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "utils.py",
          "line": 152,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "utils.py",
          "line": 104,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "utils.py",
          "line": 127,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "utils.py",
          "line": 330,
          "severity": "LOW",
          "rule_id": "PY010",
          "message": "使用裸 except，建议捕获具体异常类型。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "remove_envs.py",
      "path": "fixed_files\\remove_envs.py",
      "fixed_content": "#!/usr/bin/env python\n\nimport argparse\nimport os\nimport subprocess\n\nfrom multiprocessing import Pool\n\n\ndef get_conda_env_names(output: str) -> list:\n    \"\"\"\n    Parse conda environments (`conda env list`) created for a particular conda installation\n\n    Args:\n        output (str): Output of `conda env list` command\n    \"\"\"\n    lines = output.split(\"\\n\")\n    env_names = []\n    for line in lines:\n        if line.startswith(\"#\"):\n            continue\n        if line.strip() == \"\":\n            continue\n        if \" \" in line:\n            env_name = line.split(\" \")[0]\n            env_names.append(env_name)\n    return [x for x in env_names if len(x) > 0]\n\n\ndef delete_folders_with_prefix(prefix, conda_path):\n    \"\"\"\n    Find and rm folders with a particular prefix in the conda installation's env folder\n\n    Args:\n        prefix (str): Prefix of folders to remove\n        conda_path (str): Path to conda installation\n    \"\"\"\n    envs_folder = os.path.join(conda_path, \"envs\")\n    command = f'find {envs_folder} -type d -name \"{prefix}*\" -exec rm -rf {{}} +'\n    subprocess.run(command.split(\" \"))\n\n\ndef remove_environment(env_name, prefix):\n    \"\"\"\n    Remove all conda environments with a particular prefix from a conda installation\n    \"\"\"\n    if env_name.startswith(prefix):\n        print(f\"Removing {env_name}\")\n        conda_cmd = \"conda remove -n \" + env_name + \" --all -y\"\n        cmd = f\"{conda_source} && {conda_cmd}\"\n        try:\n            conda_create_output = subprocess.run(\n                cmd.split(), check=True, capture_output=True, text=True\n            )\n        except subprocess.CalledProcessError as e:\n            print(f\"Error: {e}\")\n            print(f\"Error output: {e.stderr}\")\n            raise e\n        print(f\"Output: {conda_create_output.stdout}\")\n\n\nif __name__ == \"__main__\":\n    \"\"\"\n    Logic for removing conda environments and their folders from a conda installation\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"prefix\", type=str, help=\"Prefix for environments to delete\")\n    parser.add_argument(\n        \"--conda_path\",\n        type=str,\n        help=\"Path to miniconda installation\",\n    )\n    args = parser.parse_args()\n\n    # Remove conda environments with a specific prefix\n    conda_source = \"source \" + os.path.join(args.conda_path, \"etc/profile.d/conda.sh\")\n    check_env = conda_source + \" && \" + \"conda env list\"\n    try:\n        conda_envs = subprocess.run(\n            check_env.split(\" \"), check=True, capture_output=True\n        )\n    except subprocess.CalledProcessError as e:\n        print(f\"Error: {e}\")\n        print(f\"Error output: {e.stderr.decode('utf-8')}\")\n        raise e\n    conda_envs_names = get_conda_env_names(conda_envs.stdout.decode(\"utf-8\"))\n\n    # Remove conda environments in parallel\n    num_processes = 25\n    pool = Pool(num_processes)\n    pool.starmap(\n        remove_environment, zip(conda_envs_names, [args.prefix] * len(conda_envs_names))\n    )\n\n    # Remove env folder with the same prefix\n    print(\n        f\"Removing miniconda folder for environments with {args.prefix} from {args.conda_path}\"\n    )\n    delete_folders_with_prefix(args.prefix, args.conda_path)\n    print(\"Done!\")\n",
      "original_issues": [
        {
          "file": "remove_envs.py",
          "line": 50,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'conda_source'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "criteria.py",
      "path": "fixed_files\\criteria.py",
      "fixed_content": "import re\nimport requests\n\nfrom swebench.collect.utils import PR_KEYWORDS\nfrom unidiff import PatchSet\n\n\ndef contains_git_commit_hash(text: str) -> bool:\n    \"\"\"\n    Returns True if the text contains a git commit hash (40 character SHA-1 hash).\n    * Excludes commit hashes that are part of a URL.\n    \"\"\"\n    pattern_git_commit_hash = re.compile(r\"(?<!/)\\b[0-9a-f]{40}\\b\")\n    if re.search(pattern_git_commit_hash, text) != None:\n        return True\n    pattern_django_commit_hash = re.compile(r\"\\[[0-9a-f]{23}\\]\")\n    if re.search(pattern_django_commit_hash, text) != None:\n        return True\n    return False\n\n\ndef contains_hyperlinks(text: str, repo: str = None) -> bool:\n    \"\"\"\n    Returns True if the text contains a URL. Excludes URLs that are part of the repository.\n    \"\"\"\n    if repo:\n        repo_prefix = f\"http://github.com/{repo}\"\n        pattern_repo = re.escape(repo_prefix)\n        # Adding a negative lookahead assertion to ensure URLs starting with the repository prefix are excluded\n        pattern_urls = r\"(?:https?://(?!{}).+)|(?:www\\.(?!{}).+)\".format(\n            pattern_repo, pattern_repo\n        )\n    else:\n        pattern_urls = r\"https?://(?:www\\.)?\\S+\"\n\n    return bool(re.search(pattern_urls, text))\n\n\ndef contains_image(text: str) -> bool:\n    \"\"\"\n    Returns True if the text contains an image or video file extension.\n    \"\"\"\n    image_extensions = [\n        \".png\",\n        \".jpg\",\n        \".jpeg\",\n        \".gif\",\n        \".bmp\",\n        \".tiff\",\n        \".svg\",\n        \".webp\",\n        \".ico\",\n        \".heif\",\n        \".bpg\",\n        \".avif\",\n    ]\n    video_extensions = [\n        \".mp4\",\n        \".avi\",\n        \".mkv\",\n        \".mov\",\n        \".wmv\",\n        \".flv\",\n        \".webm\",\n        \".mpeg\",\n    ]\n\n    pattern_image = \"|\".join(re.escape(ext) for ext in image_extensions)\n    pattern_video = \"|\".join(re.escape(ext) for ext in video_extensions)\n\n    image_regex = re.compile(r\"\\b({})\\b\".format(pattern_image), flags=re.IGNORECASE)\n    video_regex = re.compile(r\"\\b({})\\b\".format(pattern_video), flags=re.IGNORECASE)\n\n    return image_regex.search(text) != None or video_regex.search(text) != None\n\n\ndef contains_issue_reference(text: str, repo: str) -> bool:\n    \"\"\"\n    Returns True if text (problem statement) contains a reference to another issue (e.g. #1234).\n    \"\"\"\n    # Look for GitHub style issue references\n    pattern_issue_ref = re.compile(r\"(\\w+)\\s+\\#(\\d+)\")\n    references = dict(pattern_issue_ref.findall(text))\n    if references:\n        for word, _ in references.items():\n            if word.lower() in PR_KEYWORDS:\n                return True\n\n    # Look for GitLab style issue references\n    pattern_gitlab = re.compile(r\"https?:\\/\\/gitlab.com\\/(.*)\\/issues\")\n    if re.search(pattern_gitlab, text):\n        return True\n\n    # Look for GitHub `#` style references + verify if the issue exists\n    pattern_issue_ref = re.compile(r\"#\\d+\")\n    matches = pattern_issue_ref.findall(text)\n    for match in matches:\n        url = f\"http://github.com/{repo}/issues/{match[1:]}\"\n        if repo == \"django/django\":\n            url = f\"https://code.djangoproject.com/ticket/{match[1:]}\"\n        if requests.get(url).status_code == 200:\n            return True\n\n    return False\n\n\ndef contains_non_modified_files(patch_text: str) -> bool:\n    \"\"\"\n    Returns True if the patch contains files that are not modified.\n    \"\"\"\n    patch = PatchSet(patch_text)\n    return len(patch.removed_files) > 0 or len(patch.added_files) > 0\n\n\ndef contains_pytest_match_arg(patch_test_text: str) -> bool:\n    \"\"\"\n    Returns True if the test patch contains a pytest.raises() call with a match argument.\n    \"\"\"\n    if any(\n        [\n            x in patch_test_text\n            for x in [\n                \"pytest.raises\",\n                \"pytest.warns\",\n                \"pytest.deprecated_call\",\n            ]\n        ]\n    ):\n        return \"match\" in patch_test_text\n    # Django style assertions:\n    if any(\n        [\n            x in patch_test_text\n            for x in [\n                \"assertOutput\",\n                \"assertRaises\",\n                \"checks.Error\",\n            ]\n        ]\n    ):\n        return True\n    return False\n\n\ndef leq_n_code_lines(patch_text: str, n: int = 25) -> bool:\n    \"\"\"\n    Returns True if the patch has at most n lines of code changed.\n    \"\"\"\n    lines = 0\n    patch = PatchSet(patch_text)\n    for file in patch:\n        for hunk in file:\n            lines += hunk.added\n            lines += hunk.removed\n    return lines <= n\n\n\ndef leq_n_files(patch_text: str, n: int = 1) -> bool:\n    \"\"\"\n    Returns True if the patch has at most n files.\n    \"\"\"\n    patch = PatchSet(patch_text)\n    return len(patch.modified_files) <= n\n\n\ndef leq_n_hunks(patch_text: str, n: int = 3) -> bool:\n    \"\"\"\n    Returns True if the patch has at most n hunks.\n    \"\"\"\n    patch = PatchSet(patch_text)\n    num_hunks = sum([len([h for h in f]) for f in patch.modified_files])\n    return num_hunks <= n and num_hunks > 0\n\n\ndef leq_n_words(text: str, n: int = 50) -> bool:\n    \"\"\"\n    Returns True if the text has at most n words.\n    \"\"\"\n    return len(text.split()) <= n\n",
      "original_issues": [
        {
          "file": "criteria.py",
          "line": 68,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'ext'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "criteria.py",
          "line": 14,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "criteria.py",
          "line": 17,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "criteria.py",
          "line": 74,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "criteria.py",
          "line": 74,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "call_make_repo.py",
      "path": "fixed_files\\call_make_repo.py",
      "fixed_content": "#!/usr/bin/env python3\n\nimport subprocess\n\nrepos = [\"Repos here\"]\n\nfor repo in repos:\n    print(f\"Making mirror repo for {repo}\")\n    out_make = subprocess.run(\n        [\"./make_repo.sh\", repo],\n        stdout=subprocess.DEVNULL,\n        stderr=subprocess.DEVNULL,\n    )\n    if out_make.returncode != 0:\n        print(f\"Error making mirror repo for {repo}\")\n    else:\n        print(f\"Success making mirror repo for {repo}\")\n",
      "original_issues": [
        {
          "file": "call_make_repo.py",
          "line": 9,
          "severity": "HIGH",
          "rule_id": "PY003",
          "message": "subprocess.*(shell=True) 可能导致命令注入。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "docker_build.py",
      "path": "fixed_files\\docker_build.py",
      "fixed_content": "import logging\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom traceback import format_exc\n\ndef run_threadpool(func, args_list, max_workers):\n    successful = []\n    failed = []\n\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = {executor.submit(func, *args): args for args in args_list}\n        for future in as_completed(futures):\n            try:\n                result = future.result()\n                if result is not None and isinstance(result, tuple) and len(result) == 2:\n                    successful.extend(result[0])\n                    failed.extend(result[1])\n                else:\n                    successful.append(result)\n            except Exception as e:\n                logging.error(f\"Error in threadpool execution: {e}\")\n                logging.error(format_exc())\n                failed.append((futures[future], e))\n\n    return successful, failed\n\ndef build_image(image_name, setup_scripts, dockerfile, platform, client, build_dir, nocache=False):\n    logger = logging.getLogger(image_name)\n    logger.setLevel(logging.INFO)\n\n    if not build_dir.exists():\n        build_dir.mkdir(parents=True)\n\n    # Build the image\n    try:\n        with open(build_dir / \"Dockerfile\", \"w\") as f:\n            f.write(dockerfile)\n\n        for script_name, script_content in setup_scripts.items():\n            with open(build_dir / script_name, \"w\") as f:\n                f.write(script_content)\n                f.chmod(0o755)  # Make the script executable\n\n        client.images.build(\n            path=str(build_dir),\n            dockerfile=\"Dockerfile\",\n            tag=image_name,\n            nocache=nocache,\n            rm=True\n        )\n    except Exception as e:\n        raise BuildImageError(image_name, str(e), logger) from e\n\ndef remove_image(client, image_name, force=False):\n    try:\n        client.images.remove(image_name, force=force)\n    except docker.errors.ImageNotFound:\n        pass\n\ndef build_instance_image(test_spec, client, logger=None, nocache=False):\n    build_dir = INSTANCE_IMAGE_BUILD_DIR / test_spec.instance_image_key.replace(\":\", \"__\")\n    new_logger = False\n    if logger is None:\n        new_logger = True\n        logger = logging.getLogger(test_spec.instance_id)\n        logger.setLevel(logging.INFO)\n\n    image_name = test_spec.instance_image_key\n    env_image_name = test_spec.env_image_key\n\n    try:\n        client.images.get(env_image_name)\n    except docker.errors.ImageNotFound as e:\n        raise BuildImageError(\n            test_spec.instance_id,\n            f\"Environment image {env_image_name} not found for {test_spec.instance_id}\",\n            logger\n        ) from e\n\n    if new_logger:\n        setup_logger(test_spec.instance_id, build_dir / \"prepare_image.log\")\n\n    try:\n        client.images.get(image_name)\n        image_exists = True\n    except docker.errors.ImageNotFound:\n        image_exists = False\n\n    if not image_exists:\n        build_image(\n            image_name=image_name,\n            setup_scripts={\"setup_repo.sh\": test_spec.install_repo_script},\n            dockerfile=test_spec.instance_dockerfile,\n            platform=test_spec.platform,\n            client=client,\n            build_dir=build_dir,\n            nocache=nocache\n        )\n    else:\n        logger.info(f\"Image {image_name} already exists, skipping build.\")\n\ndef setup_logger(name, log_file):\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    handler = logging.FileHandler(log_file)\n    handler.setFormatter(formatter)\n\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n    logger.addHandler(handler)\n\n    return logger\n\ndef build_container(test_spec, client, run_id, logger, nocache=False, force_rebuild=False):\n    if force_rebuild:\n        remove_image(client, test_spec.instance_image_key, \"quiet\")\n    if not test_spec.is_remote_image:\n        build_instance_image(test_spec, client, logger, nocache)\n    else:\n        try:\n            client.images.get(test_spec.instance_image_key)\n        except docker.errors.ImageNotFound:\n            try:\n                client.images.pull(test_spec.instance_image_key)\n            except docker.errors.NotFound as e:\n                raise BuildImageError(test_spec.instance_id, str(e), logger) from e\n            except Exception as e:\n                raise Exception(\n                    f\"Error occurred while pulling image {test_spec.base_image_key}: {str(e)}\"\n                )\n\n    container = None\n    try:\n        run_args = test_spec.docker_specs.get(\"run_args\", {})\n        cap_add = run_args.get(\"cap_add\", [])\n\n        container = client.containers.create(\n            image=test_spec.instance_image_key,\n            name=test_spec.get_instance_container_name(run_id),\n            user=DOCKER_USER,\n            detach=True,\n            command=\"tail -f /dev/null\",\n            platform=test_spec.platform,\n            cap_add=cap_add\n        )\n        logger.info(f\"Container for {test_spec.instance_id} created: {container.id}\")\n    except Exception as e:\n        logging.error(f\"Error creating container for {test_spec.instance_id}: {e}\")\n        logging.error(format_exc())\n        cleanup_container(client, container, logger)\n        raise BuildImageError(test_spec.instance_id, str(e), logger) from e\n\ndef cleanup_container(client, container, logger):\n    if container is not None:\n        try:\n            container.remove(force=True)\n        except Exception as e:\n            logger.error(f\"Failed to remove container {container.id}: {e}\")\n",
      "original_issues": [
        {
          "file": "docker_build.py",
          "line": 29,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'super'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "docker_build.py",
          "line": 30,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'super'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "docker_build.py",
          "line": 388,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'build_instance_image'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "docker_build.py",
          "line": 419,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "docker_build.py",
          "line": 155,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "docker_build.py",
          "line": 502,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "docker_build.py",
          "line": 527,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "docker_utils.py",
      "path": "fixed_files\\docker_utils.py",
      "fixed_content": "from __future__ import annotations\n\nimport docker\nimport docker.errors\nimport os\nimport signal\nimport tarfile\nimport threading\nimport time\nimport traceback\nfrom pathlib import Path\n\nfrom docker.models.containers import Container\n\nHEREDOC_DELIMITER = \"EOF_1399519320\"  # different from dataset HEREDOC_DELIMITERs!\n\n\ndef copy_to_container(container: Container, src: Path, dst: Path):\n    \"\"\"\n    Copy a file from local to a docker container\n\n    Args:\n        container (Container): Docker container to copy to\n        src (Path): Source file path\n        dst (Path): Destination file path in the container\n    \"\"\"\n    # Check if destination path is valid\n    if os.path.dirname(dst) == \"\":\n        raise ValueError(\n            f\"Destination path parent directory cannot be empty!, dst: {dst}\"\n        )\n\n    # temporary tar file\n    tar_path = src.with_suffix(\".tar\")\n    with tarfile.open(tar_path, \"w\") as tar:\n        tar.add(\n            src, arcname=dst.name\n        )  # use destination name, so after `put_archive`, name is correct\n\n    # get bytes for put_archive cmd\n    with open(tar_path, \"rb\") as tar_file:\n        data = tar_file.read()\n\n    # Make directory if necessary\n    container.exec_run(f\"mkdir -p {dst.parent}\")\n\n    # Send tar file to container and extract\n    container.put_archive(os.path.dirname(dst), data)\n\n    # clean up in locally and in container\n    tar_path.unlink()\n\n\ndef write_to_container(container: Container, data: str, dst: Path):\n    \"\"\"\n    Write a string to a file in a docker container\n    \"\"\"\n    # echo with heredoc to file\n    command = f\"cat <<'{HEREDOC_DELIMITER}' > {dst}\\n{data}\\n{HEREDOC_DELIMITER}\"\n    container.exec_run(command)\n\n\ndef remove_image(client, image_id, logger=None):\n    \"\"\"\n    Remove a Docker image by ID.\n\n    Args:\n        client (docker.DockerClient): Docker client.\n        image_id (str): Image ID.\n        rm_image (bool): Whether to remove the image.\n        logger (logging.Logger): Logger to use for output. If None, print to stdout.\n    \"\"\"\n    if not logger:\n        # if logger is None, print to stdout\n        log_info = print\n        log_error = print\n        raise_error = True\n    elif logger == \"quiet\":\n        # if logger is \"quiet\", don't print anything\n        log_info = lambda x: None\n        log_error = lambda x: None\n        raise_error = True\n    else:\n        # if logger is a logger object, use it\n        log_error = logger.info\n        log_info = logger.info\n        raise_error = False\n    try:\n        log_info(f\"Attempting to remove image {image_id}...\")\n        client.images.remove(image_id, force=True)\n        log_info(f\"Image {image_id} removed.\")\n    except docker.errors.ImageNotFound:\n        log_info(f\"Image {image_id} not found, removing has no effect.\")\n    except Exception as e:\n        if raise_error:\n            raise e\n        log_error(f\"Failed to remove image {image_id}: {e}\\n{traceback.format_exc()}\")\n\n\ndef cleanup_container(client, container, logger):\n    \"\"\"\n    Stop and remove a Docker container.\n    Performs this forcefully if the container cannot be stopped with the python API.\n\n    Args:\n        client (docker.DockerClient): Docker client.\n        container (docker.models.containers.Container): Container to remove.\n        logger (logging.Logger): Logger to use for output. If None, print to stdout\n    \"\"\"\n    if not container:\n        return\n\n    container_id = container.id\n\n    if not logger:\n        # if logger is None, print to stdout\n        log_error = print\n        log_info = print\n        raise_error = True\n    elif logger == \"quiet\":\n        # if logger is \"quiet\", don't print anything\n        log_info = lambda x: None\n        log_error = lambda x: None\n        raise_error = True\n    else:\n        # if logger is a logger object, use it\n        log_error = logger.info\n        log_info = logger.info\n        raise_error = False\n\n    # Attempt to stop the container\n    try:\n        if container:\n            log_info(f\"Attempting to stop container {container.name}...\")\n            container.stop(timeout=15)\n    except Exception as e:\n        log_error(\n            f\"Failed to stop container {container.name}: {e}. Trying to forcefully kill...\"\n        )\n        try:\n            # Get the PID of the container\n            container_info = client.api.inspect_container(container_id)\n            pid = container_info[\"State\"].get(\"Pid\", 0)\n\n            # If container PID found, forcefully kill the container\n            if pid > 0:\n                log_info(\n                    f\"Forcefully killing container {container.name} with PID {pid}...\"\n                )\n                os.kill(pid, signal.SIGKILL)\n            else:\n                log_error(f\"PID for container {container.name}: {pid} - not killing.\")\n        except Exception as e2:\n            if raise_error:\n                raise e2\n            log_error(\n                f\"Failed to forcefully kill container {container.name}: {e2}\\n\"\n                f\"{traceback.format_exc()}\"\n            )\n\n    # Attempt to remove the container\n    try:\n        log_info(f\"Attempting to remove container {container.name}...\")\n        container.remove(force=True)\n        log_info(f\"Container {container.name} removed.\")\n    except Exception as e:\n        if raise_error:\n            raise e\n        log_error(\n            f\"Failed to remove container {container.name}: {e}\\n\"\n            f\"{traceback.format_exc()}\"\n        )\n\n\ndef exec_run_with_timeout(container, cmd, timeout: int | None = 60):\n    \"\"\"\n    Run a command in a container with a timeout.\n\n    Args:\n        container (docker.Container): Container to run the command in.\n        cmd (str): Command to run.\n        timeout (int): Timeout in seconds.\n    \"\"\"\n    # Local variables to store the result of executing the command\n    exec_result = b\"\"\n    exec_id = None\n    exception = None\n    timed_out = False\n\n    # Wrapper function to run the command\n    def run_command():\n        nonlocal exec_result, exec_id, exception\n        try:\n            exec_id = container.client.api.exec_create(container.id, cmd)[\"Id\"]\n            exec_stream = container.client.api.exec_start(exec_id, stream=True)\n            for chunk in exec_stream:\n                exec_result += chunk\n        except Exception as e:\n            exception = e\n\n    # Start the command in a separate thread\n    thread = threading.Thread(target=run_command)\n    start_time = time.time()\n    thread.start()\n    thread.join(timeout)\n\n    if exception:\n        raise exception\n\n    # If the thread is still alive, the command timed out\n    if thread.is_alive():\n        if exec_id != None:\n            exec_pid = container.client.api.exec_inspect(exec_id)[\"Pid\"]\n            container.exec_run(f\"kill -TERM {exec_pid}\", detach=True)\n        timed_out = True\n    end_time = time.time()\n    return exec_result.decode(), timed_out, end_time - start_time\n\n\ndef find_dependent_images(client: docker.DockerClient, image_name: str):\n    \"\"\"\n    Find all images that are built upon `image_name` image\n\n    Args:\n        client (docker.DockerClient): Docker client.\n        image_name (str): Name of the base image.\n    \"\"\"\n    dependent_images = []\n\n    # Get all local images\n    all_images = client.images.list()\n\n    # Get the ID of the base image\n    try:\n        base_image = client.images.get(image_name)\n        base_image_id = base_image.id\n    except docker.errors.ImageNotFound:\n        print(f\"Base image {image_name} not found.\")\n        return []\n\n    for image in all_images:\n        # Skip the base image itself\n        if image.id == base_image_id:\n            continue\n\n        # Check if the base image is in this image's history\n        history = image.history()\n        for layer in history:\n            if layer[\"Id\"] == base_image_id:\n                # If found, add this image to the dependent images list\n                tags = image.tags\n                dependent_images.append(tags[0] if tags else image.id)\n                break\n\n    return dependent_images\n\n\ndef list_images(client: docker.DockerClient):\n    \"\"\"\n    List all images from the Docker client.\n    \"\"\"\n    # don't use this in multi-threaded context\n    return {tag for i in client.images.list(all=True) for tag in i.tags}\n\n\ndef clean_images(\n    client: docker.DockerClient, prior_images: set, cache_level: str, clean: bool\n):\n    \"\"\"\n    Clean Docker images based on cache level and clean flag.\n\n    Args:\n        client (docker.DockerClient): Docker client.\n        prior_images (set): Set of images that existed before the current run.\n        cache (str): Cache level to use.\n        clean (bool): Whether to clean; remove images that are higher in the cache hierarchy than the current\n            cache level. E.g. if cache_level is set to env, remove all previously built instances images. if\n            clean is false, previously built instances images will not be removed, but instance images built\n            in the current run will be removed.\n    \"\"\"\n    images = list_images(client)\n    removed = 0\n    print(\"Cleaning cached images...\")\n    for image_name in images:\n        if should_remove(image_name, cache_level, clean, prior_images):\n            try:\n                remove_image(client, image_name, \"quiet\")\n                removed += 1\n            except Exception as e:\n                print(f\"Error removing image {image_name}: {e}\")\n                continue\n    print(f\"Removed {removed} images.\")\n\n\ndef should_remove(image_name: str, cache_level: str, clean: bool, prior_images: set):\n    \"\"\"\n    Determine if an image should be removed based on cache level and clean flag.\n    \"\"\"\n    existed_before = image_name in prior_images\n    if \"/\" in image_name:\n        image_name = image_name.rsplit(\"/\", 1)[-1]\n    if image_name.startswith(\"sweb.base\"):\n        if cache_level in {\"none\"} and (clean or not existed_before):\n            return True\n    elif image_name.startswith(\"sweb.env\"):\n        if cache_level in {\"none\", \"base\"} and (clean or not existed_before):\n            return True\n    elif image_name.startswith(\"sweb.eval\"):\n        if cache_level in {\"none\", \"base\", \"env\"} and (clean or not existed_before):\n            return True\n    return False",
      "original_issues": [
        {
          "file": "docker_utils.py",
          "line": 285,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'should_remove'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "docker_utils.py",
          "line": 212,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "docker_utils.py",
          "line": 94,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "docker_utils.py",
          "line": 136,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "docker_utils.py",
          "line": 153,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "docker_utils.py",
          "line": 166,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "docker_utils.py",
          "line": 198,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "docker_utils.py",
          "line": 289,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "grading.py",
      "path": "fixed_files\\grading.py",
      "fixed_content": "from typing import Any\n\nfrom swebench.harness.constants import (\n    APPLY_PATCH_FAIL,\n    END_TEST_OUTPUT,\n    FAIL_ONLY_REPOS,\n    FAIL_TO_FAIL,\n    FAIL_TO_PASS,\n    KEY_INSTANCE_ID,\n    KEY_PREDICTION,\n    MAP_REPO_VERSION_TO_SPECS,\n    PASS_TO_FAIL,\n    PASS_TO_PASS,\n    RESET_FAILED,\n    START_TEST_OUTPUT,\n    TESTS_ERROR,\n    TESTS_TIMEOUT,\n    EvalType,\n    ResolvedStatus,\n    TestStatus,\n)\nfrom swebench.harness.test_spec.test_spec import TestSpec\nfrom swebench.harness.log_parsers import MAP_REPO_TO_PARSER\n\n\n# MARK: Utility functions\ndef test_passed(case: str, sm: dict[str, str]) -> bool:\n    return case in sm and sm[case] in [TestStatus.PASSED.value, TestStatus.XFAIL.value]\n\n\ndef test_failed(case: str, sm: dict[str, str]) -> bool:\n    return case not in sm or sm[case] in [\n        TestStatus.FAILED.value,\n        TestStatus.ERROR.value,\n    ]\n\n\n# MARK: Evaluation report functions\ndef get_logs_eval(test_spec: TestSpec, log_fp: str) -> tuple[dict[str, str], bool]:\n    \"\"\"\n    Retrieve evaluation results for a task instance from its corresponding log file\n\n    Args:\n        log_fp (str): path to log file\n    Returns:\n        bool: whether the patch applied successfully\n        dict: status map\n\n    TODO(john-b-yang): Check this is working properly...\n    \"\"\"\n    repo = test_spec.repo\n    version = test_spec.version\n    log_parser = MAP_REPO_TO_PARSER[repo]\n    test_cmd = MAP_REPO_VERSION_TO_SPECS[repo][version][\"test_cmd\"]\n    if isinstance(test_cmd, list):\n        test_cmd = test_cmd[-1]\n\n    with open(log_fp) as f:\n        content = f.read()\n        # TODO fix constant here\n        bad_codes = list(\n            filter(\n                lambda x: x in content,\n                [\n                    APPLY_PATCH_FAIL,\n                    RESET_FAILED,\n                    TESTS_ERROR,\n                    TESTS_TIMEOUT,\n                ],\n            )\n        )\n        if bad_codes:\n            return {}, False\n        elif not (START_TEST_OUTPUT in content and END_TEST_OUTPUT in content):\n            # Test patch did not apply (should not happen at all)\n            return {}, False\n\n        # Get status map of evaluation results\n        test_content = content.split(START_TEST_OUTPUT)[1].split(END_TEST_OUTPUT)[0]\n\n        # Try parsing the content between markers first\n        status_map = log_parser(test_content, test_spec)\n\n        # If no test results found between markers (common in Modal environment),\n        # try parsing the entire log content as fallback\n        if not status_map:\n            # Look for pytest output patterns in the entire log content\n            # This handles cases where pytest output goes to stderr and isn't captured between markers\n            status_map = log_parser(content, test_spec)\n\n        return status_map, True\n\n\ndef get_eval_tests_report(\n    eval_status_map: dict[str, str],\n    gold_results: dict[str, str],\n    calculate_to_fail: bool = False,\n    eval_type: EvalType = EvalType.PASS_AND_FAIL,\n) -> dict[str, dict[str, list[str]]]:\n    \"\"\"\n    Create a report based on failure/pass change from gold results to eval results.\n\n    Args:\n        eval_sm (dict): evaluation status map\n        gold_results (dict): gold results\n        calculate_to_fail (bool): whether to calculate metrics for \"x to fail\" tests\n    Returns:\n        report (dict): report of metrics\n\n    Metric Definitions (Gold Result Pair + Eval Result):\n    - Fail-Pass (F2P) + P: Success (Resolution)\n    - Pass-Pass (P2P) + P: Success (Maintenance)\n    - Fail-Pass (F2P) + F: Failure\n    - Pass-Pass (P2P) + F: Failure\n\n    Miscellaneous Definitions\n    - Fail-Fail (F2F) + F: Failure Maintenance\n    - Pass-Fail (P2F) + F: Not considered\n    - Fail-Fail (F2F) + P: Success (Extra Credit)\n    - Pass-Fail (P2F) + P: Not considered\n    \"\"\"\n\n    def check_pass_and_fail(test_case, eval_status_map, success, failed):\n        if test_passed(test_case, eval_status_map):\n            # Assume silent success for now (test case not in eval_sm)\n            success.append(test_case)\n        elif test_failed(test_case, eval_status_map):\n            failed.append(test_case)\n\n    def check_fail_only(test_case, eval_status_map, success, failed):\n        if (\n            test_case in eval_status_map\n            and eval_status_map[test_case] == TestStatus.FAILED.value\n        ):\n            failed.append(test_case)\n        else:\n            success.append(test_case)\n\n    check_test_case = (\n        check_pass_and_fail if eval_type == EvalType.PASS_AND_FAIL else check_fail_only\n    )\n\n    # Calculate resolution metrics\n    f2p_success = []\n    f2p_failure = []\n    for test_case in gold_results[FAIL_TO_PASS]:\n        check_test_case(test_case, eval_status_map, f2p_success, f2p_failure)\n\n    # Calculate maintenance metrics\n    p2p_success = []\n    p2p_failure = []\n    for test_case in gold_results[PASS_TO_PASS]:\n        check_test_case(test_case, eval_status_map, p2p_success, p2p_failure)\n\n    results = {\n        FAIL_TO_PASS: {\n            \"success\": f2p_success,\n            \"failure\": f2p_failure,\n        },\n        PASS_TO_PASS: {\n            \"success\": p2p_success,\n            \"failure\": p2p_failure,\n        },\n    }\n\n    f2f_success = []\n    f2f_failure = []\n    p2f_success = []\n    p2f_failure = []\n    if calculate_to_fail:\n        # Calculate \"extra credit\" metrics\n        for test_case in gold_results[FAIL_TO_FAIL]:\n            check_test_case(test_case, eval_status_map, f2f_success, f2f_failure)\n\n        # Calculate not considered metrics\n        for test_case in gold_results[PASS_TO_FAIL]:\n            check_test_case(test_case, eval_status_map, p2f_success, p2f_failure)\n\n    results.update(\n        {\n            FAIL_TO_FAIL: {\n                \"success\": f2f_success,\n                \"failure\": f2f_failure,\n            },\n            PASS_TO_FAIL: {\n                \"success\": p2f_success,\n                \"failure\": p2f_failure,\n            },\n        }\n    )\n    return results\n\n\ndef compute_fail_to_pass(report: dict[str, dict[str, Any]]) -> float:\n    \"\"\"\n    Compute fail-to-pass metric. Accepts single report as argument.\n    \"\"\"\n    total = len(report[FAIL_TO_PASS][\"success\"]) + len(report[FAIL_TO_PASS][\"failure\"])\n    if total == 0:\n        return 1\n    return len(report[FAIL_TO_PASS][\"success\"]) / total\n\n\ndef compute_pass_to_pass(report: dict[str, dict[str, Any]]) -> float:\n    \"\"\"\n    Compute pass-to-pass metric. Accepts single report as argument.\n    \"\"\"\n    total = len(report[PASS_TO_PASS][\"success\"]) + len(report[PASS_TO_PASS][\"failure\"])\n    if total == 0:\n        # TODO: Don't factor in p2p metrics\n        return 1\n    return len(report[PASS_TO_PASS][\"success\"]) / total\n\n\ndef get_resolution_status(report: dict[str, dict[str, Any]]) -> str:\n    \"\"\"\n    Determine resolved status of an evaluation instance\n\n    Criteria:\n        - If fail-to-pass (Resolution) = 1 and pass-to-pass (Maintenance) = 1 -> FULL\n        - If (fail-to-pass (Resolution) < 1 and > 0) and pass-to-pass (Maintenance) = 1 -> PARTIAL\n        - Otherwise -> NO\n    \"\"\"\n    f2p = compute_fail_to_pass(report)\n    p2p = compute_pass_to_pass(report)\n\n    if f2p == 1 and p2p == 1:\n        return ResolvedStatus.FULL.value\n    elif f2p < 1 and f2p > 0 and p2p == 1:\n        return ResolvedStatus.PARTIAL.value\n    else:\n        return ResolvedStatus.NO.value\n\n\ndef get_eval_report(\n    test_spec: TestSpec,\n    prediction: dict[str, str],\n    test_log_path: str,\n    include_tests_status: bool,\n) -> dict[str, Any]:\n    \"\"\"\n    Generate a report of model evaluation results from a prediction, task instance,\n    and evaluation log.\n\n    Args:\n        test_spec (dict): test spec containing keys \"instance_id\", \"FAIL_TO_PASS\", and \"PASS_TO_PASS\"\n        prediction (dict): prediction containing keys \"instance_id\", \"model_name_or_path\", and \"model_patch\"\n        log_path (str): path to evaluation log\n        include_tests_status (bool): whether to include the status of each test in the returned report\n    Returns:\n        report (dict): report of metrics\n    \"\"\"\n    report_map = {}\n\n    instance_id = prediction[KEY_INSTANCE_ID]\n    report_map[instance_id] = {\n        \"patch_is_None\": False,\n        \"patch_exists\": False,\n        \"patch_successfully_applied\": False,\n        \"resolved\": False,\n    }\n\n    # Check if the model patch exists\n    if prediction[KEY_PREDICTION] == None:\n        report_map[instance_id][\"patch_is_None\"] = True\n        return report_map\n    report_map[instance_id][\"patch_exists\"] = True\n\n    # Get evaluation logs\n    eval_status_map, found = get_logs_eval(test_spec, test_log_path)\n\n    if not found:\n        return report_map\n    report_map[instance_id][\"patch_successfully_applied\"] = True\n\n    eval_ref = {\n        KEY_INSTANCE_ID: test_spec.instance_id,\n        FAIL_TO_PASS: test_spec.FAIL_TO_PASS,\n        PASS_TO_PASS: test_spec.PASS_TO_PASS,\n    }\n\n    eval_type = (\n        EvalType.FAIL_ONLY\n        if test_spec.repo in FAIL_ONLY_REPOS\n        else EvalType.PASS_AND_FAIL\n    )\n\n    report = get_eval_tests_report(eval_status_map, eval_ref, eval_type=eval_type)\n    if get_resolution_status(report) == ResolvedStatus.FULL.value:\n        report_map[instance_id][\"resolved\"] = True\n\n    if include_tests_status:\n        report_map[instance_id][\"tests_status\"] = report  # type: ignore\n\n    return report_map",
      "original_issues": [
        {
          "file": "grading.py",
          "line": 63,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'x'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "grading.py",
          "line": 264,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "reporting.py",
      "path": "fixed_files\\reporting.py",
      "fixed_content": "import docker\nimport json\nfrom pathlib import Path\nfrom typing import Optional\n\nfrom swebench.harness.constants import (\n    KEY_INSTANCE_ID,\n    KEY_MODEL,\n    KEY_PREDICTION,\n    RUN_EVALUATION_LOG_DIR,\n    LOG_REPORT,\n)\nfrom swebench.harness.docker_utils import list_images\nfrom swebench.harness.test_spec.test_spec import make_test_spec\n\n\ndef make_run_report(\n    predictions: dict,\n    full_dataset: list,\n    run_id: str,\n    client: Optional[docker.DockerClient] = None,\n    namespace: str = None,\n    instance_image_tag: str = \"latest\",\n    env_image_tag: str = \"latest\",\n) -> Path:\n    \"\"\"\n    Make a final evaluation and run report of the instances that have been run.\n    Also reports on images and containers that may still running if client is provided.\n\n    Args:\n        predictions (dict): Predictions dict generated by the model\n        full_dataset (list): List of all instances\n        run_id (str): Run ID\n        client (docker.DockerClient): Docker client (optional)\n\n    Returns:\n        Path to report file\n    \"\"\"\n    # instantiate sets to store IDs of different outcomes\n    completed_ids = set()\n    resolved_ids = set()\n    error_ids = set()\n    unstopped_containers = set()\n    unremoved_images = set()\n    unresolved_ids = set()\n    incomplete_ids = set()\n    # get instances with empty patches\n    empty_patch_ids = set()\n\n    # iterate through dataset and check if the instance has been run\n    for instance in full_dataset:\n        instance_id = instance[KEY_INSTANCE_ID]\n        if instance_id not in predictions:\n            # skip instances without predictions\n            incomplete_ids.add(instance_id)\n            continue\n        prediction = predictions[instance_id]\n        if prediction.get(KEY_PREDICTION, None) in [\"\", None]:\n            empty_patch_ids.add(instance_id)\n            continue\n        report_file = (\n            RUN_EVALUATION_LOG_DIR\n            / run_id\n            / prediction[KEY_MODEL].replace(\"/\", \"__\")\n            / prediction[KEY_INSTANCE_ID]\n            / LOG_REPORT\n        )\n        if report_file.exists():\n            completed_ids.add(instance_id)\n            try:\n                content = report_file.read_text().strip()\n                if not content:  # Empty file\n                    error_ids.add(instance_id)\n                    continue\n\n                report = json.loads(content)\n                if report.get(prediction[KEY_INSTANCE_ID], {}).get(\"resolved\", False):\n                    # Record if the instance was resolved\n                    resolved_ids.add(instance_id)\n                else:\n                    unresolved_ids.add(instance_id)\n            except (json.JSONDecodeError, KeyError):\n                # If the report file is not valid JSON or missing keys, treat as error\n                error_ids.add(instance_id)\n        else:\n            # Otherwise, the instance was not run successfully\n            error_ids.add(instance_id)\n\n    if client:\n        # get remaining images and containers\n        images = list_images(client)\n        test_specs = list(\n            map(\n                lambda x: make_test_spec(\n                    x,\n                    namespace=namespace,\n                    instance_image_tag=instance_image_tag,\n                    env_image_tag=env_image_tag,\n                ),\n                full_dataset,\n            )\n        )\n        for spec in test_specs:\n            image_name = spec.instance_image_key\n            if image_name in images:\n                unremoved_images.add(image_name)\n        containers = client.containers.list(all=True)\n        for container in containers:\n            if run_id in container.name:\n                unstopped_containers.add(container.name)\n\n    # print final report\n    dataset_ids = {i[KEY_INSTANCE_ID] for i in full_dataset}\n    print(f\"Total instances: {len(full_dataset)}\")\n    print(f\"Instances submitted: {len(set(predictions.keys()) & dataset_ids)}\")\n    print(f\"Instances completed: {len(completed_ids)}\")\n    print(f\"Instances incomplete: {len(incomplete_ids)}\")\n    print(f\"Instances resolved: {len(resolved_ids)}\")\n    print(f\"Instances unresolved: {len(unresolved_ids)}\")\n    print(f\"Instances with empty patches: {len(empty_patch_ids)}\")\n    print(f\"Instances with errors: {len(error_ids)}\")\n    if client:\n        print(f\"Unstopped containers: {len(unstopped_containers)}\")\n        print(f\"Unremoved images: {len(unremoved_images)}\")\n\n    # write report to file\n    report = {\n        \"total_instances\": len(full_dataset),\n        \"submitted_instances\": len(predictions),\n        \"completed_instances\": len(completed_ids),\n        \"resolved_instances\": len(resolved_ids),\n        \"unresolved_instances\": len(unresolved_ids),\n        \"empty_patch_instances\": len(empty_patch_ids),\n        \"error_instances\": len(error_ids),\n        \"completed_ids\": list(sorted(completed_ids)),\n        \"incomplete_ids\": list(sorted(incomplete_ids)),\n        \"empty_patch_ids\": list(sorted(empty_patch_ids)),\n        \"submitted_ids\": list(sorted(predictions.keys())),\n        \"resolved_ids\": list(sorted(resolved_ids)),\n        \"unresolved_ids\": list(sorted(unresolved_ids)),\n        \"error_ids\": list(sorted(error_ids)),\n        \"schema_version\": 2,\n    }\n    if not client:\n        report.update(\n            {\n                \"unstopped_instances\": len(unstopped_containers),\n                \"unstopped_containers\": list(sorted(unstopped_containers)),\n                \"unremoved_images\": list(sorted(unremoved_images)),\n            }\n        )\n    report_file = Path(\n        list(predictions.values())[0][KEY_MODEL].replace(\"/\", \"__\")\n        + f\".{run_id}\"\n        + \".json\"\n    )\n    with open(report_file, \"w\") as f:\n        print(json.dumps(report, indent=4), file=f)\n    print(f\"Report written to {report_file}\")\n    return report_file\n",
      "original_issues": [
        {
          "file": "reporting.py",
          "line": 95,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'x'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "run_evaluation.py",
      "path": "fixed_files\\run_evaluation.py",
      "fixed_content": "from __future__ import annotations\n\nimport docker\nimport json\nimport platform\nimport threading\nimport traceback\n\nif platform.system() == \"Linux\":\n    import resource\n\nfrom argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\nfrom pathlib import Path, PurePosixPath\nfrom tqdm.auto import tqdm\n\nfrom swebench.harness.constants import (\n    APPLY_PATCH_FAIL,\n    APPLY_PATCH_PASS,\n    DOCKER_PATCH,\n    DOCKER_USER,\n    DOCKER_WORKDIR,\n    INSTANCE_IMAGE_BUILD_DIR,\n    KEY_INSTANCE_ID,\n    KEY_MODEL,\n    KEY_PREDICTION,\n    LOG_REPORT,\n    LOG_INSTANCE,\n    LOG_TEST_OUTPUT,\n    RUN_EVALUATION_LOG_DIR,\n    UTF8,\n)\nfrom swebench.harness.docker_utils import (\n    clean_images,\n    cleanup_container,\n    copy_to_container,\n    exec_run_with_timeout,\n    list_images,\n    remove_image,\n    should_remove,\n)\nfrom swebench.harness.docker_build import (\n    BuildImageError,\n    build_container,\n    build_env_images,\n    close_logger,\n    setup_logger,\n)\nfrom swebench.harness.grading import get_eval_report\nfrom swebench.harness.reporting import make_run_report\nfrom swebench.harness.modal_eval import (\n    run_instances_modal,\n    validate_modal_credentials,\n)\nfrom swebench.harness.test_spec.test_spec import make_test_spec, TestSpec\nfrom swebench.harness.utils import (\n    EvaluationError,\n    load_swebench_dataset,\n    get_predictions_from_file,\n    run_threadpool,\n    str2bool,\n    optional_str,\n)\n\nGIT_APPLY_CMDS = [\n    \"git apply --verbose\",\n    \"git apply --verbose --reject\",\n    \"patch --batch --fuzz=5 -p1 -i\",\n]\n\n\ndef run_instance(\n    test_spec: TestSpec,\n    pred: dict,\n    rm_image: bool,\n    force_rebuild: bool,\n    client: docker.DockerClient,\n    run_id: str,\n    timeout: int | None = None,\n    rewrite_reports: bool = False,\n) -> dict:\n    \"\"\"\n    Run a single instance with the given prediction.\n\n    Args:\n        test_spec (TestSpec): TestSpec instance\n        pred (dict): Prediction w/ model_name_or_path, model_patch, instance_id\n        rm_image (bool): Whether to remove the image after running\n        force_rebuild (bool): Whether to force rebuild the image\n        client (docker.DockerClient): Docker client\n        run_id (str): Run ID\n        timeout (int): Timeout for running tests\n        rewrite_reports (bool): True if eval run is just to reformat existing report\n    \"\"\"\n    # Set up logging directory\n    instance_id = test_spec.instance_id\n    model_name_or_path = pred.get(KEY_MODEL, \"None\").replace(\"/\", \"__\")\n    log_dir = RUN_EVALUATION_LOG_DIR / run_id / model_name_or_path / instance_id\n\n    # Set up report file\n    report_path = log_dir / LOG_REPORT\n    if rewrite_reports:\n        test_output_path = log_dir / LOG_TEST_OUTPUT\n        if not test_output_path.exists():\n            raise ValueError(f\"Test output file {test_output_path} does not exist\")\n        report = get_eval_report(\n            test_spec=test_spec,\n            prediction=pred,\n            test_log_path=test_output_path,\n            include_tests_status=True,\n        )\n        # Write report to report.json\n        with open(report_path, \"w\") as f:\n            f.write(json.dumps(report, indent=4))\n        return {\n            \"completed\": True,\n            \"resolved\": report[instance_id][\"resolved\"],\n        }\n    if report_path.exists():\n        report = json.loads(report_path.read_text())\n        return {\n            \"completed\": True,\n            \"resolved\": report[instance_id][\"resolved\"],\n        }\n\n    if not test_spec.is_remote_image:\n        # Link the image build dir in the log dir\n        build_dir = INSTANCE_IMAGE_BUILD_DIR / test_spec.instance_image_key.replace(\n            \":\", \"__\"\n        )\n        image_build_link = log_dir / \"image_build_dir\"\n        if not image_build_link.exists():\n            try:\n                # link the image build dir in the log dir\n                image_build_link.symlink_to(\n                    build_dir.absolute(), target_is_directory=True\n                )\n            except:\n                # some error, idk why\n                pass\n\n    # Set up logger\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file = log_dir / LOG_INSTANCE\n    logger = setup_logger(instance_id, log_file)\n\n    # Run the instance\n    container = None\n    eval_completed = False\n    report = {}\n    try:\n        # Build + start instance container (instance image should already be built)\n        container = build_container(\n            test_spec, client, run_id, logger, rm_image, force_rebuild\n        )\n        container.start()\n        logger.info(f\"Container for {instance_id} started: {container.id}\")\n\n        # Copy model prediction as patch file to container\n        patch_file = Path(log_dir / \"patch.diff\")\n        patch_file.write_text(pred[KEY_PREDICTION] or \"\")\n        logger.info(\n            f\"Intermediate patch for {instance_id} written to {patch_file}, now applying to container...\"\n        )\n        copy_to_container(container, patch_file, PurePosixPath(DOCKER_PATCH))\n\n        # Attempt to apply patch to container (TODO: FIX THIS)\n        applied_patch = False\n        for git_apply_cmd in GIT_APPLY_CMDS:\n            val = container.exec_run(\n                f\"{git_apply_cmd} {DOCKER_PATCH}\",\n                workdir=DOCKER_WORKDIR,\n                user=DOCKER_USER,\n            )\n            if val.exit_code == 0:\n                logger.info(f\"{APPLY_PATCH_PASS}:\\n{val.output.decode(UTF8)}\")\n                applied_patch = True\n                break\n            else:\n                logger.info(f\"Failed to apply patch to container: {git_apply_cmd}\")\n        if not applied_patch:\n            logger.info(f\"{APPLY_PATCH_FAIL}:\\n{val.output.decode(UTF8)}\")\n            raise EvaluationError(\n                instance_id,\n                f\"{APPLY_PATCH_FAIL}:\\n{val.output.decode(UTF8)}\",\n                logger,\n            )\n\n        # Get git diff before running eval script\n        git_diff_output_before = (\n            container.exec_run(\n                \"git -c core.fileMode=false diff\", workdir=DOCKER_WORKDIR\n            )\n            .output.decode(UTF8)\n            .strip()\n        )\n        logger.info(f\"Git diff before:\\n{git_diff_output_before}\")\n\n        eval_file = Path(log_dir / \"eval.sh\")\n        eval_file.write_text(test_spec.eval_script)\n        logger.info(\n            f\"Eval script for {instance_id} written to {eval_file}; copying to container...\"\n        )\n        copy_to_container(container, eval_file, PurePosixPath(\"/eval.sh\"))\n\n        # Run eval script, write output to logs\n        test_output, timed_out, total_runtime = exec_run_with_timeout(\n            container, \"/bin/bash /eval.sh\", timeout\n        )\n        test_output_path = log_dir / LOG_TEST_OUTPUT\n        logger.info(f\"Test runtime: {total_runtime:_.2f} seconds\")\n        with open(test_output_path, \"w\") as f:\n            f.write(test_output)\n            logger.info(f\"Test output for {instance_id} written to {test_output_path}\")\n            if timed_out:\n                f.write(f\"\\n\\nTimeout error: {timeout} seconds exceeded.\")\n                raise EvaluationError(\n                    instance_id,\n                    f\"Test timed out after {timeout} seconds.\",\n                    logger,\n                )\n\n        # Get git diff after running eval script (ignore permission changes)\n        git_diff_output_after = (\n            container.exec_run(\n                \"git -c core.fileMode=false diff\", workdir=DOCKER_WORKDIR\n            )\n            .output.decode(UTF8)\n            .strip()\n        )\n\n        # Check if git diff changed after running eval script\n        logger.info(f\"Git diff after:\\n{git_diff_output_after}\")\n        if git_diff_output_after != git_diff_output_before:\n            logger.info(\"Git diff changed after running eval script\")\n\n        # Get report from test output\n        logger.info(f\"Grading answer for {instance_id}...\")\n        report = get_eval_report(\n            test_spec=test_spec,\n            prediction=pred,\n            test_log_path=test_output_path,\n            include_tests_status=True,\n        )\n        logger.info(\n            f\"report: {report}\\n\"\n            f\"Result for {instance_id}: resolved: {report[instance_id]['resolved']}\"\n        )\n\n        # Write report to report.json\n        with open(report_path, \"w\") as f:\n            f.write(json.dumps(report, indent=4))\n        eval_completed = True\n    except (EvaluationError, BuildImageError) as e:\n        error_msg = traceback.format_exc()\n        logger.info(error_msg)\n        print(e)\n    except Exception as e:\n        error_msg = (\n            f\"Error in evaluating model for {instance_id}: {e}\\n\"\n            f\"{traceback.format_exc()}\\n\"\n            f\"Check ({logger.log_file}) for more information.\"\n        )\n        logger.error(error_msg)\n    finally:\n        # Remove instance container + image, close logger\n        cleanup_container(client, container, logger)\n        if rm_image:\n            remove_image(client, test_spec.instance_image_key, logger)\n        close_logger(logger)\n        return {\n            \"completed\": eval_completed,\n            \"resolved\": report.get(instance_id, {}).get(\"resolved\", False),\n        }\n\n\ndef run_instances(\n    predictions: dict,\n    instances: list,\n    cache_level: str,\n    clean: bool,\n    force_rebuild: bool,\n    max_workers: int,\n    run_id: str,\n    timeout: int,\n    namespace: str | None = \"swebench\",\n    instance_image_tag: str = \"latest\",\n    env_image_tag: str = \"latest\",\n    rewrite_reports: bool = False,\n):\n    \"\"\"\n    Run all instances for the given predictions in parallel.\n\n    Args:\n        predictions (dict): Predictions dict generated by the model\n        instances (list): List of instances\n        cache_level (str): Cache level\n        clean (bool): Clean images above cache level\n        force_rebuild (bool): Force rebuild images\n        max_workers (int): Maximum number of workers\n        run_id (str): Run ID\n        timeout (int): Timeout for running tests\n    \"\"\"\n    client = docker.from_env()\n    test_specs = list(\n        map(\n            lambda instance: make_test_spec(\n                instance,\n                namespace=namespace,\n                instance_image_tag=instance_image_tag,\n                env_image_tag=env_image_tag,\n            ),\n            instances,\n        )\n    )\n\n    # print number of existing instance images\n    instance_image_ids = {x.instance_image_key for x in test_specs}\n    existing_images = {\n        tag\n        for i in client.images.list(all=True)\n        for tag in i.tags\n        if tag in instance_image_ids\n    }\n    if not force_rebuild and len(existing_images):\n        print(\n            f\"Found {len(existing_images)} existing instance images. Will reuse them.\"\n        )\n\n    # run instances in parallel\n    payloads = []\n    for test_spec in test_specs:\n        payloads.append(\n            (\n                test_spec,\n                predictions[test_spec.instance_id],\n                should_remove(\n                    test_spec.instance_image_key,\n                    cache_level,\n                    clean,\n                    existing_images,\n                ),\n                force_rebuild,\n                client,\n                run_id,\n                timeout,\n                rewrite_reports,\n            )\n        )\n\n    # run instances in parallel\n    print(f\"Running {len(instances)} instances...\")\n    stats = {\"✓\": 0, \"✖\": 0, \"error\": 0}\n    pbar = tqdm(total=len(payloads), desc=\"Evaluation\", postfix=stats)\n    lock = threading.Lock()\n\n    def run_evaluation_with_progress(*args):\n        result = run_instance(*args)\n        with lock:\n            if result[\"completed\"]:\n                if result[\"resolved\"]:\n                    stats[\"✓\"] += 1\n                else:\n                    stats[\"✖\"] += 1\n            else:\n                stats[\"error\"] += 1\n            pbar.set_postfix(stats)\n            pbar.update()\n        return result\n\n    run_threadpool(run_evaluation_with_progress, payloads, max_workers)\n    print(\"All instances run.\")\n\n\ndef get_dataset_from_preds(\n    dataset_name: str,\n    split: str,\n    instance_ids: list,\n    predictions: dict,\n    run_id: str,\n    rewrite_reports: bool,\n    exclude_completed: bool = True,\n):\n    \"\"\"\n    Return only instances that have predictions and are in the dataset.\n    If instance_ids is provided, only return instances with those IDs.\n    If exclude_completed is True, only return instances that have not been run yet.\n    \"\"\"\n    # load dataset\n    dataset = load_swebench_dataset(dataset_name, split)\n    dataset_ids = {i[KEY_INSTANCE_ID] for i in dataset}\n\n    if instance_ids:\n        # check that all instance IDs have predictions\n        missing_preds = set(instance_ids) - set(predictions.keys())\n        if missing_preds:\n            print(\n                f\"Warning: Missing predictions for {len(missing_preds)} instance IDs.\"\n            )\n\n    # check that all prediction IDs are in the dataset\n    prediction_ids = set(predictions.keys())\n    if prediction_ids - dataset_ids:\n        raise ValueError(\n            (\n                \"Some prediction IDs not found in dataset!\"\n                f\"\\nMissing IDs:\\n{' '.join(prediction_ids - dataset_ids)}\"\n            )\n        )\n    if instance_ids:\n        dataset = [i for i in dataset if i[KEY_INSTANCE_ID] in instance_ids]\n\n    if rewrite_reports:\n        # we only return instances that have existing test outputs\n        test_output_ids = set()\n        for instance in dataset:\n            if instance[KEY_INSTANCE_ID] not in predictions:\n                continue\n            prediction = predictions[instance[KEY_INSTANCE_ID]]\n            test_output_file = (\n                RUN_EVALUATION_LOG_DIR\n                / run_id\n                / prediction[\"model_name_or_path\"].replace(\"/\", \"__\")\n                / prediction[KEY_INSTANCE_ID]\n                / \"test_output.txt\"\n            )\n            if test_output_file.exists():\n                test_output_ids.add(instance[KEY_INSTANCE_ID])\n        dataset = [\n            i\n            for i in dataset\n            if i[KEY_INSTANCE_ID] in prediction_ids\n            and i[KEY_INSTANCE_ID] in test_output_ids\n        ]\n        return dataset\n\n    # check which instance IDs have already been run\n    completed_ids = set()\n    for instance in dataset:\n        if instance[KEY_INSTANCE_ID] not in prediction_ids:\n            # skip instances without predictions\n            continue\n        prediction = predictions[instance[KEY_INSTANCE_ID]]\n        report_file = (\n            RUN_EVALUATION_LOG_DIR\n            / run_id\n            / prediction[KEY_MODEL].replace(\"/\", \"__\")\n            / prediction[KEY_INSTANCE_ID]\n            / LOG_REPORT\n        )\n        if report_file.exists():\n            completed_ids.add(instance[KEY_INSTANCE_ID])\n\n    if completed_ids and exclude_completed:\n        # filter dataset to only instances that have not been run\n        print(f\"{len(completed_ids)} instances already run, skipping...\")\n        dataset = [i for i in dataset if i[KEY_INSTANCE_ID] not in completed_ids]\n\n    empty_patch_ids = {\n        k\n        for k, v in predictions.items()\n        if v[KEY_PREDICTION] == \"\" or v[KEY_PREDICTION] == None\n    }\n\n    # filter dataset to only instances with predictions\n    dataset = [\n        i\n        for i in dataset\n        if i[KEY_INSTANCE_ID] in prediction_ids\n        and i[KEY_INSTANCE_ID] not in empty_patch_ids\n    ]\n    return dataset\n\n\ndef main(\n    dataset_name: str,\n    split: str,\n    instance_ids: list,\n    predictions_path: str,\n    max_workers: int,\n    force_rebuild: bool,\n    cache_level: str,\n    clean: bool,\n    open_file_limit: int,\n    run_id: str,\n    timeout: int,\n    namespace: str | None,\n    rewrite_reports: bool,\n    modal: bool,\n    instance_image_tag: str = \"latest\",\n    env_image_tag: str = \"latest\",\n    report_dir: str = \".\",\n):\n    \"\"\"\n    Run evaluation harness for the given dataset and predictions.\n    \"\"\"\n    if dataset_name == \"SWE-bench/SWE-bench_Multimodal\" and split == \"test\":\n        print(\n            \"⚠️ Local evaluation for the test split of SWE-bench Multimodal is not supported. \"\n            \"Please check out sb-cli (https://github.com/swe-bench/sb-cli/) for instructions on how to submit predictions.\"\n        )\n        return\n\n    # set open file limit\n    assert len(run_id) > 0, \"Run ID must be provided\"\n    if report_dir != None:\n        report_dir = Path(report_dir)\n        if not report_dir.exists():\n            report_dir.mkdir(parents=True)\n\n    if force_rebuild and namespace != None:\n        raise ValueError(\"Cannot force rebuild and use a namespace at the same time.\")\n\n    # load predictions as map of instance_id to prediction\n    predictions = get_predictions_from_file(predictions_path, dataset_name, split)\n    predictions = {pred[KEY_INSTANCE_ID]: pred for pred in predictions}\n\n    # get dataset from predictions\n    dataset = get_dataset_from_preds(\n        dataset_name, split, instance_ids, predictions, run_id, rewrite_reports\n    )\n    full_dataset = load_swebench_dataset(dataset_name, split, instance_ids)\n\n    if modal:\n        # run instances on Modal\n        if not dataset:\n            print(\"No instances to run.\")\n        else:\n            validate_modal_credentials()\n            run_instances_modal(predictions, dataset, full_dataset, run_id, timeout)\n        return\n\n    # run instances locally\n    if platform.system() == \"Linux\":\n        resource.setrlimit(resource.RLIMIT_NOFILE, (open_file_limit, open_file_limit))\n    client = docker.from_env()\n\n    existing_images = list_images(client)\n    if not dataset:\n        print(\"No instances to run.\")\n    else:\n        # build environment images + run instances\n        if namespace == None and not rewrite_reports:\n            build_env_images(\n                client,\n                dataset,\n                force_rebuild,\n                max_workers,\n                namespace,\n                instance_image_tag,\n                env_image_tag,\n            )\n        run_instances(\n            predictions,\n            dataset,\n            cache_level,\n            clean,\n            force_rebuild,\n            max_workers,\n            run_id,\n            timeout,\n            namespace=namespace,\n            instance_image_tag=instance_image_tag,\n            env_image_tag=env_image_tag,\n            rewrite_reports=rewrite_reports,\n        )\n\n    # clean images + make final report\n    clean_images(client, existing_images, cache_level, clean)\n    return make_run_report(\n        predictions,\n        full_dataset,\n        run_id,\n        client,\n        namespace,\n        instance_image_tag,\n        env_image_tag,\n    )\n\n\nif __name__ == \"__main__\":\n    parser = ArgumentParser(\n        description=\"Run evaluation harness for the given dataset and predictions.\",\n        formatter_class=ArgumentDefaultsHelpFormatter,\n    )\n\n    # Common args\n    parser.add_argument(\n        \"-d\",\n        \"--dataset_name\",\n        default=\"SWE-bench/SWE-bench_Lite\",\n        type=str,\n        help=\"Name of dataset or path to JSON file.\",\n    )\n    parser.add_argument(\n        \"-s\", \"--split\", type=str, default=\"test\", help=\"Split of the dataset\"\n    )\n    parser.add_argument(\n        \"-i\",\n        \"--instance_ids\",\n        nargs=\"+\",\n        type=str,\n        help=\"Instance IDs to run (space separated)\",\n    )\n    parser.add_argument(\n        \"-p\",\n        \"--predictions_path\",\n        type=str,\n        help=\"Path to predictions file - if 'gold', uses gold predictions\",\n        required=True,\n    )\n\n    # Local execution args\n    parser.add_argument(\n        \"--max_workers\",\n        type=int,\n        default=4,\n        help=\"Maximum number of workers (should be <= 75%% of CPU cores)\",\n    )\n    parser.add_argument(\n        \"--open_file_limit\", type=int, default=4096, help=\"Open file limit\"\n    )\n    parser.add_argument(\n        \"-t\",\n        \"--timeout\",\n        type=int,\n        default=1_800,\n        help=\"Timeout (in seconds) for running tests for each instance\",\n    )\n    parser.add_argument(\n        \"--force_rebuild\",\n        type=str2bool,\n        default=False,\n        help=\"Force rebuild of all images\",\n    )\n    parser.add_argument(\n        \"--cache_level\",\n        type=str,\n        choices=[\"none\", \"base\", \"env\", \"instance\"],\n        help=\"Cache level - remove images above this level\",\n        default=\"env\",\n    )\n    # if clean is true then we remove all images that are above the cache level\n    # if clean is false, we only remove images above the cache level if they don't already exist\n    parser.add_argument(\n        \"--clean\", type=str2bool, default=False, help=\"Clean images above cache level\"\n    )\n    parser.add_argument(\n        \"-id\", \"--run_id\", type=str, required=True, help=\"Run ID - identifies the run\"\n    )\n    parser.add_argument(\n        \"-n\",\n        \"--namespace\",\n        type=optional_str,\n        default=\"swebench\",\n        help='Namespace for images. (use \"none\" to use no namespace)',\n    )\n    parser.add_argument(\n        \"--instance_image_tag\", type=str, default=\"latest\", help=\"Instance image tag\"\n    )\n    parser.add_argument(\n        \"--env_image_tag\", type=str, default=\"latest\", help=\"Environment image tag\"\n    )\n    parser.add_argument(\n        \"--rewrite_reports\",\n        type=str2bool,\n        default=False,\n        help=\"Doesn't run new instances, only writes reports for instances with existing test outputs\",\n    )\n    parser.add_argument(\n        \"--report_dir\", type=str, default=\".\", help=\"Directory to write reports to\"\n    )\n\n    # Modal execution args\n    parser.add_argument(\"--modal\", type=str2bool, default=False, help=\"Run on Modal\")\n\n    args = parser.parse_args()\n    main(**vars(args))",
      "original_issues": [
        {
          "file": "run_evaluation.py",
          "line": 307,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'instance'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "run_evaluation.py",
          "line": 459,
          "severity": "HIGH",
          "rule_id": "PY100",
          "message": "使用了未定义的名称 'k'。",
          "priority": "CRITICAL",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "run_evaluation.py",
          "line": 461,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "run_evaluation.py",
          "line": 505,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "run_evaluation.py",
          "line": 510,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "run_evaluation.py",
          "line": 542,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "run_evaluation.py",
          "line": 137,
          "severity": "LOW",
          "rule_id": "PY010",
          "message": "使用裸 except，建议捕获具体异常类型。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "run_evaluation.py",
          "line": 257,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "build_dataset.py",
      "path": "fixed_files\\build_dataset.py",
      "fixed_content": "#!/usr/bin/env python3\n\nimport argparse\nimport json\nimport logging\nimport os\nfrom typing import Optional\n\nfrom swebench.collect.utils import (\n    extract_patches,\n    extract_problem_statement_and_hints,\n    Repo,\n)\n\nlogging.basicConfig(\n    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n)\nlogger = logging.getLogger(__name__)\n\n\ndef create_instance(repo: Repo, pull: dict) -> dict:\n    \"\"\"\n    Create a single task instance from a pull request, where task instance is:\n\n    {\n        repo (str): owner/repo this task instance is from,\n        pull_number (int): number of PR this task instance is from,\n        base_commit (str): SHA of the base commit PR is based on,\n        patch (str): reference solution as .patch (apply to base commit),\n        test_patch (str): test suite as .patch (apply to base commit),\n    }\n    \"\"\"\n    patch, test_patch = extract_patches(pull, repo)\n    problem_statement, hints = extract_problem_statement_and_hints(pull, repo)\n    return {\n        \"repo\": repo.repo.full_name,\n        \"pull_number\": pull[\"number\"],\n        \"instance_id\": (repo.repo.full_name + \"-\" + str(pull[\"number\"])).replace(\n            \"/\", \"__\"\n        ),\n        \"issue_numbers\": pull[\"resolved_issues\"],\n        \"base_commit\": pull[\"base\"][\"sha\"],\n        \"patch\": patch,\n        \"test_patch\": test_patch,\n        \"problem_statement\": problem_statement,\n        \"hints_text\": hints,\n        \"created_at\": pull[\"created_at\"],\n    }\n\n\ndef is_valid_pull(pull: dict) -> bool:\n    \"\"\"\n    Check whether PR has an associated issue and is merged\n\n    Args:\n        pull (dict): pull request object\n    Returns:\n        bool: whether PR is valid\n    \"\"\"\n    if pull[\"merged_at\"] == None:\n        return False\n    if \"resolved_issues\" not in pull or len(pull[\"resolved_issues\"]) < 1:\n        return False\n    return True\n\n\ndef is_valid_instance(instance: dict) -> bool:\n    \"\"\"\n    Check whether task instance has all required fields for task instance creation\n\n    Args:\n        instance (dict): task instance object\n    Returns:\n        bool: whether task instance is valid\n    \"\"\"\n    if instance[\"patch\"] == None or instance[\"patch\"] == \"\":\n        return False\n    if instance[\"problem_statement\"] == None or instance[\"problem_statement\"] == \"\":\n        return False\n    return True\n\n\ndef has_test_patch(instance: dict) -> bool:\n    \"\"\"\n    Check whether task instance has a test suite\n\n    Args:\n        instance (dict): task instance object\n    Returns:\n        bool: whether task instance has a test suite\n    \"\"\"\n    if instance[\"test_patch\"] == None or instance[\"test_patch\"].strip() == \"\":\n        return False\n    return True\n\n\ndef main(pr_file: str, output: str, token: Optional[str] = None):\n    \"\"\"\n    Main thread for creating task instances from pull requests\n\n    Args:\n        pr_file (str): path to pull request JSONL file\n        output (str): output file name\n        token (str): GitHub token\n    \"\"\"\n    if token == None:\n        # Get GitHub token from environment variable if not provided\n        token = os.environ.get(\"GITHUB_TOKEN\")\n\n    def load_repo(repo_name):\n        # Return repo object for a given repo name\n        owner, repo = repo_name.split(\"/\")\n        return Repo(owner, repo, token=token)\n\n    repos = dict()\n    completed = 0\n    with_tests = 0\n    total_instances = 0\n    all_output = output + \".all\"\n    seen_prs = set()\n\n    # Continue where we left off if output file already exists\n    if os.path.exists(all_output):\n        with open(all_output) as f:\n            for line in f:\n                pr = json.loads(line)\n                if \"instance_id\" not in pr:\n                    pr[\"instance_id\"] = (\n                        pr[\"repo\"] + \"-\" + str(pr[\"pull_number\"])\n                    ).replace(\"/\", \"__\")\n                instance_id = pr[\"instance_id\"]\n                seen_prs.add(instance_id)\n                if is_valid_instance(pr):\n                    completed += 1\n                    if has_test_patch(pr):\n                        with_tests += 1\n    logger.info(\n        f\"Will skip {len(seen_prs)} pull requests that have already been inspected\"\n    )\n\n    # Write to .all file for all PRs\n    write_mode_all = \"w\" if not os.path.exists(all_output) else \"a\"\n    with open(all_output, write_mode_all) as all_output:\n        # Write to output file for PRs with test suites\n        write_mode = \"w\" if not os.path.exists(output) else \"a\"\n        with open(output, write_mode) as output:\n            for ix, line in enumerate(open(pr_file)):\n                total_instances += 1\n                pull = json.loads(line)\n                if ix % 100 == 0:\n                    logger.info(\n                        f\"[{pull['base']['repo']['full_name']}] (Up to {ix} checked) \"\n                        f\"{completed} valid, {with_tests} with tests.\"\n                    )\n                # Construct instance fields\n                instance_id = (\n                    pull[\"base\"][\"repo\"][\"full_name\"] + \"-\" + str(pull[\"number\"])\n                )\n                instance_id = instance_id.replace(\"/\", \"__\")\n                if instance_id in seen_prs:\n                    seen_prs -= {instance_id}\n                    continue\n                if not is_valid_pull(pull):\n                    # Throw out invalid PRs\n                    continue\n                # Create task instance\n                repo_name = pull[\"base\"][\"repo\"][\"full_name\"]\n                if repo_name not in repos:\n                    repos[repo_name] = load_repo(repo_name)\n                repo = repos[repo_name]\n                instance = create_instance(repo, pull)\n                if is_valid_instance(instance):\n                    # If valid, write to .all output file\n                    print(\n                        json.dumps(instance), end=\"\\n\", flush=True, file=all_output\n                    )  # write all instances to a separate file\n                    completed += 1\n                    if has_test_patch(instance):\n                        # If has test suite, write to output file\n                        print(json.dumps(instance), end=\"\\n\", flush=True, file=output)\n                        with_tests += 1\n    logger.info(\n        f\"[{', '.join(repos.keys())}] Total instances: {total_instances}, completed: {completed}, with tests: {with_tests}\"\n    )\n    logger.info(\n        f\"[{', '.join(repos.keys())}] Skipped {len(seen_prs)} pull requests that have already been inspected\"\n    )\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"pr_file\", type=str, help=\"Path to pull request JSONL file\")\n    parser.add_argument(\"output\", type=str, help=\"Output file name\")\n    parser.add_argument(\"--token\", type=str, help=\"GitHub token\")\n    args = parser.parse_args()\n    main(**vars(args))",
      "original_issues": [
        {
          "file": "build_dataset.py",
          "line": 60,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "build_dataset.py",
          "line": 76,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "build_dataset.py",
          "line": 78,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "build_dataset.py",
          "line": 92,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "build_dataset.py",
          "line": 106,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "print_pulls.py",
      "path": "fixed_files\\print_pulls.py",
      "fixed_content": "#!/usr/bin/env python3\n\n\"\"\"Given the `<owner/name>` of a GitHub repo, this script writes the raw information for all the repo's PRs to a single `.jsonl` file.\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nimport json\nimport logging\nimport os\n\nfrom datetime import datetime\nfrom fastcore.xtras import obj2dict\nfrom swebench.collect.utils import Repo\nfrom typing import Optional\n\nlogging.basicConfig(\n    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n)\nlogger = logging.getLogger(__name__)\n\n\ndef log_all_pulls(\n    repo: Repo,\n    output: str,\n    max_pulls: int = None,\n    cutoff_date: str = None,\n) -> None:\n    \"\"\"\n    Iterate over all pull requests in a repository and log them to a file\n\n    Args:\n        repo (Repo): repository object\n        output (str): output file name\n    \"\"\"\n    cutoff_date = (\n        datetime.strptime(cutoff_date, \"%Y%m%d\").strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n        if cutoff_date != None\n        else None\n    )\n\n    with open(output, \"w\") as file:\n        for i_pull, pull in enumerate(repo.get_all_pulls()):\n            setattr(pull, \"resolved_issues\", repo.extract_resolved_issues(pull))\n            print(json.dumps(obj2dict(pull)), end=\"\\n\", flush=True, file=file)\n            if max_pulls != None and i_pull >= max_pulls:\n                break\n            if cutoff_date != None and pull.created_at < cutoff_date:\n                break\n\n\ndef log_single_pull(\n    repo: Repo,\n    pull_number: int,\n    output: str,\n) -> None:\n    \"\"\"\n    Get a single pull request from a repository and log it to a file\n\n    Args:\n        repo (Repo): repository object\n        pull_number (int): pull request number\n        output (str): output file name\n    \"\"\"\n    logger.info(f\"Fetching PR #{pull_number} from {repo.owner}/{repo.name}\")\n\n    # Get the pull request using the GitHub API\n    pull = repo.call_api(\n        repo.api.pulls.get, owner=repo.owner, repo=repo.name, pull_number=pull_number\n    )\n\n    if pull == None:\n        logger.error(f\"PR #{pull_number} not found in {repo.owner}/{repo.name}\")\n        return\n\n    # Extract resolved issues\n    setattr(pull, \"resolved_issues\", repo.extract_resolved_issues(pull))\n\n    # Log the pull request to a file\n    with open(output, \"w\") as file:\n        print(json.dumps(obj2dict(pull)), end=\"\\n\", flush=True, file=file)\n\n    logger.info(f\"PR #{pull_number} saved to {output}\")\n    logger.info(f\"Resolved issues: {pull.resolved_issues}\")\n\n\ndef main(\n    repo_name: str,\n    output: str,\n    token: Optional[str] = None,\n    max_pulls: int = None,\n    cutoff_date: str = None,\n    pull_number: int = None,\n):\n    \"\"\"\n    Logic for logging all pull requests in a repository\n\n    Args:\n        repo_name (str): name of the repository\n        output (str): output file name\n        token (str, optional): GitHub token\n        max_pulls (int, optional): maximum number of pulls to log\n        cutoff_date (str, optional): cutoff date for PRs to consider\n        pull_number (int, optional): specific pull request number to log\n    \"\"\"\n    if token == None:\n        token = os.environ.get(\"GITHUB_TOKEN\")\n    owner, repo = repo_name.split(\"/\")\n    repo = Repo(owner, repo, token=token)\n\n    if pull_number != None:\n        log_single_pull(repo, pull_number, output)\n    else:\n        log_all_pulls(repo, output, max_pulls=max_pulls, cutoff_date=cutoff_date)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument(\"repo_name\", type=str, help=\"Name of the repository\")\n    parser.add_argument(\"output\", type=str, help=\"Output file name\")\n    parser.add_argument(\"--token\", type=str, help=\"GitHub token\")\n    parser.add_argument(\n        \"--max_pulls\", type=int, help=\"Maximum number of pulls to log\", default=None\n    )\n    parser.add_argument(\n        \"--cutoff_date\",\n        type=str,\n        help=\"Cutoff date for PRs to consider in format YYYYMMDD\",\n        default=None,\n    )\n    parser.add_argument(\n        \"--pull_number\",\n        type=int,\n        help=\"Specific pull request number to log\",\n        default=None,\n    )\n    args = parser.parse_args()\n    main(**vars(args))",
      "original_issues": [
        {
          "file": "print_pulls.py",
          "line": 38,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "print_pulls.py",
          "line": 46,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "print_pulls.py",
          "line": 48,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "print_pulls.py",
          "line": 72,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "print_pulls.py",
          "line": 106,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "print_pulls.py",
          "line": 111,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "prepare_images.py",
      "path": "fixed_files\\prepare_images.py",
      "fixed_content": "import docker\nimport resource\n\nfrom argparse import ArgumentParser\n\nfrom swebench.harness.constants import KEY_INSTANCE_ID\nfrom swebench.harness.docker_build import build_instance_images\nfrom swebench.harness.docker_utils import list_images\nfrom swebench.harness.test_spec.test_spec import make_test_spec\nfrom swebench.harness.utils import load_swebench_dataset, str2bool, optional_str\n\n\ndef filter_dataset_to_build(\n    dataset: list,\n    instance_ids: list | None,\n    client: docker.DockerClient,\n    force_rebuild: bool,\n    namespace: str = None,\n    tag: str = None,\n    env_image_tag: str = None,\n):\n    \"\"\"\n    Filter the dataset to only include instances that need to be built.\n\n    Args:\n        dataset (list): List of instances (usually all of SWE-bench dev/test split)\n        instance_ids (list): List of instance IDs to build.\n        client (docker.DockerClient): Docker client.\n        force_rebuild (bool): Whether to force rebuild all images.\n    \"\"\"\n    # Get existing images\n    existing_images = list_images(client)\n    data_to_build = []\n\n    if instance_ids == None:\n        instance_ids = [instance[KEY_INSTANCE_ID] for instance in dataset]\n\n    # Check if all instance IDs are in the dataset\n    not_in_dataset = set(instance_ids).difference(\n        set([instance[KEY_INSTANCE_ID] for instance in dataset])\n    )\n    if not_in_dataset:\n        raise ValueError(f\"Instance IDs not found in dataset: {not_in_dataset}\")\n\n    for instance in dataset:\n        if instance[KEY_INSTANCE_ID] not in instance_ids:\n            # Skip instances not in the list\n            continue\n\n        # Check if the instance needs to be built (based on force_rebuild flag and existing images)\n        spec = make_test_spec(\n            instance,\n            namespace=namespace,\n            instance_image_tag=tag,\n            env_image_tag=env_image_tag,\n        )\n        if force_rebuild:\n            data_to_build.append(instance)\n        elif spec.instance_image_key not in existing_images:\n            data_to_build.append(instance)\n\n    return data_to_build\n\n\ndef main(\n    dataset_name,\n    split,\n    instance_ids,\n    max_workers,\n    force_rebuild,\n    open_file_limit,\n    namespace,\n    tag,\n    env_image_tag,\n):\n    \"\"\"\n    Build Docker images for the specified instances.\n\n    Args:\n        instance_ids (list): List of instance IDs to build.\n        max_workers (int): Number of workers for parallel processing.\n        force_rebuild (bool): Whether to force rebuild all images.\n        open_file_limit (int): Open file limit.\n    \"\"\"\n    # Set open file limit\n    resource.setrlimit(resource.RLIMIT_NOFILE, (open_file_limit, open_file_limit))\n    client = docker.from_env()\n\n    # Filter out instances that were not specified\n    dataset = load_swebench_dataset(dataset_name, split)\n    dataset = filter_dataset_to_build(\n        dataset, instance_ids, client, force_rebuild, namespace, tag, env_image_tag\n    )\n\n    if len(dataset) == 0:\n        print(\"All images exist. Nothing left to build.\")\n        return 0\n\n    # Build images for remaining instances\n    successful, failed = build_instance_images(\n        client=client,\n        dataset=dataset,\n        force_rebuild=force_rebuild,\n        max_workers=max_workers,\n        namespace=namespace,\n        tag=tag,\n        env_image_tag=env_image_tag,\n    )\n    print(f\"Successfully built {len(successful)} images\")\n    print(f\"Failed to build {len(failed)} images\")\n\n\nif __name__ == \"__main__\":\n    parser = ArgumentParser()\n    parser.add_argument(\n        \"--dataset_name\",\n        type=str,\n        default=\"SWE-bench/SWE-bench_Lite\",\n        help=\"Name of the dataset to use\",\n    )\n    parser.add_argument(\"--split\", type=str, default=\"test\", help=\"Split to use\")\n    parser.add_argument(\n        \"--instance_ids\",\n        nargs=\"+\",\n        type=str,\n        help=\"Instance IDs to run (space separated)\",\n    )\n    parser.add_argument(\n        \"--max_workers\", type=int, default=4, help=\"Max workers for parallel processing\"\n    )\n    parser.add_argument(\n        \"--force_rebuild\", type=str2bool, default=False, help=\"Force rebuild images\"\n    )\n    parser.add_argument(\n        \"--open_file_limit\", type=int, default=8192, help=\"Open file limit\"\n    )\n    parser.add_argument(\n        \"--namespace\",\n        type=optional_str,\n        default=None,\n        help=\"Namespace to use for the images (default: None)\",\n    )\n    parser.add_argument(\n        \"--tag\", type=str, default=None, help=\"Tag to use for the images\"\n    )\n    parser.add_argument(\n        \"--env_image_tag\", type=str, default=None, help=\"Environment image tag to use\"\n    )\n    args = parser.parse_args()\n    main(**vars(args))",
      "original_issues": [
        {
          "file": "prepare_images.py",
          "line": 35,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "javascript.py",
      "path": "fixed_files\\javascript.py",
      "fixed_content": "import json\nimport re\n\nfrom pathlib import Path\nfrom swebench.harness.constants import (\n    END_TEST_OUTPUT,\n    START_TEST_OUTPUT,\n)\nfrom swebench.harness.test_spec.utils import make_eval_script_list_common\nfrom unidiff import PatchSet\n\n\n# MARK: Test Command Creation Functions\ndef get_test_cmds_calypso(instance) -> list:\n    test_paths = [x.path for x in PatchSet(instance[\"test_patch\"])]\n    test_cmds = []\n    for test_path in test_paths:\n        if re.search(r\"__snapshots__/(.*).js.snap$\", test_path):\n            # Jest snapshots are not run directly\n            test_path = \"/\".join(test_path.split(\"/\")[:-2])\n\n        # Determine which testing script to use\n        if any([test_path.startswith(x) for x in [\"client\", \"packages\"]]):\n            pkg = test_path.split(\"/\")[0]\n            if instance[\"version\"] == \"10.10.0\" or instance[\"version\"] == \"10.12.0\" or instance[\"version\"] == \"10.13.0\" or instance[\"version\"] == \"10.14.0\" or instance[\"version\"] == \"10.15.2\" or instance[\"version\"] == \"10.16.3\":\n                test_cmds.append(\n                    f\"./node_modules/.bin/jest --verbose -c=test/{pkg}/jest.config.js '{test_path}'\"\n                )\n            elif instance[\"version\"] == \"6.11.5\" or instance[\"version\"] == \"8.9.1\" or instance[\"version\"] == \"8.9.3\" or instance[\"version\"] == \"8.9.4\" or instance[\"version\"] == \"8.11.0\" or instance[\"version\"] == \"8.11.2\" or instance[\"version\"] == \"10.4.1\" or instance[\"version\"] == \"10.5.0\" or instance[\"version\"] == \"10.6.0\" or instance[\"version\"] == \"10.9.0\":\n                test_cmds.append(\n                    f\"./node_modules/.bin/jest --verbose -c=test/{pkg}/jest.config.json '{test_path}'\"\n                )\n            else:\n                test_cmds.append(f\"npm run test-{pkg} --verbose '{test_path}'\")\n        elif any([test_path.startswith(x) for x in [\"test/e2e\"]]):\n            test_cmds.extend(\n                [\n                    \"cd test/e2e\",\n                    f\"NODE_CONFIG_ENV=test npm run test {test_path}\",\n                    \"cd ../..\",\n                ]\n            )\n\n    return test_cmds\n\n\nMAP_REPO_TO_TEST_CMDS = {\n    \"Automattic/wp-calypso\": get_test_cmds_calypso,\n}\n\n\n# MARK: Utility Functions\ndef get_download_img_commands(instance) -> list:\n    cmds = []\n    image_assets = {}\n    if \"image_assets\" in instance:\n        if isinstance(instance[\"image_assets\"], str):\n            image_assets = json.loads(instance[\"image_assets\"])\n        else:\n            image_assets = instance[\"image_assets\"]\n    for i in image_assets.get(\"test_patch\", []):\n        folder = Path(i[\"path\"]).parent\n        cmds.append(f\"mkdir -p {folder}\")\n        cmds.append(f\"curl -o {i['path']} {i['url']}\")\n        cmds.append(f\"chmod 777 {i['path']}\")\n    return cmds\n\n\n# MARK: Script Creation Functions\ndef make_eval_script_list_js(\n    instance, specs, env_name, repo_directory, base_commit, test_patch\n) -> list:\n    \"\"\"\n    Applies the test patch and runs the tests.\n    \"\"\"\n    eval_commands = make_eval_script_list_common(\n        instance, specs, env_name, repo_directory, base_commit, test_patch\n    )\n    # Insert downloading right after reset command\n    eval_commands[4:4] = get_download_img_commands(instance)\n    if instance[\"repo\"] in MAP_REPO_TO_TEST_CMDS:\n        # Update test commands if they are custom commands\n        test_commands = MAP_REPO_TO_TEST_CMDS[instance[\"repo\"]](instance)\n        idx_start_test_out = eval_commands.index(f\": '{START_TEST_OUTPUT}'\")\n        idx_end_test_out = eval_commands.index(f\": '{END_TEST_OUTPUT}'\")\n        eval_commands[idx_start_test_out + 1 : idx_end_test_out] = test_commands\n    return eval_commands\n",
      "original_issues": [
        {
          "file": "javascript.py",
          "line": 27,
          "severity": "MEDIUM",
          "rule_id": "AST002",
          "message": "疑似使用 'is' 进行值比较，建议使用 '==' （is 仅用于 None/True/False）。",
          "priority": "HIGH",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "get_tasks_pipeline.py",
      "path": "fixed_files\\get_tasks_pipeline.py",
      "fixed_content": "#!/usr/bin/env python3\n\n\"\"\"Script to collect pull requests and convert them to candidate task instances\"\"\"\n\nimport argparse\nimport os\nimport traceback\n\nfrom dotenv import load_dotenv\nfrom multiprocessing import Pool\nfrom swebench.collect.build_dataset import main as build_dataset\nfrom swebench.collect.print_pulls import main as print_pulls\n\n\nload_dotenv()\n\n\ndef split_instances(input_list: list, n: int) -> list:\n    \"\"\"\n    Split a list into n approximately equal length sublists\n\n    Args:\n        input_list (list): List to split\n        n (int): Number of sublists to split into\n    Returns:\n        result (list): List of sublists\n    \"\"\"\n    avg_length = len(input_list) // n\n    remainder = len(input_list) % n\n    result, start = [], 0\n\n    for i in range(n):\n        length = avg_length + 1 if i < remainder else avg_length\n        sublist = input_list[start : start + length]\n        result.append(sublist)\n        start += length\n\n    return result\n\n\ndef construct_data_files(data: dict):\n    \"\"\"\n    Logic for combining multiple .all PR files into a single fine tuning dataset\n\n    Args:\n        data (dict): Dictionary containing the following keys:\n            repos (list): List of repositories to retrieve instruction data for\n            path_prs (str): Path to save PR data files to\n            path_tasks (str): Path to save task instance data files to\n            token (str): GitHub token to use for API requests\n    \"\"\"\n    repos, path_prs, path_tasks, max_pulls, cutoff_date, token = (\n        data[\"repos\"],\n        data[\"path_prs\"],\n        data[\"path_tasks\"],\n        data[\"max_pulls\"],\n        data[\"cutoff_date\"],\n        data[\"token\"],\n    )\n    for repo in repos:\n        repo = repo.strip(\",\").strip()\n        repo_name = repo.split(\"/\")[1]\n        try:\n            path_pr = os.path.join(path_prs, f\"{repo_name}-prs.jsonl\")\n            if cutoff_date:\n                path_pr = path_pr.replace(\".jsonl\", f\"-{cutoff_date}.jsonl\")\n            if not os.path.exists(path_pr):\n                print(f\"Pull request data for {repo} not found, creating...\")\n                print_pulls(\n                    repo, path_pr, token, max_pulls=max_pulls, cutoff_date=cutoff_date\n                )\n                print(f\"✅ Successfully saved PR data for {repo} to {path_pr}\")\n            else:\n                print(\n                    f\"📁 Pull request data for {repo} already exists at {path_pr}, skipping...\"\n                )\n\n            path_task = os.path.join(path_tasks, f\"{repo_name}-task-instances.jsonl\")\n            if not os.path.exists(path_task):\n                print(f\"Task instance data for {repo} not found, creating...\")\n                build_dataset(path_pr, path_task, token)\n                print(\n                    f\"✅ Successfully saved task instance data for {repo} to {path_task}\"\n                )\n            else:\n                print(\n                    f\"📁 Task instance data for {repo} already exists at {path_task}, skipping...\"\n                )\n        except Exception as e:\n            print(\"-\" * 80)\n            print(f\"Something went wrong for {repo}, skipping: {e}\")\n            print(\"Here is the full traceback:\")\n            traceback.print_exc()\n            print(\"-\" * 80)\n\n\ndef main(\n    repos: list,\n    path_prs: str,\n    path_tasks: str,\n    max_pulls: int = None,\n    cutoff_date: str = None,\n):\n    \"\"\"\n    Spawns multiple threads given multiple GitHub tokens for collecting fine tuning data\n\n    Args:\n        repos (list): List of repositories to retrieve instruction data for\n        path_prs (str): Path to save PR data files to\n        path_tasks (str): Path to save task instance data files to\n        cutoff_date (str): Cutoff date for PRs to consider in format YYYYMMDD\n    \"\"\"\n    path_prs, path_tasks = os.path.abspath(path_prs), os.path.abspath(path_tasks)\n    print(f\"Will save PR data to {path_prs}\")\n    print(f\"Will save task instance data to {path_tasks}\")\n    print(f\"Received following repos to create task instances for: {repos}\")\n\n    tokens = os.getenv(\"GITHUB_TOKENS\")\n    if not tokens:\n        raise Exception(\n            \"Missing GITHUB_TOKENS, consider rerunning with GITHUB_TOKENS=$(gh auth token)\"\n        )\n    tokens = tokens.split(\",\")\n    data_task_lists = split_instances(repos, len(tokens))\n\n    data_pooled = [\n        {\n            \"repos\": repos,\n            \"path_prs\": path_prs,\n            \"path_tasks\": path_tasks,\n            \"max_pulls\": max_pulls,\n            \"cutoff_date\": cutoff_date,\n            \"token\": token,\n        }\n        for repos, token in zip(data_task_lists, tokens)\n    ]\n\n    with Pool(len(tokens)) as p:\n        p.map(construct_data_files, data_pooled)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument(\n        \"--repos\",\n        nargs=\"+\",\n        help=\"List of repositories (e.g., `sqlfluff/sqlfluff`) to create task instances for\",\n    )\n    parser.add_argument(\n        \"--path_prs\", type=str, help=\"Path to folder to save PR data files to\"\n    )\n    parser.add_argument(\n        \"--path_tasks\",\n        type=str,\n        help=\"Path to folder to save task instance data files to\",\n    )\n    parser.add_argument(\n        \"--max_pulls\", type=int, help=\"Maximum number of pulls to log\", default=None\n    )\n    parser.add_argument(\n        \"--cutoff_date\",\n        type=str,\n        help=\"Cutoff date for PRs to consider in format YYYYMMDD\",\n        default=None,\n    )\n    args = parser.parse_args()\n    main(**vars(args))\n",
      "original_issues": [
        {
          "file": "get_tasks_pipeline.py",
          "line": 89,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "remove_containers.py",
      "path": "fixed_files\\remove_containers.py",
      "fixed_content": "import docker\nimport json\n\nfrom argparse import ArgumentParser\n\n\"\"\"\nScript for removing containers associated with specified instance IDs.\n\"\"\"\n\n\ndef main(instance_ids, predictions_path):\n    all_ids = set()\n    if predictions_path:\n        with open(predictions_path, \"r\") as f:\n            predictions = json.loads(f.read())\n            for pred in predictions:\n                all_ids.add(pred[\"instance_id\"])\n\n    if instance_ids:\n        all_ids |= set(instance_ids)\n\n    if not all_ids:\n        print(\"No instance IDs provided, exiting.\")\n        return\n\n    for instance_id in all_ids:\n        try:\n            client = docker.from_env()\n            container = client.containers.get(f\"sweb.eval.{instance_id}\")\n            container.stop()\n            container.remove()\n            print(f\"Removed container {instance_id}\")\n        except docker.errors.NotFound:\n            print(f\"Container {instance_id} not found, skipping.\")\n        except docker.errors.APIError as e:\n            print(f\"Error removing container {instance_id}: {e}\")\n            continue\n\n\nif __name__ == \"__main__\":\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument(\n        \"--instance_ids\",\n        help=\"Instance IDs to remove containers for\",\n    )\n    parser.add_argument(\n        \"--predictions_path\",\n        help=\"Path to predictions file\",\n    )\n    args = parser.parse_args()\n    instance_ids = (\n        [i.strip() for i in args.instance_ids.split(\",\")] if args.instance_ids else []\n    )\n    main(\n        instance_ids=instance_ids,\n        predictions_path=args.predictions_path,\n    )\n",
      "original_issues": [
        {
          "file": "remove_containers.py",
          "line": 35,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "run_evaluation_modal.py",
      "path": "fixed_files\\run_evaluation_modal.py",
      "fixed_content": "# This file contains logic for running evaluations on Modal: <https://modal.com/>.\n\nfrom __future__ import annotations\n\nimport asyncio\nimport json\nimport modal\nimport modal.container_process\nimport modal.io_streams\nimport tenacity\nimport time\nimport traceback\n\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom swebench.harness.docker_build import setup_logger\nfrom swebench.harness.reporting import make_run_report\nfrom swebench.harness.utils import EvaluationError\nfrom typing import cast\n\nSANDBOX_ENTRYPOINT = \"run_evaluation_modal_entrypoint\"\nLOCAL_SANDBOX_ENTRYPOINT_PATH = (\n    Path(__file__).parent / f\"{SANDBOX_ENTRYPOINT}.py\"\n).resolve()\nREMOTE_SANDBOX_ENTRYPOINT_PATH = f\"/root/{SANDBOX_ENTRYPOINT}.py\"\n\napp = modal.App(\"swebench-evaluation\")\n\nswebench_image = modal.Image.debian_slim().pip_install(\"swebench\", \"tenacity\")\n\nfrom swebench.harness.constants import (\n    APPLY_PATCH_FAIL,\n    APPLY_PATCH_PASS,\n    RUN_EVALUATION_LOG_DIR,\n)\nfrom swebench.harness.grading import get_eval_report\nfrom swebench.harness.test_spec.test_spec import make_test_spec, TestSpec\n\n\n@dataclass\nclass TestOutput:\n    instance_id: str\n    test_output: str\n    report_json_str: str\n    run_instance_log: str\n    patch_diff: str\n    log_dir: Path\n    errored: bool\n\n\nclass ModalSandboxRuntime:\n    \"\"\"\n    Runtime for running instances in a Modal Sandbox.\n    \"\"\"\n\n    def __init__(\n        self, test_spec: TestSpec, timeout: int | None = None, verbose: bool = True\n    ):\n        self.test_spec = test_spec\n        self.image = ModalSandboxRuntime.get_instance_image(test_spec)\n        self.sandbox = self._get_sandbox(timeout)\n        self.verbose = verbose\n        self._stream_tasks = []\n\n        # Hack for pylint\n        self.write_file(\"/sys/fs/cgroup/cpu/cpu.shares\", \"2048\")\n\n    @tenacity.retry(\n        stop=tenacity.stop_after_attempt(7),\n        wait=tenacity.wait_exponential(multiplier=1, min=4, max=10),\n    )\n    def _get_sandbox(self, timeout: int | None = None):\n        # Sometimes network flakiness causes the image build to fail,\n        # so we retry a few times.\n        if timeout is None:\n            # Default 30 minutes\n            timeout = 60 * 30\n\n        return modal.Sandbox.create(\n            image=self.image.add_local_file(\n                REMOTE_SANDBOX_ENTRYPOINT_PATH,\n                REMOTE_SANDBOX_ENTRYPOINT_PATH,\n            ),\n            timeout=timeout,\n            cpu=4,\n        )\n\n    async def _read_stream(\n        self, stream: modal.io_streams.StreamReader, output_list: list[str]\n    ):\n        try:\n            async for line in stream:\n                output_list.append(line)\n                if self.verbose:\n                    print(line)\n        except asyncio.CancelledError:\n            pass\n        except Exception as e:\n            print(f\"Error reading stream: {e}\")\n\n    async def _read_output(\n        self,\n        p: modal.container_process.ContainerProcess,\n        stdout: list[str],\n        stderr: list[str],\n    ):\n        self._stream_tasks = [\n            asyncio.create_task(self._read_stream(p.stdout, stdout)),\n            asyncio.create_task(self._read_stream(p.stderr, stderr)),\n        ]\n        try:\n            await asyncio.gather(*self._stream_tasks)\n        except asyncio.CancelledError:\n            pass\n\n    def write_file(self, file_path: str, content: str):\n        self.sandbox.open(file_path, \"w\").write(content)\n\n    def exec(self, command: str) -> tuple[str, int]:\n        \"\"\"\n        Execute a command in the sandbox.\n\n        Returns:\n            tuple[str, int]: Sandbox output and return code.\n        \"\"\"\n        p = self.sandbox.exec(\"python\", \"-m\", SANDBOX_ENTRYPOINT, command)\n        stdout = []\n        stderr = []\n        try:\n            # We separate stdout/stderr because some tests rely on them being separate.\n            # We still read stdout/stderr simultaneously to continuously\n            # flush both streams and avoid blocking.\n            asyncio.run(self._read_output(p, stdout, stderr))\n        except Exception as e:\n            print(f\"Error during command execution: {e}\")\n        p.wait()\n        return \"\".join(stdout + stderr), p.returncode\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if self._stream_tasks:\n            try:\n                # Forcefully kill remaining streams\n                for task in self._stream_tasks:\n                    if not task.done():\n                        task.cancel()\n                        try:\n                            asyncio.wait_for(task, timeout=0.1)\n                        except asyncio.TimeoutError:\n                            pass\n                        except Exception:\n                            pass\n\n                self.sandbox.terminate()\n            except Exception:\n                pass\n            finally:\n                self._stream_tasks = []\n\n    @staticmethod\n    def get_instance_image(test_spec: TestSpec) -> modal.Image:\n        env_script = test_spec.setup_env_script\n        # add trusted host flag for Modal's PyPI mirror\n        env_script = env_script.replace(\n            \"conda activate testbed && python -m pip install -r $HOME/requirements.txt\",\n            \"conda activate testbed && python -m pip install --trusted-host pypi-mirror.modal.local -r $HOME/requirements.txt\",\n        )\n        repo_script = test_spec.install_repo_script\n\n        remote_env_script_path = \"/root/setup_env.sh\"\n        remote_repo_script_path = \"/root/setup_repo.sh\"\n\n        Path(remote_env_script_path).write_text(env_script)\n        Path(remote_repo_script_path).write_text(repo_script)\n\n        # Modal automatically caches images\n        # https://modal.com/docs/guide/custom-container#image-caching-and-rebuilds\n        return (\n            modal.Image.from_registry(\"ubuntu:22.04\", add_python=\"3.11\")\n            .run_commands(\"apt update\")\n            .env({\"DEBIAN_FRONTEND\": \"noninteractive\", \"TZ\": \"Etc/UTC\"})\n            .apt_install(\n                \"wget\",\n                \"git\",\n                \"build-essential\",\n                \"libffi-dev\",\n                \"libtiff-dev\",\n                \"jq\",\n                \"curl\",\n                \"locales\",\n                \"locales-all\",\n                \"tzdata\",\n            )\n            .run_commands(\n                \"wget 'https://repo.anaconda.com/miniconda/Miniconda3-py311_23.11.0-2-Linux-x86_64.sh' -O miniconda.sh\",\n                \"bash miniconda.sh -b -p /opt/miniconda3\",\n                \"echo 'export PATH=/opt/miniconda3/bin:$PATH' >> ~/.bashrc\",\n                \"/opt/miniconda3/bin/conda init --all\",\n                \"/opt/miniconda3/bin/conda config --append channels conda-forge\",\n                \"adduser --disabled-password --gecos 'dog' nonroot\",\n            )\n            .add_local_file(\n                Path(remote_env_script_path), remote_env_script_path, copy=True\n            )\n            .add_local_file(\n                Path(remote_repo_script_path), remote_repo_script_path, copy=True\n            )\n            .run_commands(\n                f\"chmod +x {remote_env_script_path}\",\n                f\"/bin/bash -c 'source ~/.bashrc && {remote_env_script_path}'\",\n                \"echo 'source /opt/miniconda3/etc/profile.d/conda.sh && conda activate testbed' >> /root/.bashrc\",\n                f\"/bin/bash {remote_repo_script_path}\",\n            )\n            .workdir(\"/testbed/\")\n        )\n\n\ndef get_log_dir(pred: dict, run_id: str, instance_id: str) -> Path:\n    model_name_or_path = cast(\n        str, pred.get(\"model_name_or_path\", \"None\").replace(\"/\", \"__\")\n    )\n    return RUN_EVALUATION_LOG_DIR / run_id / model_name_or_path / instance_id\n\n\n@app.function(\n    image=swebench_image.add_local_file(\n        LOCAL_SANDBOX_ENTRYPOINT_PATH,\n        REMOTE_SANDBOX_ENTRYPOINT_PATH,\n    ),\n    timeout=120\n    * 60,  # Much larger than default timeout to account for image build time\n    include_source=True,\n)\ndef run_instance_modal(\n    test_spec: TestSpec,\n    pred: dict,\n    run_id: str,\n    timeout: int | None = None,\n) -> TestOutput:\n    \"\"\"\n    Run a single instance with the given prediction.\n\n    Args:\n        test_spec (TestSpec): TestSpec instance\n        pred (dict): Prediction w/ model_name_or_path, model_patch, instance_id\n        run_id (str): Run ID\n        timeout (int): Timeout for running tests\n    \"\"\"\n    instance_id = test_spec.instance_id\n    log_dir = get_log_dir(pred, run_id, instance_id)\n    log_dir.mkdir(parents=True, exist_ok=True)\n\n    log_file = log_dir / \"run_instance.log\"\n\n    logger = setup_logger(instance_id, log_file, add_stdout=True)\n\n    try:\n        runner = ModalSandboxRuntime(test_spec, timeout)\n    except Exception as e:\n        print(f\"Error creating sandbox: {e}\")\n        raise EvaluationError(\n            instance_id,\n            f\"Error creating sandbox: {e}\",\n            logger,\n        ) from e\n\n    patch_diff = pred.get(\"model_patch\", \"\")\n\n    try:\n        patch_file = \"/tmp/patch.diff\"\n        runner.write_file(patch_file, patch_diff)\n\n        apply_patch_output, returncode = runner.exec(\n            \"cd /testbed && git apply -v /tmp/patch.diff\",\n        )\n\n        if returncode != 0:\n            logger.info(\"Failed to apply patch to container, trying again...\")\n\n            apply_patch_output, returncode = runner.exec(\n                \"cd /testbed && patch --batch --fuzz=5 -p1 -i /tmp/patch.diff\",\n            )\n\n            if returncode != 0:\n                logger.info(f\"{APPLY_PATCH_FAIL}:\\n{apply_patch_output}\")\n                raise EvaluationError(\n                    instance_id,\n                    f\"{APPLY_PATCH_FAIL}:\\n{apply_patch_output}\",\n                    logger,\n                )\n            else:\n                logger.info(f\"{APPLY_PATCH_PASS}:\\n{apply_patch_output}\")\n        else:\n            logger.info(f\"{APPLY_PATCH_PASS}:\\n{apply_patch_output}\")\n\n        # Get git diff before running eval script\n        git_diff_output_before, returncode = runner.exec(\n            \"cd /testbed && git diff\",\n        )\n        logger.info(f\"Git diff before:\\n{git_diff_output_before}\")\n\n        eval_file = \"/root/eval.sh\"\n        eval_script = test_spec.eval_script\n        # django hack\n        eval_script = eval_script.replace(\"locale-gen\", \"locale-gen en_US.UTF-8\")\n        runner.write_file(eval_file, eval_script)\n\n        start_time = time.time()\n\n        run_command = \"cd /testbed\"\n        # pylint hack\n        if \"pylint\" in test_spec.instance_id:\n            run_command += \" && PYTHONPATH=\"\n        # increase recursion limit for testing\n        run_command += \" && python3 -c 'import sys; sys.setrecursionlimit(10000)'\"\n        # run eval script\n        run_command += \" && /bin/bash /root/eval.sh\"\n        test_output, returncode = runner.exec(run_command)\n\n        total_runtime = time.time() - start_time\n\n        test_output_path = log_dir / \"test_output.txt\"\n        logger.info(f\"Test runtime: {total_runtime:_.2f} seconds\")\n        with open(test_output_path, \"w\") as f:\n            f.write(test_output)\n            logger.info(f\"Test output for {instance_id} written to {test_output_path}\")\n            print(f\"Test output for {instance_id} written to {test_output_path}\")\n\n        # Get git diff after running eval script\n        git_diff_output_after, returncode = runner.exec(\"cd /testbed && git diff\")\n\n        # Check if git diff changed after running eval script\n        logger.info(f\"Git diff after:\\n{git_diff_output_after}\")\n        if git_diff_output_after != git_diff_output_before:\n            logger.info(\"Git diff changed after running eval script\")\n\n        # Get report from test output\n        logger.info(f\"Grading answer for {instance_id}...\")\n        report = get_eval_report(\n            test_spec=test_spec,\n            prediction=pred,\n            test_log_path=test_output_path,\n            include_tests_status=True,\n        )\n        logger.info(\n            f\"report: {report}\\n\"\n            f\"Result for {instance_id}: resolved: {report[instance_id]['resolved']}\"\n        )\n\n        return TestOutput(\n            instance_id=instance_id,\n            test_output=test_output,\n            report_json_str=json.dumps(report, indent=4),\n            run_instance_log=log_file.read_text(),\n            patch_diff=patch_diff,\n            log_dir=log_dir,\n            errored=False,\n        )\n    except modal.exception.SandboxTimeoutError as e:\n        raise EvaluationError(\n            instance_id,\n            f\"Test timed out after {timeout} seconds.\",\n            logger,\n        ) from e\n    except EvaluationError:\n        error_msg = traceback.format_exc()\n        logger.info(error_msg)\n        return TestOutput(\n            instance_id=instance_id,\n            test_output=\"\",\n            report_json_str=\"\",\n            run_instance_log=log_file.read_text(),\n            patch_diff=patch_diff,\n            log_dir=log_dir,\n            errored=True,\n        )\n    except Exception as e:\n        error_msg = (\n            f\"Error in evaluating model for {instance_id}: {e}\\n\"\n            f\"{traceback.format_exc()}\\n\"\n            f\"Check ({logger.log_file}) for more information.\"\n        )\n        logger.error(error_msg)\n        return TestOutput(\n            instance_id=instance_id,\n            test_output=\"\",\n            report_json_str=\"\",\n            run_instance_log=log_file.read_text(),\n            patch_diff=patch_diff,\n            log_dir=log_dir,\n            errored=True,\n        )\n\n\ndef run_instances_modal(\n    predictions: dict,\n    instances: list,\n    full_dataset: list,\n    run_id: str,\n    timeout: int,\n):\n    \"\"\"\n    Run all instances for the given predictions on Modal.\n\n    Args:\n        predictions (dict): Predictions dict generated by the model\n        instances (list): List of instances\n        run_id (str): Run ID\n        timeout (int): Timeout for running tests\n    \"\"\"\n    test_specs = list(map(make_test_spec, instances))\n\n    with modal.enable_output():\n        with app.run():\n            run_test_specs = []\n\n            # Check for instances that have already been run\n            for test_spec in test_specs:\n                log_dir = get_log_dir(\n                    predictions[test_spec.instance_id], run_id, test_spec.instance_id\n                )\n                if log_dir.exists():\n                    continue\n                run_test_specs.append(test_spec)\n\n            if run_test_specs:\n                # Run instances that haven't been run yet\n                results = run_instance_modal.starmap(\n                    [\n                        (\n                            test_spec,\n                            predictions[test_spec.instance_id],\n                            run_id,\n                            timeout,\n                        )\n                        for test_spec in run_test_specs\n                    ],\n                    return_exceptions=True,\n                )\n\n                for result in results:\n                    if not isinstance(result, TestOutput):\n                        print(f\"Result failed with error: {result}\")\n                        continue\n\n                    # Save logs locally\n                    log_dir = result.log_dir\n                    log_dir.mkdir(parents=True, exist_ok=True)\n                    with open(log_dir / \"run_instance.log\", \"w\") as f:\n                        f.write(result.run_instance_log)\n                    with open(log_dir / \"test_output.txt\", \"w\") as f:\n                        f.write(result.test_output)\n                    with open(log_dir / \"patch.diff\", \"w\") as f:\n                        f.write(result.patch_diff)\n                    with open(log_dir / \"report.json\", \"w\") as f:\n                        try:\n                            report_json = json.loads(result.report_json_str)\n                            json.dump(report_json, f, indent=4)\n                        except Exception:\n                            # This happens if the test fails with any exception\n                            print(f\"{result.instance_id}: no report.json\")\n\n            make_run_report(predictions, full_dataset, run_id)\n",
      "original_issues": [
        {
          "file": "run_evaluation_modal.py",
          "line": 98,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "run_evaluation_modal.py",
          "line": 134,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "run_evaluation_modal.py",
          "line": 150,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "run_evaluation_modal.py",
          "line": 154,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "run_evaluation_modal.py",
          "line": 258,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "run_evaluation_modal.py",
          "line": 376,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "run_evaluation_modal.py",
          "line": 458,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "run_api.py",
      "path": "fixed_files\\run_api.py",
      "fixed_content": "#!/usr/bin/env python3\n\n\"\"\"This python script is designed to run inference on a dataset using either the OpenAI or Anthropic API, depending on the model specified.\nIt sorts instances by length and continually writes the outputs to a specified file, so that the script can be stopped and restarted without losing progress.\n\"\"\"\n\nimport json\nimport os\nimport time\nimport dotenv\nimport traceback\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nimport numpy as np\nimport tiktoken\nimport openai\nfrom anthropic import HUMAN_PROMPT, AI_PROMPT, Anthropic\nfrom tenacity import (\n    retry,\n    stop_after_attempt,\n    wait_random_exponential,\n)\nfrom datasets import load_dataset, load_from_disk\nfrom swebench.inference.make_datasets.utils import extract_diff\nfrom argparse import ArgumentParser\nimport logging\n\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\nlogger = logging.getLogger(__name__)\ndotenv.load_dotenv()\n\nMODEL_LIMITS = {\n    \"claude-instant-1\": 100_000,\n    \"claude-2\": 100_000,\n    \"claude-3-opus-20240229\": 200_000,\n    \"claude-3-sonnet-20240229\": 200_000,\n    \"claude-3-haiku-20240307\": 200_000,\n    \"gpt-3.5-turbo-16k-0613\": 16_385,\n    \"gpt-3.5-turbo-0613\": 4_097,\n    \"gpt-3.5-turbo-1106\": 16_385,\n    \"gpt-4-32k-0613\": 32_768,\n    \"gpt-4-0613\": 8_192,\n    \"gpt-4-1106-preview\": 128_000,\n    \"gpt-4-0125-preview\": 128_000,\n}\n\n# The cost per token for each model input.\nMODEL_COST_PER_INPUT = {\n    \"claude-instant-1\": 0.00000163,\n    \"claude-2\": 0.00001102,\n    \"claude-3-opus-20240229\": 0.000015,\n    \"claude-3-sonnet-20240229\": 0.000003,\n    \"claude-3-haiku-20240307\": 0.00000025,\n    \"gpt-3.5-turbo-16k-0613\": 0.0000015,\n    \"gpt-3.5-turbo-0613\": 0.0000015,\n    \"gpt-3.5-turbo-1106\": 0.000001,\n    \"gpt-35-turbo-0613\": 0.0000015,\n    \"gpt-35-turbo\": 0.0000015,  # probably still 0613\n    \"gpt-4-0613\": 0.00003,\n    \"gpt-4-32k-0613\": 0.00006,\n    \"gpt-4-32k\": 0.00006,\n    \"gpt-4-1106-preview\": 0.00001,\n    \"gpt-4-0125-preview\": 0.00001,\n}\n\n# The cost per token for each model output.\nMODEL_COST_PER_OUTPUT = {\n    \"claude-instant-1\": 0.00000551,\n    \"claude-2\": 0.00003268,\n    \"claude-3-opus-20240229\": 0.000075,\n    \"claude-3-sonnet-20240229\": 0.000015,\n    \"claude-3-haiku-20240307\": 0.00000125,\n    \"gpt-3.5-turbo-16k-0613\": 0.000002,\n    \"gpt-3.5-turbo-16k\": 0.000002,\n    \"gpt-3.5-turbo-1106\": 0.000002,\n    \"gpt-35-turbo-0613\": 0.000002,\n    \"gpt-35-turbo\": 0.000002,\n    \"gpt-4-0613\": 0.00006,\n    \"gpt-4-32k-0613\": 0.00012,\n    \"gpt-4-32k\": 0.00012,\n    \"gpt-4-1106-preview\": 0.00003,\n    \"gpt-4-0125-preview\": 0.00003,\n}\n\n# used for azure\nENGINES = {\n    \"gpt-3.5-turbo-16k-0613\": \"gpt-35-turbo-16k\",\n    \"gpt-4-0613\": \"gpt-4\",\n    \"gpt-4-32k-0613\": \"gpt-4-32k\",\n}\n\n\ndef calc_cost(model_name, input_tokens, output_tokens):\n    \"\"\"\n    Calculates the cost of a response from the openai API.\n\n    Args:\n    response (openai.ChatCompletion): The response from the API.\n\n    Returns:\n    float: The cost of the response.\n    \"\"\"\n    cost = (\n        MODEL_COST_PER_INPUT[model_name] * input_tokens\n        + MODEL_COST_PER_OUTPUT[model_name] * output_tokens\n    )\n    logger.info(\n        f\"input_tokens={input_tokens}, output_tokens={output_tokens}, cost={cost:.2f}\"\n    )\n    return cost\n\n\n@retry(wait=wait_random_exponential(min=30, max=600), stop=stop_after_attempt(3))\ndef call_chat(model_name_or_path, inputs, use_azure, temperature, top_p, **model_args):\n    \"\"\"\n    Calls the openai API to generate completions for the given inputs.\n\n    Args:\n    model_name_or_path (str): The name or path of the model to use.\n    inputs (str): The inputs to generate completions for.\n    use_azure (bool): Whether to use the azure API.\n    temperature (float): The temperature to use.\n    top_p (float): The top_p to use.\n    **model_args (dict): A dictionary of model arguments.\n    \"\"\"\n    system_messages = inputs.split(\"\\n\", 1)[0]\n    user_message = inputs.split(\"\\n\", 1)[1]\n    try:\n        if use_azure:\n            response = openai.chat.completions.create(\n                engine=ENGINES[model_name_or_path] if use_azure else None,\n                messages=[\n                    {\"role\": \"system\", \"content\": system_messages},\n                    {\"role\": \"user\", \"content\": user_message},\n                ],\n                temperature=temperature,\n                top_p=top_p,\n                **model_args,\n            )\n        else:\n            response = openai.chat.completions.create(\n                model=model_name_or_path,\n                messages=[\n                    {\"role\": \"system\", \"content\": system_messages},\n                    {\"role\": \"user\", \"content\": user_message},\n                ],\n                temperature=temperature,\n                top_p=top_p,\n                **model_args,\n            )\n        input_tokens = response.usage.prompt_tokens\n        output_tokens = response.usage.completion_tokens\n        cost = calc_cost(response.model, input_tokens, output_tokens)\n        return response, cost\n    except openai.BadRequestError as e:\n        if e.code == \"context_length_exceeded\":\n            print(\"Context length exceeded\")\n            return None\n        raise e\n\n\ndef gpt_tokenize(string: str, encoding) -> int:\n    \"\"\"Returns the number of tokens in a text string.\"\"\"\n    num_tokens = len(encoding.encode(string))\n    return num_tokens\n\n\ndef claude_tokenize(string: str, api) -> int:\n    \"\"\"Returns the number of tokens in a text string.\"\"\"\n    num_tokens = api.count_tokens(string)\n    return num_tokens\n\n\ndef openai_inference(\n    test_dataset,\n    model_name_or_path,\n    output_file,\n    model_args,\n    existing_ids,\n    max_cost,\n):\n    \"\"\"\n    Runs inference on a dataset using the openai API.\n\n    Args:\n    test_dataset (datasets.Dataset): The dataset to run inference on.\n    model_name_or_path (str): The name or path of the model to use.\n    output_file (str): The path to the output file.\n    model_args (dict): A dictionary of model arguments.\n    existing_ids (set): A set of ids that have already been processed.\n    max_cost (float): The maximum cost to spend on inference.\n    \"\"\"\n    encoding = tiktoken.encoding_for_model(model_name_or_path)\n    test_dataset = test_dataset.filter(\n        lambda x: gpt_tokenize(x[\"text\"], encoding) <= MODEL_LIMITS[model_name_or_path],\n        desc=\"Filtering\",\n        load_from_cache_file=False,\n    )\n    openai_key = os.environ.get(\"OPENAI_API_KEY\", None)\n    if openai_key is None:\n        raise ValueError(\n            \"Must provide an api key. Expected in OPENAI_API_KEY environment variable.\"\n        )\n    openai.api_key = openai_key\n    print(f\"Using OpenAI key {'*' * max(0, len(openai_key) - 5) + openai_key[-5:]}\")\n    use_azure = model_args.pop(\"use_azure\", False)\n    if use_azure:\n        openai.api_type = \"azure\"\n        openai.api_base = \"https://pnlpopenai3.openai.azure.com/\"\n        openai.api_version = \"2023-05-15\"\n    temperature = model_args.pop(\"temperature\", 0.2)\n    top_p = model_args.pop(\"top_p\", 0.95 if temperature > 0 else 1)\n    print(f\"Using temperature={temperature}, top_p={top_p}\")\n    basic_args = {\n        \"model_name_or_path\": model_name_or_path,\n    }\n    total_cost = 0\n    print(f\"Filtered to {len(test_dataset)} instances\")\n    with open(output_file, \"a+\") as f:\n        for datum in tqdm(test_dataset, desc=f\"Inference for {model_name_or_path}\"):\n            instance_id = datum[\"instance_id\"]\n            if instance_id in existing_ids:\n                continue\n            output_dict = {\"instance_id\": instance_id}\n            output_dict.update(basic_args)\n            output_dict[\"text\"] = f\"{datum['text']}\\n\\n\"\n            response, cost = call_chat(\n                output_dict[\"model_name_or_path\"],\n                output_dict[\"text\"],\n                use_azure,\n                temperature,\n                top_p,\n            )\n            completion = response.choices[0].message.content\n            total_cost += cost\n            print(f\"Total Cost: {total_cost:.2f}\")\n            output_dict[\"full_output\"] = completion\n            output_dict[\"model_patch\"] = extract_diff(completion)\n            print(json.dumps(output_dict), file=f, flush=True)\n            if max_cost is not None and total_cost >= max_cost:\n                print(f\"Reached max cost {max_cost}, exiting\")\n                break\n\n\n@retry(wait=wait_random_exponential(min=60, max=600), stop=stop_after_attempt(6))\ndef call_anthropic(\n    inputs, anthropic, model_name_or_path, temperature, top_p, **model_args\n):\n    \"\"\"\n    Calls the anthropic API to generate completions for the given inputs.\n\n    Args:\n    inputs (str): The inputs to generate completions for.\n    anthropic (Anthropic): The anthropic API object.\n    model_name_or_path (str): The name or path of the model to use.\n    temperature (float): The temperature to use.\n    top_p (float): The top_p to use.\n    model_args (dict): A dictionary of model arguments.\n    \"\"\"\n    try:\n        completion = anthropic.completions.create(\n            model=model_name_or_path,\n            max_tokens_to_sample=6000,\n            prompt=inputs,\n            temperature=temperature,\n            top_p=top_p,\n            **model_args,\n        )\n        response = completion.completion\n        input_tokens = anthropic.count_tokens(inputs)\n        output_tokens = anthropic.count_tokens(response)\n        cost = calc_cost(model_name_or_path, input_tokens, output_tokens)\n        return completion, cost\n    except Exception as e:\n        logger.error(e)\n        logger.error(f\"Inputs: {inputs}\")\n        traceback.print_exc()\n        time.sleep(20)\n        return None\n\n\n@retry(wait=wait_random_exponential(min=60, max=600), stop=stop_after_attempt(6))\ndef call_anthropic_v2(\n    inputs, anthropic, model_name_or_path, temperature, top_p, **model_args\n):\n    \"\"\"\n    Calls the anthropic API to generate completions for the given inputs.\n\n    Args:\n    inputs list(str): The inputs to generate completions for.\n    anthropic (Anthropic): The anthropic API object.\n    model_name_or_path (str): The name or path of the model to use.\n    temperature (float): The temperature to use.\n    top_p (float): The top_p to use.\n    model_args (dict): A dictionary of model arguments.\n    \"\"\"\n    system_messages = inputs.split(\"\\n\", 1)[0]\n    user_message = inputs.split(\"\\n\", 1)[1]\n    try:\n        messages = [\n            {\"role\": \"user\", \"content\": user_message},\n        ]\n        response = anthropic.messages.create(\n            messages=messages,\n            max_tokens=4096,\n            model=model_name_or_path,\n            temperature=temperature,\n            top_p=top_p,\n            system=system_messages,\n        )\n        input_tokens = response.usage.input_tokens\n        output_tokens = response.usage.output_tokens\n        cost = calc_cost(response.model, input_tokens, output_tokens)\n        return response, cost\n    except Exception as e:\n        logger.error(e)\n        logger.error(f\"Inputs: {inputs}\")\n        traceback.print_exc()\n        time.sleep(20)\n        return None\n\n\ndef anthropic_inference(\n    test_dataset,\n    model_name_or_path,\n    output_file,\n    model_args,\n    existing_ids,\n    max_cost,\n):\n    \"\"\"\n    Runs inference on a dataset using the anthropic API.\n\n    Args:\n    test_dataset (datasets.Dataset): The dataset to run inference on.\n    model_name_or_path (str): The name or path of the model to use.\n    output_file (str): The path to the output file.\n    model_args (dict): A dictionary of model arguments.\n    existing_ids (set): A set of ids that have already been processed.\n    max_cost (float): The maximum cost to spend on inference.\n    \"\"\"\n    api_key = os.environ.get(\"ANTHROPIC_API_KEY\", None)\n    if api_key is None:\n        raise ValueError(\n            \"Must provide an api key. Expected in ANTHROPIC_API_KEY environment variable.\"\n        )\n    print(f\"Using Anthropic key {'*' * max(0, len(api_key) - 5) + api_key[-5:]}\")\n    anthropic = Anthropic(api_key=api_key)\n    test_dataset = test_dataset.filter(\n        lambda x: claude_tokenize(x[\"text\"], anthropic)\n        <= MODEL_LIMITS[model_name_or_path],\n        desc=\"Filtering\",\n        load_from_cache_file=False,\n    )\n    temperature = model_args.pop(\"temperature\", 0.2)\n    top_p = model_args.pop(\"top_p\", 0.95 if temperature > 0 else 1)\n    print(f\"Using temperature={temperature}, top_p={top_p}\")\n    basic_args = {\n        \"model_name_or_path\": model_name_or_path,\n    }\n    total_cost = 0\n    print(f\"Filtered to {len(test_dataset)} instances\")\n    if \"claude-3\" in model_name_or_path.lower():\n        call_api = call_anthropic_v2\n    else:\n        call_api = call_anthropic\n    with open(output_file, \"a+\") as f:\n        for datum in tqdm(test_dataset, desc=f\"Inference for {model_name_or_path}\"):\n            instance_id = datum[\"instance_id\"]\n            if instance_id in existing_ids:\n                continue\n            output_dict = {\"instance_id\": instance_id}\n            output_dict.update(basic_args)\n            if \"claude-3\" in model_name_or_path.lower():\n                output_dict[\"text_inputs\"] = f\"{datum['text']}\\n\"\n            else:\n                output_dict[\"text_inputs\"] = (\n                    f\"{HUMAN_PROMPT} {datum['text']}\\n\\n{AI_PROMPT}\"\n                )\n            try:\n                completion, cost = call_api(\n                    output_dict[\"text_inputs\"],\n                    anthropic,\n                    model_name_or_path,\n                    temperature,\n                    top_p,\n                    **model_args,\n                )\n            except Exception as e:\n                logger.error(e)\n                traceback.print_exc()\n                continue\n            total_cost += cost\n            print(f\"Total Cost: {total_cost:.2f}\")\n            if \"claude-3\" in model_name_or_path.lower():\n                output_dict[\"full_output\"] = completion.content[0].text\n            else:\n                output_dict[\"full_output\"] = completion.completion\n            output_dict[\"model_patch\"] = extract_diff(output_dict[\"full_output\"])\n            print(json.dumps(output_dict), file=f, flush=True)\n            if max_cost is not None and total_cost >= max_cost:\n                print(f\"Reached max cost {max_cost}, exiting\")\n                break\n\n\ndef parse_model_args(model_args):\n    \"\"\"\n    Parses a string of model arguments and returns a dictionary of keyword arguments.\n\n    Args:\n        model_args (str): A string of comma-separated key-value pairs representing model arguments.\n\n    Returns:\n        dict: A dictionary of keyword arguments parsed from the input string.\n    \"\"\"\n    kwargs = dict()\n    if model_args is not None:\n        for arg in model_args.split(\",\"):\n            key, value = arg.split(\"=\")\n            # infer value type\n            if value in {\"True\", \"False\"}:\n                kwargs[key] = value == \"True\"\n            elif value.isnumeric():\n                kwargs[key] = int(value)\n            elif value.replace(\".\", \"\", 1).isnumeric():\n                kwargs[key] = float(value)\n            elif value in {\"None\"}:\n                kwargs[key] = None\n            elif value in {\"[]\"}:\n                kwargs[key] = []\n            elif value in {\"{}\"}:\n                kwargs[key] = {}\n            elif value.startswith(\"'\") and value.endswith(\"'\"):\n                kwargs[key] = value[1:-1]\n            elif value.startswith('\"') and value.endswith('\"'):\n                kwargs[key] = value[1:-1]\n            else:\n                kwargs[key] = value\n    return kwargs\n\n\ndef main(\n    dataset_name_or_path,\n    split,\n    model_name_or_path,\n    shard_id,\n    num_shards,\n    output_dir,\n    model_args,\n    max_cost,\n):\n    if shard_id is None and num_shards is not None:\n        logger.warning(\n            f\"Received num_shards={num_shards} but shard_id is None, ignoring\"\n        )\n    if shard_id is not None and num_shards is None:\n        logger.warning(f\"Received shard_id={shard_id} but num_shards is None, ignoring\")\n    model_args = parse_model_args(model_args)\n    model_nickname = model_name_or_path\n    if \"checkpoint\" in Path(model_name_or_path).name:\n        model_nickname = Path(model_name_or_path).parent.name\n    else:\n        model_nickname = Path(model_name_or_path).name\n    output_file = f\"{model_nickname}__{dataset_name_or_path.split('/')[-1]}__{split}\"\n    if shard_id is not None and num_shards is not None:\n        output_file += f\"__shard-{shard_id}__num_shards-{num_shards}\"\n    output_file = Path(output_dir, output_file + \".jsonl\")\n    logger.info(f\"Will write to {output_file}\")\n    existing_ids = set()\n    if os.path.exists(output_file):\n        with open(output_file) as f:\n            for line in f:\n                data = json.loads(line)\n                instance_id = data[\"instance_id\"]\n                existing_ids.add(instance_id)\n    logger.info(f\"Read {len(existing_ids)} already completed ids from {output_file}\")\n    if Path(dataset_name_or_path).exists():\n        dataset = load_from_disk(dataset_name_or_path)\n    else:\n        dataset = load_dataset(dataset_name_or_path)\n    if split not in dataset:\n        raise ValueError(f\"Invalid split {split} for dataset {dataset_name_or_path}\")\n    dataset = dataset[split]\n    lens = np.array(list(map(len, dataset[\"text\"])))\n    dataset = dataset.select(np.argsort(lens))\n    if len(existing_ids) > 0:\n        dataset = dataset.filter(\n            lambda x: x[\"instance_id\"] not in existing_ids,\n            desc=\"Filtering out existing ids\",\n            load_from_cache_file=False,\n        )\n    if shard_id is not None and num_shards is not None:\n        dataset = dataset.shard(num_shards, shard_id, contiguous=True)\n    inference_args = {\n        \"test_dataset\": dataset,\n        \"model_name_or_path\": model_name_or_path,\n        \"output_file\": output_file,\n        \"model_args\": model_args,\n        \"existing_ids\": existing_ids,\n        \"max_cost\": max_cost,\n    }\n    if model_name_or_path.startswith(\"claude\"):\n        anthropic_inference(**inference_args)\n    elif model_name_or_path.startswith(\"gpt\"):\n        openai_inference(**inference_args)\n    else:\n        raise ValueError(f\"Invalid model name or path {model_name_or_path}\")\n    logger.info(\"Done!\")\n\n\nif __name__ == \"__main__\":\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument(\n        \"--dataset_name_or_path\",\n        type=str,\n        required=True,\n        help=\"HuggingFace dataset name or local path\",\n    )\n    parser.add_argument(\n        \"--split\",\n        type=str,\n        default=\"test\",\n        help=\"Dataset split to use\",\n    )\n    parser.add_argument(\n        \"--model_name_or_path\",\n        type=str,\n        help=\"Name of API model. Update MODEL* constants in this file to add new models.\",\n        choices=sorted(list(MODEL_LIMITS.keys())),\n    )\n    parser.add_argument(\n        \"--shard_id\",\n        type=int,\n        default=None,\n        help=\"Shard id to process. If None, process all shards.\",\n    )\n    parser.add_argument(\n        \"--num_shards\",\n        type=int,\n        default=None,\n        help=\"Number of shards. If None, process all shards.\",\n    )\n    parser.add_argument(\n        \"--output_dir\",\n        type=str,\n        default=None,\n        required=True,\n        help=\"Path to the output file.\",\n    )\n    parser.add_argument(\n        \"--model_args\",\n        type=str,\n        default=None,\n        help=\"List of model arguments separated by commas. (e.g. 'top_p=0.95,temperature=0.70')\",\n    )\n    parser.add_argument(\n        \"--max_cost\",\n        type=float,\n        default=None,\n        help=\"Maximum cost to spend on inference.\",\n    )\n    args = parser.parse_args()\n    main(**vars(args))\n",
      "original_issues": [
        {
          "file": "run_api.py",
          "line": 274,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "run_api.py",
          "line": 315,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "run_api.py",
          "line": 389,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "run_llama.py",
      "path": "fixed_files\\run_llama.py",
      "fixed_content": "import json\nimport logging\nimport re\nfrom argparse import ArgumentParser\nfrom datetime import datetime\nfrom pathlib import Path\n\nimport torch\nfrom datasets import load_from_disk, load_dataset\nfrom peft import PeftConfig, PeftModel\nfrom tqdm.auto import tqdm\nfrom transformers import (\n    LlamaTokenizer,\n    StoppingCriteria,\n    StoppingCriteriaList,\n)\nfrom swebench.inference.llamao.modeling_flash_llama import (\n    RepeatingTokensCriteria,\n)\n\nlogger = logging.getLogger(__name__)\n\ndef get_all_existing_ids(output_file):\n    stub_pattern = re.compile(\n        r\"((?:[\\w\\-\\.]+)\\_\\_temp\\-((\\d+(\\.\\d+)?)|None)\\_\\_top\\-p\\-((\\d+(\\.\\d+)?)|None))(\\_\\_|\\.jsonl)\"\n    )\n    match = stub_pattern.match(output_file.name)\n    if not output_file.exists():\n        return set()\n    if match is None:\n        raise ValueError(f\"output_file {output_file} doesn't match pattern\")\n    stub = match[1]\n    existing_ids = set()\n    output_files = list(Path(output_file.parent).glob(stub + \"*\"))\n    for filename in output_files:\n        logger.info(f\"Loading existing ids from existing {filename}\")\n        with open(filename) as f:\n            for line in f:\n                datum = json.loads(line)\n                existing_ids.add(datum[\"instance_id\"])\n    logger.info(f\"Found {len(existing_ids)} existing ids\")\n    return existing_ids\n\n\ndef main(\n    model_name_or_path,\n    peft_path,\n    dataset_path,\n    split,\n    temperature,\n    top_p,\n    output_dir,\n    min_len,\n    max_len,\n    shard_id,\n    num_shards,\n):\n    if shard_id is not None and num_shards is None:\n        raise ValueError(\"num_shards must be specified with shard_id\")\n    if shard_id is None and num_shards is not None:\n        raise ValueError(\"shard_id must be specified with num_shards\")\n    peft_config = None\n    if peft_path is not None:\n        peft_config = PeftConfig.from_pretrained(peft_path)\n        if peft_config.base_model_name_or_path != model_name_or_path:\n            logger.warning(\n                f\"model_name_or_path {model_name_or_path} does not match peft_path base_model {peft_config.base_model_name_or_path}\"\n            )\n    output_file = get_output_file(\n        output_dir=output_dir,\n        model_name_or_path=model_name_or_path,\n        peft_path=peft_path,\n        dataset_path=dataset_path,\n        split=split,\n        temperature=temperature,\n        top_p=top_p,\n        min_len=min_len,\n        max_len=max_len,\n        shard_id=shard_id,\n        num_shards=num_shards,\n    )\n    logger.warning(f\"output_file: {output_file}\")\n    model = load_model(model_name_or_path, peft_path)\n    tokenizer = load_tokenizer(model_name_or_path)\n    existing_ids = get_all_existing_ids(output_file)\n    dataset = load_data(\n        dataset_path=dataset_path,\n        split=split,\n        tokenizer=tokenizer,\n        min_len=min_len,\n        max_len=max_len,\n        model_name_or_path=model_name_or_path,\n        peft_path=peft_path,\n        existing_ids=existing_ids,\n        shard_id=shard_id,\n        num_shards=num_shards,\n    )\n    with open(output_file, \"a\") as f:\n        generate(\n            model=model,\n            dataset=dataset,\n            tokenizer=tokenizer,\n            temperature=temperature,\n            top_p=top_p,\n            fileobj=f,\n            model_name_or_path=model_name_or_path,\n            peft_path=peft_path,\n        )\n    logger.info(\"Done\")\n\n\nif __name__ == \"__main__\":\n    parser = ArgumentParser()\n    parser.add_argument(\n        \"--model_name_or_path\",\n        type=str,\n        required=True,\n        help=\"Path to model or hf model name\",\n    )\n    parser.add_argument(\"--peft_path\", type=str, help=\"Path to PEFT adapters\")\n    parser.add_argument(\n        \"--dataset_path\",\n        type=str,\n        required=True,\n        help=\"Path to dataset or hf dataset name\",\n    )\n    parser.add_argument(\n        \"--split\", type=str, default=\"test\", help=\"Dataset split to use\"\n    )\n    parser.add_argument(\"--output_dir\", type=str, default=\"./outputs\")\n    parser.add_argument(\"--temperature\", type=float, default=0.0)\n    parser.add_argument(\"--top_p\", type=float, default=1.0)\n    parser.add_argument(\n        \"--min_len\",\n        type=int,\n        default=None,\n        help=\"Minimum length of input sequences to include\",\n    )\n    parser.add_argument(\n        \"--max_len\",\n        type=int,\n        default=None,\n        help=\"Maximum length of input sequences to include\",\n    )\n    parser.add_argument(\n        \"--shard_id\", type=int, default=None, help=\"ID of the shard to load\"\n    )\n    parser.add_argument(\n        \"--num_shards\", type=int, default=None, help=\"Total number of shards\"\n    )\n    args = parser.parse_args()\n    main(**vars(args))\n",
      "original_issues": [
        {
          "file": "run_llama.py",
          "line": 330,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "bm25_retrieval.py",
      "path": "fixed_files\\bm25_retrieval.py",
      "fixed_content": "import json\nimport os\nimport ast\nimport jedi\nimport shutil\nimport traceback\nimport subprocess\nfrom filelock import FileLock\nfrom typing import Any\nfrom datasets import load_from_disk, load_dataset\nfrom pyserini.search.lucene import LuceneSearcher\nfrom git import Repo\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nfrom argparse import ArgumentParser\n\nfrom swebench.inference.make_datasets.utils import list_files, string_to_bool\n\nimport logging\n\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\nlogger = logging.getLogger(__name__)\n\n\nclass ContextManager:\n    \"\"\"\n    A context manager for managing a Git repository at a specific commit.\n\n    Args:\n        repo_path (str): The path to the Git repository.\n        base_commit (str): The commit hash to switch to.\n        verbose (bool, optional): Whether to print verbose output. Defaults to False.\n\n    Attributes:\n        repo_path (str): The path to the Git repository.\n        base_commit (str): The commit hash to switch to.\n        verbose (bool): Whether to print verbose output.\n        repo (git.Repo): The Git repository object.\n\n    Methods:\n        __enter__(): Switches to the specified commit and returns the context manager object.\n        get_readme_files(): Returns a list of filenames for all README files in the repository.\n        __exit__(exc_type, exc_val, exc_tb): Does nothing.\n    \"\"\"\n\n    def __init__(self, repo_path, base_commit, verbose=False):\n        self.repo_path = Path(repo_path).resolve().as_posix()\n        self.base_commit = base_commit\n        self.verbose = verbose\n        self.repo = Repo(self.repo_path)\n\n    def __enter__(self):\n        if self.verbose:\n            print(f\"Switching to {self.base_commit}\")\n        try:\n            self.repo.git.reset(\"--hard\", self.base_commit)\n            self.repo.git.clean(\"-fdxq\")\n        except Exception as e:\n            logger.error(f\"Failed to switch to {self.base_commit}\")\n            logger.error(e)\n            raise e\n        return self\n\n    def get_readme_files(self):\n        files = os.listdir(self.repo_path)\n        files = list(filter(lambda x: os.path.isfile(x), files))\n        files = list(filter(lambda x: x.lower().startswith(\"readme\"), files))\n        return files\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        pass\n\n\ndef file_name_and_contents(filename, relative_path):\n    text = relative_path + \"\\n\"\n    with open(filename) as f:\n        text += f.read()\n    return text\n\n\ndef file_name_and_documentation(filename, relative_path):\n    text = relative_path + \"\\n\"\n    try:\n        with open(filename) as f:\n            node = ast.parse(f.read())\n        data = ast.get_docstring(node)\n        if data:\n            text += f\"{data}\"\n        for child_node in ast.walk(node):\n            if isinstance(\n                child_node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)\n            ):\n                data = ast.get_docstring(child_node)\n                if data:\n                    text += f\"\\n\\n{child_node.name}\\n{data}\"\n    except Exception as e:\n        logger.error(e)\n        logger.error(f\"Failed to parse file {str(filename)}. Using simple filecontent.\")\n        with open(filename) as f:\n            text += f.read()\n    return text\n\n\ndef file_name_and_docs_jedi(filename, relative_path):\n    text = relative_path + \"\\n\"\n    with open(filename) as f:\n        source_code = f.read()\n    try:\n        script = jedi.Script(source_code, path=filename)\n        module = script.get_context()\n        docstring = module.docstring()\n        text += f\"{module.full_name}\\n\"\n        if docstring:\n            text += f\"{docstring}\\n\\n\"\n        abspath = Path(filename).absolute()\n        names = [\n            name\n            for name in script.get_names(\n                all_scopes=True, definitions=True, references=False\n            )\n            if not name.in_builtin_module()\n        ]\n        for name in names:\n            try:\n                origin = name.goto(follow_imports=True)[0]\n                if origin.module_name != module.full_name:\n                    continue\n                if name.parent().full_name != module.full_name:\n                    if name.type in {\"statement\", \"param\"}:\n                        continue\n                full_name = name.full_name\n                text += f\"{full_name}\\n\"\n                docstring = name.docstring()\n                if docstring:\n                    text += f\"{docstring}\\n\\n\"\n            except:\n                continue\n    except Exception as e:\n        logger.error(e)\n        logger.error(f\"Failed to parse file {str(filename)}. Using simple filecontent.\")\n        text = f\"{relative_path}\\n{source_code}\"\n        return text\n    return text\n\n\nDOCUMENT_ENCODING_FUNCTIONS = {\n    \"file_name_and_contents\": file_name_and_contents,\n    \"file_name_and_documentation\": file_name_and_documentation,\n    \"file_name_and_docs_jedi\": file_name_and_docs_jedi,\n}\n\n\ndef clone_repo(repo, root_dir, token):\n    \"\"\"\n    Clones a GitHub repository to a specified directory.\n\n    Args:\n        repo (str): The GitHub repository to clone.\n        root_dir (str): The root directory to clone the repository to.\n        token (str): The GitHub personal access token to use for authentication.\n\n    Returns:\n        Path: The path to the cloned repository directory.\n    \"\"\"\n    repo_dir = Path(root_dir, f\"repo__{repo.replace('/', '__')}\")\n\n    if not repo_dir.exists():\n        repo_url = f\"https://{token}@github.com/{repo}.git\"\n        logger.info(f\"Cloning {repo} {os.getpid()}\")\n        Repo.clone_from(repo_url, repo_dir)\n    return repo_dir\n\n\ndef build_documents(repo_dir, commit, document_encoding_func):\n    \"\"\"\n    Builds a dictionary of documents from a given repository directory and commit.\n\n    Args:\n        repo_dir (str): The path to the repository directory.\n        commit (str): The commit hash to use.\n        document_encoding_func (function): A function that takes a filename and a relative path and returns the encoded document text.\n\n    Returns:\n        dict: A dictionary where the keys are the relative paths of the documents and the values are the encoded document text.\n    \"\"\"\n    documents = dict()\n    with ContextManager(repo_dir, commit):\n        filenames = list_files(repo_dir, include_tests=False)\n        for relative_path in filenames:\n            filename = os.path.join(repo_dir, relative_path)\n            text = document_encoding_func(filename, relative_path)\n            documents[relative_path] = text\n    return documents\n\n\ndef make_index(\n    repo_dir,\n    root_dir,\n    query,\n    commit,\n    document_encoding_func,\n    python,\n    instance_id,\n):\n    \"\"\"\n    Builds an index for a given set of documents using Pyserini.\n\n    Args:\n        repo_dir (str): The path to the repository directory.\n        root_dir (str): The path to the root directory.\n        query (str): The query to use for retrieval.\n        commit (str): The commit hash to use for retrieval.\n        document_encoding_func (function): The function to use for encoding documents.\n        python (str): The path to the Python executable.\n        instance_id (int): The ID of the current instance.\n\n    Returns:\n        index_path (Path): The path to the built index.\n    \"\"\"\n    index_path = Path(root_dir, f\"index__{str(instance_id)}\", \"index\")\n    if index_path.exists():\n        return index_path\n    thread_prefix = f\"(pid {os.getpid()}) \"\n    documents_path = Path(root_dir, instance_id, \"documents.jsonl\")\n    if not documents_path.parent.exists():\n        documents_path.parent.mkdir(parents=True)\n    documents = build_documents(repo_dir, commit, document_encoding_func)\n    with open(documents_path, \"w\") as docfile:\n        for relative_path, contents in documents.items():\n            print(\n                json.dumps({\"id\": relative_path, \"contents\": contents}),\n                file=docfile,\n                flush=True,\n            )\n    cmd = [\n        python,\n        \"-m\",\n        \"pyserini.index\",\n        \"--collection\",\n        \"JsonCollection\",\n        \"--generator\",\n        \"DefaultLuceneDocumentGenerator\",\n        \"--threads\",\n        \"2\",\n        \"--input\",\n        documents_path.parent.as_posix(),\n        \"--index\",\n        index_path.as_posix(),\n        \"--storePositions\",\n        \"--storeDocvectors\",\n        \"--storeRaw\",\n    ]\n    try:\n        proc = subprocess.Popen(\n            cmd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            universal_newlines=True,\n        )\n        output, error = proc.communicate()\n    except KeyboardInterrupt:\n        proc.kill()\n        raise KeyboardInterrupt\n    if proc.returncode == 130:\n        logger.warning(thread_prefix + \"Process killed by user\")\n        raise KeyboardInterrupt\n    if proc.returncode != 0:\n        logger.error(f\"return code: {proc.returncode}\")\n        raise Exception(\n            thread_prefix\n            + f\"Failed to build index for {instance_id} with error {error}\"\n        )\n    return index_path\n\n\ndef get_remaining_instances(instances, output_file):\n    \"\"\"\n    Filters a list of instances to exclude those that have already been processed and saved in a file.\n\n    Args:\n        instances (List[Dict]): A list of instances, where each instance is a dictionary with an \"instance_id\" key.\n        output_file (Path): The path to the file where the processed instances are saved.\n\n    Returns:\n        List[Dict]: A list of instances that have not been processed yet.\n    \"\"\"\n    instance_ids = set()\n    remaining_instances = list()\n    if output_file.exists():\n        with FileLock(output_file.as_posix() + \".lock\"):\n            with open(output_file) as f:\n                for line in f:\n                    instance = json.loads(line)\n                    instance_id = instance[\"instance_id\"]\n                    instance_ids.add(instance_id)\n            logger.warning(\n                f\"Found {len(instance_ids)} existing instances in {output_file}. Will skip them.\"\n            )\n    else:\n        output_file.parent.mkdir(parents=True, exist_ok=True)\n        return instances\n    for instance in instances:\n        instance_id = instance[\"instance_id\"]\n        if instance_id not in instance_ids:\n            remaining_instances.append(instance)\n    return remaining_instances\n\n\ndef search(instance, index_path):\n    \"\"\"\n    Searches for relevant documents in the given index for the given instance.\n\n    Args:\n        instance (dict): The instance to search for.\n        index_path (str): The path to the index to search in.\n\n    Returns:\n        dict: A dictionary containing the instance ID and a list of hits, where each hit is a dictionary containing the\n        document ID and its score.\n    \"\"\"\n    try:\n        instance_id = instance[\"instance_id\"]\n        searcher = LuceneSearcher(index_path.as_posix())\n        cutoff = len(instance[\"problem_statement\"])\n        while True:\n            try:\n                hits = searcher.search(\n                    instance[\"problem_statement\"][:cutoff],\n                    k=20,\n                    remove_dups=True,\n                )\n            except Exception as e:\n                if \"maxClauseCount\" in str(e):\n                    cutoff = int(round(cutoff * 0.8))\n                    continue\n                else:\n                    raise e\n            break\n        results = {\"instance_id\": instance_id, \"hits\": []}\n        for hit in hits:\n            results[\"hits\"].append({\"docid\": hit.docid, \"score\": hit.score})\n        return results\n    except Exception:\n        logger.error(f\"Failed to process {instance_id}\")\n        logger.error(traceback.format_exc())\n        return None\n\n\ndef search_indexes(remaining_instance, output_file, all_index_paths):\n    \"\"\"\n    Searches the indexes for the given instances and writes the results to the output file.\n\n    Args:\n        remaining_instance (list): A list of instances to search for.\n        output_file (str): The path to the output file to write the results to.\n        all_index_paths (dict): A dictionary mapping instance IDs to the paths of their indexes.\n    \"\"\"\n    for instance in tqdm(remaining_instance, desc=\"Retrieving\"):\n        instance_id = instance[\"instance_id\"]\n        if instance_id not in all_index_paths:\n            continue\n        index_path = all_index_paths[instance_id]\n        results = search(instance, index_path)\n        if results is None:\n            continue\n        with FileLock(output_file.as_posix() + \".lock\"):\n            with open(output_file, \"a\") as out_file:\n                print(json.dumps(results), file=out_file, flush=True)\n\n\ndef get_missing_ids(instances, output_file):\n    with open(output_file) as f:\n        written_ids = set()\n        for line in f:\n            instance = json.loads(line)\n            instance_id = instance[\"instance_id\"]\n            written_ids.add(instance_id)\n    missing_ids = set()\n    for instance in instances:\n        instance_id = instance[\"instance_id\"]\n        if instance_id not in written_ids:\n            missing_ids.add(instance_id)\n    return missing_ids\n\n\ndef get_index_paths_worker(\n    instance,\n    root_dir_name,\n    document_encoding_func,\n    python,\n    token,\n):\n    index_path = None\n    repo = instance[\"repo\"]\n    commit = instance[\"base_commit\"]\n    instance_id = instance[\"instance_id\"]\n    try:\n        repo_dir = clone_repo(repo, root_dir_name, token)\n        query = instance[\"problem_statement\"]\n        index_path = make_index(\n            repo_dir=repo_dir,\n            root_dir=root_dir_name,\n            query=query,\n            commit=commit,\n            document_encoding_func=document_encoding_func,\n            python=python,\n            instance_id=instance_id,\n        )\n    except:\n        logger.error(f\"Failed to process {repo}/{commit} (instance {instance_id})\")\n        logger.error(traceback.format_exc())\n    return instance_id, index_path\n\n\ndef get_index_paths(\n    remaining_instances: list[dict[str, Any]],\n    root_dir_name: str,\n    document_encoding_func: Any,\n    python: str,\n    token: str,\n    output_file: str,\n) -> dict[str, str]:\n    \"\"\"\n    Retrieves the index paths for the given instances using multiple processes.\n\n    Args:\n        remaining_instances: A list of instances for which to retrieve the index paths.\n        root_dir_name: The root directory name.\n        document_encoding_func: A function for encoding documents.\n        python: The path to the Python executable.\n        token: The token to use for authentication.\n        output_file: The output file.\n        num_workers: The number of worker processes to use.\n\n    Returns:\n        A dictionary mapping instance IDs to index paths.\n    \"\"\"\n    all_index_paths = dict()\n    for instance in tqdm(remaining_instances, desc=\"Indexing\"):\n        instance_id, index_path = get_index_paths_worker(\n            instance=instance,\n            root_dir_name=root_dir_name,\n            document_encoding_func=document_encoding_func,\n            python=python,\n            token=token,\n        )\n        if index_path is None:\n            continue\n        all_index_paths[instance_id] = index_path\n    return all_index_paths\n\n\ndef get_root_dir(dataset_name, output_dir, document_encoding_style):\n    root_dir = Path(output_dir, dataset_name, document_encoding_style + \"_indexes\")\n    if not root_dir.exists():\n        root_dir.mkdir(parents=True, exist_ok=True)\n    root_dir_name = root_dir\n    return root_dir, root_dir_name\n\n\ndef main(\n    dataset_name_or_path,\n    document_encoding_style,\n    output_dir,\n    shard_id,\n    num_shards,\n    splits,\n    leave_indexes,\n):\n    document_encoding_func = DOCUMENT_ENCODING_FUNCTIONS[document_encoding_style]\n    token = os.environ.get(\"GITHUB_TOKEN\", \"git\")\n    if Path(dataset_name_or_path).exists():\n        dataset = load_from_disk(dataset_name_or_path)\n        dataset_name = os.path.basename(dataset_name_or_path)\n    else:\n        dataset = load_dataset(dataset_name_or_path)\n        dataset_name = dataset_name_or_path.replace(\"/\", \"__\")\n    if shard_id is not None:\n        for split in splits:\n            dataset[split] = dataset[split].shard(num_shards, shard_id)\n    instances = list()\n    if set(splits) - set(dataset.keys()) != set():\n        raise ValueError(f\"Unknown splits {set(splits) - set(dataset.keys())}\")\n    for split in splits:\n        instances += list(dataset[split])\n    python = subprocess.run(\"which python\", shell=True, capture_output=True)\n    python = python.stdout.decode(\"utf-8\").strip()\n    output_file = Path(\n        output_dir, dataset_name, document_encoding_style + \".retrieval.jsonl\"\n    )\n    remaining_instances = get_remaining_instances(instances, output_file)\n    root_dir, root_dir_name = get_root_dir(\n        dataset_name, output_dir, document_encoding_style\n    )\n    try:\n        all_index_paths = get_index_paths(\n            remaining_instances,\n            root_dir_name,\n            document_encoding_func,\n            python,\n            token,\n            output_file,\n        )\n    except KeyboardInterrupt:\n        logger.info(f\"Cleaning up {root_dir}\")\n        del_dirs = list(root_dir.glob(\"repo__*\"))\n        if leave_indexes:\n            index_dirs = list(root_dir.glob(\"index__*\"))\n            del_dirs += index_dirs\n        for dirname in del_dirs:\n            shutil.rmtree(dirname, ignore_errors=True)\n    logger.info(f\"Finished indexing {len(all_index_paths)} instances\")\n    search_indexes(remaining_instances, output_file, all_index_paths)\n    missing_ids = get_missing_ids(instances, output_file)\n    logger.warning(f\"Missing indexes for {len(missing_ids)} instances.\")\n    logger.info(f\"Saved retrieval results to {output_file}\")\n    del_dirs = list(root_dir.glob(\"repo__*\"))\n    logger.info(f\"Cleaning up {root_dir}\")\n    if leave_indexes:\n        index_dirs = list(root_dir.glob(\"index__*\"))\n        del_dirs += index_dirs\n    for dirname in del_dirs:\n        shutil.rmtree(dirname, ignore_errors=True)\n\n\nif __name__ == \"__main__\":\n    parser = ArgumentParser()\n    parser.add_argument(\n        \"--dataset_name_or_path\",\n        type=str,\n        default=\"SWE-bench/SWE-bench\",\n        help=\"Dataset to use for test set from HuggingFace Datasets or path to a save_to_disk directory.\",\n    )\n    parser.add_argument(\n        \"--document_encoding_style\",\n        choices=DOCUMENT_ENCODING_FUNCTIONS.keys(),\n        default=\"file_name_and_contents\",\n    )\n    parser.add_argument(\"--output_dir\", default=\"./retreival_results\")\n    parser.add_argument(\"--splits\", nargs=\"+\", default=[\"train\", \"test\"])\n    parser.add_argument(\"--shard_id\", type=int)\n    parser.add_argument(\"--num_shards\", type=int, default=20)\n    parser.add_argument(\"--leave_indexes\", type=string_to_bool, default=True)\n    args = parser.parse_args()\n    main(**vars(args))\n",
      "original_issues": [
        {
          "file": "bm25_retrieval.py",
          "line": 58,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "bm25_retrieval.py",
          "line": 96,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "bm25_retrieval.py",
          "line": 136,
          "severity": "LOW",
          "rule_id": "PY010",
          "message": "使用裸 except，建议捕获具体异常类型。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "bm25_retrieval.py",
          "line": 138,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "bm25_retrieval.py",
          "line": 332,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "bm25_retrieval.py",
          "line": 343,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "bm25_retrieval.py",
          "line": 409,
          "severity": "LOW",
          "rule_id": "PY010",
          "message": "使用裸 except，建议捕获具体异常类型。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        },
        {
          "file": "bm25_retrieval.py",
          "line": 1,
          "severity": "LOW",
          "rule_id": "RUFF-I001",
          "message": "Import block is un-sorted or un-formatted",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "create_instance.py",
      "path": "fixed_files\\create_instance.py",
      "fixed_content": "import json\nimport logging\nimport os\nimport traceback\nfrom copy import deepcopy\nfrom pathlib import Path\nfrom tempfile import TemporaryDirectory\nimport unidiff\nfrom tqdm.auto import tqdm\n\nfrom swebench.inference.make_datasets.tokenize_dataset import TOKENIZER_FUNCS\nfrom swebench.inference.make_datasets.utils import (\n    AutoContextManager,\n    ingest_directory_contents,\n)\n\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\nlogger = logging.getLogger(__name__)\n\n\nPATCH_EXAMPLE = \"\"\"--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\"\"\"\n\n\nFULL_GENERATION_EXAMPLE = \"\"\"[start of /src/this_file.py]\nimport os\n\ndef euclidean(a, b):\n    if b == 0:\n        return a\n    return euclidean(b, a % b)\n[end of /src/this_file.py]\n[start of /src/another_file.py]\ndef bresenham(x0, y0, x1, y1):\n    points = []\n    dx = abs(x1 - x0)\n    dy = abs(y1 - y0)\n    x, y = x0, y0\n    sx = -1 if x0 > x1 else 1\n    sy = -1 if y0 > y1 else 1\n    if dx > dy:\n        err = dx / 2.0\n        while x != x1:\n            points.append((x, y))\n            err -= dy\n            if err < 0:\n                y += sy\n                err += dx\n            x += sx\n    else:\n        err = dy / 2.0\n        while y != y1:\n            points.append((x\n            err -= dx\n            if err < 0:\n                x += sx\n                err += dy\n            y += sy\n    points.append((x, y))\n    return points\n[end of /src/another_file.py]\"\"\"\n\n\ndef add_lines_list(content):\n    content_with_lines = list()\n    for ix, line in enumerate(content.split(\"\\n\"), start=1):\n        content_with_lines.append(f\"{ix} {line}\")\n    return content_with_lines\n\n\ndef add_lines(content):\n    return \"\\n\".join(add_lines_list(content))\n\n\ndef make_code_text(files_dict, add_line_numbers=True):\n    all_text = \"\"\n    for filename, contents in sorted(files_dict.items()):\n        all_text += f\"[start of {filename}]\\n\"\n        if add_line_numbers:\n            all_text += add_lines(contents)\n        else:\n            all_text += contents\n        all_text += f\"\\n[end of {filename}]\\n\"\n    return all_text.strip(\"\\n\")\n\n\ndef make_code_text_edits_only(files_dict, patch, add_line_numbers=True):\n    files = dict()\n    patch = unidiff.PatchSet(patch)\n    for patched_file in patch:\n        source_file = patched_file.source_file.split(\"a/\", 1)[-1]\n        files[source_file] = list()\n        for hunk in patched_file:\n            start = hunk.source_start - 15\n            end = start + hunk.source_length + 15\n            files[source_file].append((start, end))\n    all_text = \"\"\n    for filename, content in files_dict.items():\n        all_text += f\"[start of {filename}]\\n\"\n        content_with_lines = add_lines_list(content)\n        for start, end in files[filename]:\n            if start > 0:\n                all_text += \"...\\n\"\n            all_text += \"\\n\".join(content_with_lines[start:end])\n            all_text += \"\\n\"\n            if end < len(content_with_lines):\n                all_text += \"...\\n\"\n        all_text = all_text.strip(\"\\n\")\n        all_text += f\"\\n[end of {filename}]\\n\"\n    return all_text.strip(\"\\n\")\n\n\ndef prompt_style_2(instance):\n    premise = \"You will be provided with a partial code base and an issue statement explaining a problem to resolve.\"\n    readmes_text = make_code_text(instance[\"readmes\"])\n    code_text = make_code_text(instance[\"file_contents\"])\n    instructions = (\n        \"I need you to solve this issue by generating a single patch file that I can apply \"\n        + \"directly to this repository using git apply. Please respond with a single patch \"\n        + \"file in the following format.\"\n    )\n    problem_statement = instance[\"problem_statement\"]\n    final_text = [\n        premise,\n        \"<issue>\",\n        problem_statement,\n        \"</issue>\",\n        \"<code>\",\n        readmes_text,\n        code_text,\n        \"</code>\",\n        instructions,\n        \"<patch>\",\n        PATCH_EXAMPLE,\n        \"</patch>\",\n    ]\n    final_text = \"\\n\".join(final_text)\n    return final_text\n\n\ndef prompt_style_2_edits_only(instance):\n    premise = \"You will be provided with a partial code base and an issue statement explaining a problem to resolve.\"\n    readmes_text = make_code_text(instance[\"readmes\"])\n    code_text = make_code_text_edits_only(instance[\"file_contents\"], instance[\"patch\"])\n    instructions = (\n        \"I need you to solve this issue by generating a single patch file that I can apply \"\n        + \"directly to this repository using git apply. Please respond with a single patch \"\n        + \"file in the following format.\"\n    )\n    problem_statement = instance[\"problem_statement\"]\n    final_text = [\n        premise,\n        \"<issue>\",\n        problem_statement,\n        \"</issue>\",\n        \"<code>\",\n        readmes_text,\n        code_text,\n        \"</code>\",\n        instructions,\n        \"<patch>\",\n        PATCH_EXAMPLE,\n        \"</patch>\",\n    ]\n    final_text = \"\\n\".join(final_text)\n    return final_text\n\n\ndef prompt_style_3(instance):\n    premise = \"You will be provided with a partial code base and an issue statement explaining a problem to resolve.\"\n    readmes_text = make_code_text(instance[\"readmes\"])\n    code_text = make_code_text(instance[\"file_contents\"])\n    example_explanation = (\n        \"Here is an example of a patch file. It consists of changes to the code base. \"\n        + \"It specifies the file names, the line numbers of each change, and the removed and added lines. \"\n        + \"A single patch file can contain changes to multiple files.\"\n    )\n    final_instruction = (\n        \"I need you to solve the provided issue by generating a single patch file that I can apply \"\n        + \"directly to this repository using git apply. Please respond with a single patch \"\n        + \"file in the format shown above.\"\n    )\n    problem_statement = instance[\"problem_statement\"]\n    final_text = [\n        premise,\n        \"<issue>\",\n        problem_statement,\n        \"</issue>\",\n        \"\",\n        \"<code>\",\n        readmes_text,\n        code_text,\n        \"</code>\",\n        \"\",\n        example_explanation,\n        \"<patch>\",\n        PATCH_EXAMPLE,\n        \"</patch>\",\n        \"\",\n        final_instruction,\n        \"Respond below:\",\n    ]\n    final_text = \"\\n\".join(final_text)\n    return final_text\n\n\ndef full_file_gen(instance):\n    premise = \"You will be provided with a partial code base and an issue statement explaining a problem to resolve.\"\n    readmes_text = make_code_text(instance[\"readmes\"], add_line_numbers=False)\n    code_text = make_code_text(instance[\"file_contents\"], add_line_numbers=False)\n    instructions = (\n        \"I need you to solve this issue by regenerating the full files in the code base that you would like to change. \"\n        + \"You can change as many files as you like. \"\n        + \"Please respond with a list of files and their revised contents in the following format.\"\n    )\n    problem_statement = instance[\"problem_statement\"]\n    final_text = [\n        premise,\n        \"<issue>\",\n        problem_statement,\n        \"</issue>\",\n        \"<code>\",\n        readmes_text,\n        code_text,\n        \"</code>\",\n        instructions,\n        \"<example>\",\n        FULL_GENERATION_EXAMPLE,\n        \"</example>\",\n    ]\n    final_text = \"\\n\".join(final_text)\n    return final_text\n\n\ndef ingest_files(filenames):\n    files_dict = dict()\n    for filename in filenames:\n        with open(filename) as f:\n            content = f.read()\n        files_dict[filename] = content\n    return files_dict\n\n\nPROMPT_FUNCTIONS = {\n    \"style-2\": prompt_style_2,\n    \"style-3\": prompt_style_3,\n    \"full_file_gen\": full_file_gen,\n    \"style-2-edits-only\": prompt_style_2_edits_only,\n}\n\n\ndef add_retrieval_results(input_instances, retrieval_file, k, file_source):\n    \"\"\"\n    Adds retrieval results to input_instances in-place\n    \"\"\"\n    retrieval_results_path = Path(retrieval_file)\n    assert retrieval_results_path.exists(), (\n        f\"Retrieval results not found at {retrieval_results_path}\"\n    )\n    retrieval_results = [json.loads(line) for line in open(retrieval_results_path)]\n    retrieval_results = {x[\"instance_id\"]: x[\"hits\"] for x in retrieval_results}\n    for instance_id, instance in tqdm(\n        input_instances.items(),\n        total=len(input_instances),\n        desc=\"Adding retrieval results\",\n    ):\n        try:\n            instance[\"hits\"] = retrieval_results[instance_id][:k]\n        except KeyError:\n            logger.warning(f\"Instance {instance_id} not found in retrieval results\")\n            instance[\"hits\"] = list()\n\n\ndef get_oracle_filenames(instance):\n    \"\"\"\n    Returns the filenames that are changed in the patch\n    \"\"\"\n    source_files = {\n        patch_file.source_file.split(\"a/\", 1)[-1]\n        for patch_file in unidiff.PatchSet(instance[\"patch\"])\n    }\n    gold_docs = set()\n    for source_file in source_files:\n        gold_docs.add(source_file)\n    return gold_docs\n\n\ndef add_text_inputs(\n    instances,\n    retrieval_file,\n    k,\n    prompt_style,\n    file_source,\n    max_context_len=None,\n    tokenizer_name=None,\n    verbose=False,\n    progress_file=None,\n) -> None:\n    \"\"\"Process instances and save results to progress file.\n\n    Args:\n    - instances: dictionary with unprocessed input instances\n    - retrieval_file: if using retrieval method for file_contents, specify retrieval_file\n    - k: if using retrieval, specifies the maximum number of files to include\n    - prompt_style: specify the function to generate instructions and prompt\n    - file_source: where to collect file_contents (e.g. oracle or bm25)\n    - verbose: set ContextManager verbose to True\n    - progress_file: required, path to save processed instances\n    \"\"\"\n    assert progress_file is not None, \"progress_file is required\"\n\n    # Create progress file directory if it doesn't exist\n    progress_path = Path(progress_file)\n    progress_path.parent.mkdir(parents=True, exist_ok=True)\n\n    # Load already processed instances\n    processed_ids = set()\n    file_exists = os.path.exists(progress_file)\n\n    if file_exists:\n        with open(progress_file) as f:\n            for line in f:\n                instance = json.loads(line)\n                processed_ids.add(instance[\"instance_id\"])\n        logger.info(f\"Found {len(processed_ids)} already processed instances\")\n        progress_file_handle = open(progress_file, \"a\")\n    else:\n        progress_file_handle = open(progress_file, \"w\")\n\n    try:\n        if max_context_len is not None:\n            assert tokenizer_name is not None, (\n                \"Must specify tokenizer_name if using max_context_len\"\n            )\n            tokenizer, tokenizer_func = TOKENIZER_FUNCS[tokenizer_name]\n\n        # Add retrieval results if needed\n        if file_source in {\"bm25\"}:\n            instances = deepcopy(instances)\n            add_retrieval_results(instances, retrieval_file, k, file_source)\n\n        # Filter out already processed instances\n        instances_to_process = {\n            k: v for k, v in instances.items() if k not in processed_ids\n        }\n        logger.info(f\"Processing {len(instances_to_process)} instances\")\n\n        orig_dir = os.getcwd()\n        with TemporaryDirectory(\n            dir=\"/scratch\" if os.path.exists(\"/scratch\") else \"/tmp\"\n        ) as root_dir:\n            for instance_id, instance in tqdm(\n                instances_to_process.items(),\n                total=len(instances_to_process),\n                desc=\"Processing instances\",\n            ):\n                try:\n                    with AutoContextManager(instance, root_dir, verbose=verbose) as cm:\n                        # Process instance\n                        processed_instance = deepcopy(instance)\n\n                        # Add readmes\n                        readmes = cm.get_readme_files()\n                        processed_instance[\"readmes\"] = ingest_files(readmes)\n\n                        # Handle file contents based on configuration\n                        if max_context_len is not None:\n                            processed_instance[\"file_contents\"] = dict()\n                            base_text_inputs = PROMPT_FUNCTIONS[prompt_style](\n                                processed_instance\n                            )\n                            base_text_input_length = len(\n                                tokenizer_func(base_text_inputs, tokenizer)\n                            )\n\n                        if file_source == \"oracle\":\n                            processed_instance[\"file_contents\"] = ingest_files(\n                                get_oracle_filenames(processed_instance)\n                            )\n                        elif file_source == \"bm25\":\n                            processed_instance[\"file_contents\"] = ingest_files(\n                                [x[\"docid\"] for x in processed_instance[\"hits\"]]\n                            )\n                        elif file_source == \"all\":\n                            processed_instance[\"file_contents\"] = (\n                                ingest_directory_contents(cm.repo_path)\n                            )\n                        elif file_source == \"none\":\n                            processed_instance[\"file_contents\"] = dict()\n                        else:\n                            raise ValueError(f\"Invalid file source {file_source}\")\n\n                        # Handle context length limits\n                        if max_context_len is not None:\n                            cur_input_len = base_text_input_length\n                            include_files = []\n                            for filename in [\n                                x[\"docid\"] for x in processed_instance[\"hits\"]\n                            ]:\n                                content = make_code_text(\n                                    {\n                                        filename: processed_instance[\"file_contents\"][\n                                            filename\n                                        ]\n                                    }\n                                )\n                                if tokenizer_name == \"llama\":\n                                    tokens = tokenizer_func(\"\\n\" + content, tokenizer)\n                                    idx = tokens.index(13)\n                                    tokens = tokens[idx + 1 :]\n                                else:\n                                    tokens = tokenizer_func(content, tokenizer)\n                                if cur_input_len + len(tokens) < max_context_len:\n                                    include_files.append(filename)\n                                    cur_input_len += len(tokens)\n                            processed_instance[\"file_contents\"] = {\n                                filename: processed_instance[\"file_contents\"][filename]\n                                for filename in include_files\n                            }\n\n                        # Generate final text inputs\n                        processed_instance[\"text_inputs\"] = PROMPT_FUNCTIONS[\n                            prompt_style\n                        ](processed_instance)\n\n                        # Save to progress file\n                        progress_file_handle.write(\n                            json.dumps(processed_instance) + \"\\n\"\n                        )\n                        progress_file_handle.flush()\n\n                except Exception as e:\n                    print(f\"Failed on instance {instance_id}\", e)\n                    traceback.print_exc()\n                    # Save failed instance\n                    failed_instance = {**instance, \"text_inputs\": None}\n                    progress_file_handle.write(json.dumps(failed_instance) + \"\\n\")\n                    progress_file_handle.flush()\n                finally:\n                    os.chdir(orig_dir)\n        os.chdir(orig_dir)\n    finally:\n        progress_file_handle.close()\n",
      "original_issues": [
        {
          "file": "create_instance.py",
          "line": 484,
          "severity": "LOW",
          "rule_id": "PY011",
          "message": "过于宽泛的异常捕获：Exception。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "create_text_dataset.py",
      "path": "fixed_files\\create_text_dataset.py",
      "fixed_content": "#!/usr/bin/env python3\n\n\"\"\"\nCreate a dataset for text-to-text training from the raw task instance outputs.\n\"\"\"\n\nimport json\nimport logging\nimport os\nfrom argparse import ArgumentParser\nfrom pathlib import Path\nfrom datasets import Dataset, DatasetDict, load_dataset, load_from_disk\nfrom tqdm.auto import tqdm\n\nfrom swebench.inference.make_datasets.create_instance import (\n    add_text_inputs,\n    PROMPT_FUNCTIONS,\n)\nfrom swebench.inference.make_datasets.tokenize_dataset import TOKENIZER_FUNCS\n\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\nlogger = logging.getLogger(__name__)\n\n\ndef load_jsonl_file(filename):\n    if type(filename) == str:\n        filename = Path(filename)\n    if filename.name.endswith(\".jsonl\") or filename.name.endswith(\".jsonl.all\"):\n        with open(filename) as f:\n            return [json.loads(line) for line in f]\n    elif filename.name.endswith(\".json\"):\n        with open(filename) as f:\n            return json.load(f)\n    else:\n        raise ValueError(f\"Unknown file type {filename}\")\n\n\ndef instances_generator(files):\n    all_data = list()\n    for file in tqdm(files, desc=\"Loading instance files\"):\n        all_data.extend(load_jsonl_file(file))\n    return all_data\n\n\ndef get_training_and_eval_instances(raw_files, test_dataset):\n    logger.info(\"Loading instances\")\n    raw_instances = list(instances_generator(raw_files))\n    final_instances = list(test_dataset[\"test\"])\n    eval_repos = {x[\"repo\"] for x in final_instances}\n    train_instances = [x for x in raw_instances if x[\"repo\"] not in eval_repos]\n    train_instances = list(sorted(train_instances, key=lambda x: x[\"instance_id\"]))\n    eval_instances = list(sorted(final_instances, key=lambda x: x[\"instance_id\"]))\n    logger.info(f\"Found {len(train_instances)} training ids\")\n    logger.info(f\"Found {len(eval_instances)} eval ids\")\n    return train_instances, eval_instances\n\n\ndef extract_fields(instance):\n    instance_id = instance[\"instance_id\"]\n    if instance[\"text_inputs\"] is None or instance[\"patch\"] is None:\n        logger.warning(f\"No text for {instance_id}\")\n        return None\n    text_inputs = instance[\"text_inputs\"].strip() + \"\\n\\n\"\n    if text_inputs is None or instance[\"patch\"] is None:\n        logger.warning(f\"No inputs for {instance_id}\")\n        return None\n    patch = \"\\n\".join([\"<patch>\", instance[\"patch\"], \"</patch>\"])\n    return {**instance, \"text\": text_inputs, \"patch\": patch}\n\n\ndef validate_arguments(\n    push_to_hub_user, output_dir, max_context_len, tokenizer_name, file_source, k\n):\n    \"\"\"Validate command line arguments and environment setup.\"\"\"\n    if push_to_hub_user is not None:\n        hub_token = os.environ.get(\"HUGGING_FACE_HUB_TOKEN\", None)\n        assert hub_token is not None, (\n            \"Must provide HUGGING_FACE_HUB_TOKEN to push to the Hub\"\n        )\n        assert output_dir is None, \"Cannot provide output_dir if pushing to the Hub\"\n    if max_context_len is not None:\n        assert tokenizer_name is not None\n    if push_to_hub_user is None and not Path(output_dir).exists():\n        Path(output_dir).mkdir(parents=True)\n    if max_context_len is not None:\n        assert file_source not in {\"all\", \"oracle\"}, (\n            \"Cannot use max_context_len with oracle or all file sources\"\n        )\n        assert tokenizer_name is not None, (\n            \"Must provide tokenizer_name if max_context_len is not None\"\n        )\n    if k is not None:\n        assert file_source not in {\"all\", \"oracle\"}, (\n            \"Cannot use max_context_len with oracle or all file sources\"\n        )\n    return hub_token if push_to_hub_user is not None else None\n\n\ndef construct_output_filename(\n    dataset_name, prompt_style, file_source, k, max_context_len, tokenizer_name\n):\n    \"\"\"Construct the output filename based on parameters.\"\"\"\n    if dataset_name.startswith(\"princeton-nlp\"):\n        dataset_name = dataset_name.split(\"/\")[-1]\n    dataset_name = dataset_name.replace(\"/\", \"__\")\n    output_file = f\"{dataset_name}__{prompt_style}__fs-{file_source}\"\n    if k is not None:\n        output_file += f\"__k-{k}\"\n    if max_context_len is not None:\n        output_file += f\"__mcc-{max_context_len}-{tokenizer_name}\"\n    return output_file\n\n\ndef main(\n    dataset_name_or_path,\n    splits,\n    validation_ratio,\n    output_dir,\n    retrieval_file,\n    prompt_style,\n    file_source,\n    k,\n    max_context_len,\n    tokenizer_name,\n    push_to_hub_user,\n):\n    # Validate arguments and setup\n    hub_token = validate_arguments(\n        push_to_hub_user, output_dir, max_context_len, tokenizer_name, file_source, k\n    )\n    output_file = construct_output_filename(\n        dataset_name_or_path,\n        prompt_style,\n        file_source,\n        k,\n        max_context_len,\n        tokenizer_name,\n    )\n    output_file = Path(output_dir, output_file)\n    if push_to_hub_user is None:\n        if output_file.exists():\n            existing_dataset = load_from_disk(output_file)\n            # if requested splits are in existing dataset, abort\n            for split in splits:\n                if split in existing_dataset:\n                    logger.info(\n                        f\"{output_file.absolute().as_posix()} already exists for split {split}. Aborting\"\n                    )\n                    return\n            del existing_dataset  # don't store in memory\n\n    # Load dataset\n    dataset = (\n        load_from_disk(dataset_name_or_path)\n        if Path(dataset_name_or_path).exists()\n        else load_dataset(dataset_name_or_path)\n    )\n    logger.info(f\"Found {set(dataset.keys())} splits\")\n    if set(splits) - set(dataset.keys()) != set():\n        raise ValueError(f\"Unknown splits {set(splits) - set(dataset.keys())}\")\n\n    # Define columns for final dataset\n    columns = [\n        \"instance_id\",\n        \"text\",\n        \"repo\",\n        \"base_commit\",\n        \"problem_statement\",\n        \"hints_text\",\n        \"created_at\",\n        \"patch\",\n        \"test_patch\",\n        \"version\",\n        \"FAIL_TO_PASS\",\n        \"PASS_TO_PASS\",\n        \"environment_setup_commit\",\n    ]\n\n    # Process each split\n    split_data = {}\n    progress_files = {}\n    for split in splits:\n        logger.info(f\"Processing {split} split\")\n        split_instances = {x[\"instance_id\"]: x for x in dataset[split]}\n        progress_file = f\"{output_file}.{split}.progress.jsonl\"\n        progress_files[split] = progress_file\n        # Process instances and save to progress file\n        add_text_inputs(\n            split_instances,\n            retrieval_file=retrieval_file,\n            k=k,\n            prompt_style=prompt_style,\n            file_source=file_source,\n            max_context_len=max_context_len,\n            tokenizer_name=tokenizer_name,\n            progress_file=progress_file,\n        )\n\n    logger.info(\"Creating final dataset\")\n    # Create final dataset\n    if output_file.exists():\n        final_dataset = load_from_disk(output_file)\n    else:\n        final_dataset = DatasetDict()\n    for split in splits:\n        split_data = {key: [] for key in columns}\n        valid_instance_ids = set(dataset[split][\"instance_id\"])\n        invalid_instances = []\n\n        with open(progress_files[split]) as f:\n            for line in f:\n                datum = extract_fields(json.loads(line))\n                if not datum:\n                    continue\n                if datum[\"instance_id\"] not in valid_instance_ids:\n                    invalid_instances.append(datum[\"instance_id\"])\n                    continue\n                for key in columns:\n                    split_data[key].append(datum.get(key, \"\"))\n\n        if invalid_instances:\n            logger.warning(\n                f\"Found {len(invalid_instances)} instances in progress file that are not in the {split} dataset: {invalid_instances}. These will be removed from the final dataset.\"\n            )\n\n        final_dataset[split] = Dataset.from_dict(split_data)\n\n    # Handle validation split\n    if validation_ratio > 0 and \"train\" in final_dataset:\n        train_val = final_dataset[\"train\"].train_test_split(\n            test_size=validation_ratio, seed=42\n        )\n        final_dataset[\"train\"] = train_val[\"train\"]\n        final_dataset[\"validation\"] = train_val[\"test\"]\n\n    # Log final dataset sizes\n    for split in final_dataset:\n        logger.info(f\"Found {len(final_dataset[split])} {split} instances\")\n\n    # Save dataset\n    if push_to_hub_user is not None:\n        final_dataset.push_to_hub(\n            f\"{push_to_hub_user}/{output_file.name}\", use_auth_token=hub_token\n        )\n    else:\n        final_dataset.save_to_disk(output_file)\n\n    # Cleanup progress files\n    for progress_file in progress_files.values():\n        if os.path.exists(progress_file):\n            os.remove(progress_file)\n\n    logger.info(f\"Finished saving to {output_file}\")\n\n\nif __name__ == \"__main__\":\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument(\n        \"--dataset_name_or_path\",\n        type=str,\n        default=\"SWE-bench/SWE-bench\",\n        help=\"Dataset to use for test set from HuggingFace Datasets or path to a save_to_disk directory.\",\n    )\n    parser.add_argument(\n        \"--splits\",\n        nargs=\"+\",\n        default=[\"train\", \"test\"],\n        help=\"Splits to use from the dataset.\",\n    )\n    parser.add_argument(\n        \"--validation_ratio\",\n        type=float,\n        default=0.01,\n        help=\"Ratio of the training set to use for validation.\",\n    )\n    parser.add_argument(\"--output_dir\", type=str, help=\"Path to the output directory.\")\n    parser.add_argument(\n        \"--retrieval_file\",\n        type=str,\n        help=\"Path to the file where the retrieval results are stored.\",\n    )\n    parser.add_argument(\n        \"--prompt_style\",\n        type=str,\n        default=\"style-3\",\n        choices=PROMPT_FUNCTIONS.keys(),\n        help=\"Prompt style to use. See create_instance.PROMPT_FUNCTIONS for details.\",\n    )\n    parser.add_argument(\n        \"--file_source\",\n        type=str,\n        default=\"oracle\",\n        choices=[\"oracle\", \"bm25\", \"all\"],\n        help=\"How to select the files to use in context.\",\n    )\n    parser.add_argument(\n        \"--k\",\n        type=int,\n        default=None,\n        help=\"Maximum number of files to use for retrieval.\",\n    )\n    parser.add_argument(\n        \"--max_context_len\",\n        type=int,\n        default=None,\n        help=\"Maximum number of tokens to use for context.\",\n    )\n    parser.add_argument(\n        \"--tokenizer_name\",\n        type=str,\n        default=None,\n        choices=TOKENIZER_FUNCS.keys(),\n        help=\"Tokenizer to use for max_context_len. Only needed if max_context_len is specified.\",\n    )\n    parser.add_argument(\n        \"--push_to_hub_user\",\n        type=str,\n        help=\"Username to use for pushing to the Hub. If not provided, will save to disk.\",\n    )\n    main(**vars(parser.parse_args()))\n",
      "original_issues": [
        {
          "file": "create_text_dataset.py",
          "line": 251,
          "severity": "LOW",
          "rule_id": "PY203",
          "message": "list.remove() 要求参数为列表中的元素，而非索引。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "eval_retrieval.py",
      "path": "fixed_files\\eval_retrieval.py",
      "fixed_content": "#!/usr/bin/env python\n\n\"\"\"This script can be used to evaluate the BM25 retrieval results for a dataset created with create_text_dataset.py with the --retrieval_file option and --file_source bm25.\"\"\"\n\nimport re\nimport numpy as np\nfrom datasets import load_dataset, disable_caching, load_from_disk\nfrom argparse import ArgumentParser\nimport logging\n\ndisable_caching()\nlogging.basicConfig(\n    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n)\nlogger = logging.getLogger(__name__)\n\n\ndef main(dataset_name_or_path, split):\n    try:\n        dataset = load_from_disk(dataset_name_or_path)[split]\n    except Exception as e:\n        logger.error(f\"Failed to load dataset from disk: {e}\")\n        dataset = load_dataset(dataset_name_or_path, split=split)\n    print(\n        f\"Evaluating {len(dataset)} instances from {dataset_name_or_path} {split} split\"\n    )\n    instance_files_pattern = re.compile(\n        r\"\\[start of ([\\w\\.\\-\\/]+)\\]\\n(?:.+?)\\n\\[end of \\1\\]\", re.DOTALL\n    )\n    patch_files_pattern = re.compile(r\"\\-\\-\\- a/(.+)\")\n    patch_files = {instance[\"instance_id\"]: instance[\"patch\"] for instance in dataset}\n    recalls_any = list()\n    recalls_all = list()\n    recalls = list()\n    for datum in dataset:\n        instance_id = datum[\"instance_id\"]\n        retrieved_files = instance_files_pattern.findall(datum[\"text\"])\n        if retrieved_files and \"readme\" in retrieved_files[0].lower():\n            retrieved_files = retrieved_files[1:]\n        retrieved_files = set(retrieved_files)\n        gold_files = set(patch_files_pattern.findall(patch_files[instance_id]))\n        if len(gold_files) == 0:\n            print(f\"WARNING: Instance {datum['instance_id']} has no gold files\")\n            continue\n        if len(retrieved_files) == 0:\n            print(f\"WARNING: Instance {datum['instance_id']} has no retrieved files\")\n            recall = 0.0\n        else:\n            recall = len(retrieved_files.intersection(gold_files)) / len(gold_files)\n        recalls.append(recall)\n        recalls_any.append(int(recall > 0))\n        recalls_all.append(int(recall == 1))\n    recalls = np.array(recalls)\n    recalls_any = np.array(recalls_any)\n    recalls_all = np.array(recalls_all)\n    print(f\"Avg Recall: {np.mean(recalls) * 100:.2f}\")\n    print(f\"All Recall: {np.mean(recalls_all) * 100:.2f}\")\n    print(f\"Any Recall: {np.mean(recalls_any) * 100:.2f}\")\n\n\nif __name__ == \"__main__\":\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument(\n        \"--dataset_name_or_path\", type=str, default=\"SWE-bench/SWE-bench_bm25_13K\"\n    )\n    parser.add_argument(\"--split\", type=str, default=\"test\")\n    args = parser.parse_args()\n    main(**vars(args))\n",
      "original_issues": [
        {
          "file": "eval_retrieval.py",
          "line": 21,
          "severity": "LOW",
          "rule_id": "PY010",
          "message": "使用裸 except，建议捕获具体异常类型。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "get_versions.py",
      "path": "fixed_files\\get_versions.py",
      "fixed_content": "import argparse\nimport glob\nimport json\nimport logging\nimport os\nimport re\nimport requests\nimport subprocess\n\nfrom multiprocessing import Pool, Manager\n\nfrom swebench.versioning.constants import (\n    SWE_BENCH_URL_RAW,\n    MAP_REPO_TO_VERSION_PATHS,\n    MAP_REPO_TO_VERSION_PATTERNS,\n)\nfrom swebench.versioning.utils import get_instances, split_instances\n\nlogging.basicConfig(\n    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n)\nlogger = logging.getLogger(__name__)\n\n\nINSTALL_CMD = {\n    \"pytest-dev/pytest\": \"pip install -e .\",\n    \"matplotlib/matplotlib\": \"python -m pip install -e .\",\n    \"pydata/xarray\": \"pip install -e .\",\n}\n\n\ndef _find_version_in_text(text: str, instance: dict) -> str:\n    \"\"\"\n    Helper function for applying regex patterns to look for versions in text\n\n    Args:\n        text (str): Text to search\n        instance (dict): Instance to find version for\n    Returns:\n        str: Version text, if found\n    \"\"\"\n    # Remove comments\n    pattern = r'\"\"\".*?\"\"\"'\n    text = re.sub(pattern, \"\", text, flags=re.DOTALL)\n    # Search through all patterns\n    for pattern in MAP_REPO_TO_VERSION_PATTERNS[instance[\"repo\"]]:\n        matches = re.search(pattern, text)\n        if matches is not None:\n            print(instance[\"repo\"])\n            if instance[\"repo\"] == \"pyvista/pyvista\":\n                text = matches.group(0)\n                text = text.split(\"=\")[-1].strip() if \"=\" in text else text.strip()\n                text = \".\".join(text.split(\",\"))\n                return text\n            return str(matches.group(1)).replace(\" \", \"\")\n\n\ndef get_version(instance, is_build=False, path_repo=None):\n    \"\"\"\n    Function for looking up the version of a task instance.\n\n    If is_build is True, then the version is looked up by 1. building the repo\n    at the instance's base commit, 2. activating the conda environment, and 3.\n    looking for the version according to a predefined list of paths.\n\n    Otherwise, the version is looked up by searching GitHub at the instance's\n    base commit for the version according to a predefined list of paths.\n\n    Args:\n        instance (dict): Instance to find version for\n        is_build (bool): Whether to build the repo and look for the version\n        path_repo (str): Path to repo to build\n    Returns:\n        str: Version text, if found\n    \"\"\"\n    keep_major_minor = lambda x, sep: \".\".join(x.strip().split(sep)[:2])\n    paths_to_version = MAP_REPO_TO_VERSION_PATHS[instance[\"repo\"]]\n    version = None\n    for path_to_version in paths_to_version:\n        init_text = None\n        if is_build and path_repo is not None:\n            version_path_abs = os.path.join(path_repo, path_to_version)\n            if os.path.exists(version_path_abs):\n                logger.info(f\"Found version file at {path_to_version}\")\n                with open(path_to_version) as f:\n                    init_text = f.read()\n        else:\n            url = os.path.join(\n                SWE_BENCH_URL_RAW,\n                instance[\"repo\"],\n                instance[\"base_commit\"],\n                path_to_version,\n            )\n            init_text = requests.get(url).text\n        version = _find_version_in_text(init_text, instance)\n        if version is not None:\n            if \".\" in version:\n                version = keep_major_minor(version, \".\")\n            if \",\" in version:\n                version = keep_major_minor(version, \",\")\n            version = re.sub(r\"[^0-9\\.]\", \"\", version)\n            return version\n    return version\n\n\ndef map_version_to_task_instances(task_instances: list) -> dict:\n    \"\"\"\n    Create a map of version key to list of task instances\n\n    Args:\n        task_instances (list): List of task instances\n    Returns:\n        dict: Map of version key to list of task instances\n    \"\"\"\n    return_map = {}\n    if \"version\" in task_instances[0]:\n        for instance in task_instances:\n            version = instance[\"version\"]\n            if version not in return_map:\n                return_map[version] = []\n            return_map[version].append(instance)\n        return return_map\n    for instance in task_instances:\n        version = get_version(instance)\n        if version not in return_map:\n            return_map[version] = []\n        return_map[version].append(instance)\n    return return_map\n\n\ndef get_versions_from_build(data: dict):\n    \"\"\"\n    Logic for looking up versions by building the repo at the instance's base\n    commit and looking for the version according to repo-specific paths.\n\n    Args:\n        data (dict): Dictionary of data for building a repo for any task instance\n            in a given list.\n    \"\"\"\n    data_tasks, path_repo, conda_env, path_conda, save_path = (\n        data[\"data_tasks\"],\n        data[\"path_repo\"],\n        data[\"conda_env\"],\n        data[\"path_conda\"],\n        data[\"save_path\"],\n    )\n    # Activate conda environment and set installation command\n    cmd_activate = f\"source {os.path.join(path_conda, 'bin/activate')}\"\n    cmd_source = f\"source {os.path.join(path_conda, 'etc/profile.d/conda.sh')}\"\n    cmd_install = INSTALL_CMD[data_tasks[0][\"repo\"]]\n\n    # Change directory to repo testbed\n    cwd = os.getcwd()\n    os.chdir(path_repo)\n\n    for instance in data_tasks[::-1]:\n        # Reset repo to base commit\n        subprocess.run(\n            \"git restore .\", check=True, shell=True, stdout=subprocess.DEVNULL\n        )\n        subprocess.run(\n            \"git reset HEAD .\", check=True, shell=True, stdout=subprocess.DEVNULL\n        )\n        subprocess.run(\n            \"git clean -fd\", shell=True, check=True, stdout=subprocess.DEVNULL\n        )\n        out_check = subprocess.run(\n            f\"git -c advice.detachedHead=false checkout {instance['base_commit']}\",\n            shell=True,\n            stdout=subprocess.DEVNULL,\n        )\n        if out_check.returncode != 0:\n            logger.error(f\"[{instance['instance_id']}] Checkout failed\")\n            continue\n\n        # Run installation command in repo\n        out_install = subprocess.run(\n            f\"{cmd_source}; {cmd_activate} {conda_env}; {cmd_install}\",\n            shell=True,\n            stdout=subprocess.DEVNULL,\n        )\n        if out_install.returncode != 0:\n            logger.error(f\"[{instance['instance_id']}] Installation failed\")\n            continue\n\n        # Look up version according to repo-specific paths\n        version = get_version(instance, is_build=True, path_repo=path_repo)\n        instance[\"version\"] = version\n        logger.info(f\"For instance {instance['instance_id']}, version is {version}\")\n\n    # Save results\n    with open(save_path, \"w\") as f:\n        json.dump(data_tasks, fp=f)\n    os.chdir(cwd)\n\n\ndef get_versions_from_web(data: dict):\n    \"\"\"\n    Logic for looking up versions by searching GitHub at the instance's base\n    commit and looking for the version according to repo-specific paths.\n\n    Args:\n        data (dict): Dictionary of data for searching GitHub for any task instance\n            in a given list.\n    \"\"\"\n    data_tasks, save_path = data[\"data_tasks\"], data[\"save_path\"]\n    version_not_found = data[\"not_found_list\"]\n    for instance in data_tasks:\n        version = get_version(instance)\n        if version is not None:\n            instance[\"version\"] = version\n            logger.info(f\"For instance {instance['instance_id']}, version is {version}\")\n        elif version_not_found is not None:\n            logger.info(f\"[{instance['instance_id']}]: version not found\")\n            version_not_found.append(instance)\n    with open(save_path, \"w\") as f:\n        json.dump(data_tasks, fp=f)\n\n\ndef merge_results(instances_path: str, repo_prefix: str, output_dir: str = None) -> int:\n    \"\"\"\n    Helper function for merging JSON result files generated from multiple threads.\n\n    Args:\n        instances_path (str): Path to original task instances without versions\n        repo_prefix (str): Prefix of result files (repo name)\n        output_dir (str): Path to save merged results to\n    Returns:\n        int: Number of instances in merged results\n    \"\"\"\n    # Merge values from result JSON files into a single list\n    merged = []\n    for task_with_version_path in glob.glob(f\"{repo_prefix}_versions_*.json\"):\n        with open(task_with_version_path) as f:\n            task_with_version = json.load(f)\n            merged.extend(task_with_version)\n        os.remove(task_with_version_path)\n\n    # Save merged results to original task instances file's path with `_versions` suffix\n    old_path_file = instances_path.split(\"/\")[-1]\n    instances_path_new = f\"{old_path_file.split('.')[0]}_versions.json\"\n    if output_dir is not None:\n        instances_path_new = os.path.join(output_dir, instances_path_new)\n    with open(f\"{instances_path_new}\", \"w\") as f:\n        json.dump(merged, fp=f)\n    logger.info(\n        f\"Saved merged results to {instances_path_new} ({len(merged)} instances)\"\n    )\n    return len(merged)\n\n\ndef main(args):\n    \"\"\"\n    Main function for looking up versions for task instances.\n    \"\"\"\n    # Get task instances + split into groups for each thread\n    data_tasks = get_instances(args.instances_path)\n    data_task_lists = split_instances(data_tasks, args.num_workers)\n    repo_prefix = data_tasks[0][\"repo\"].replace(\"/\", \"__\")\n\n    logger.info(\n        f\"Getting versions for {len(data_tasks)} instances for {data_tasks[0]['repo']}\"\n    )\n    logger.info(\n        f\"Split instances into {len(data_task_lists)} groups with lengths {[len(x) for x in data_task_lists]}\"\n    )\n\n    # If retrieval method includes GitHub, then search GitHub for versions via parallel call\n    if any([x == args.retrieval_method for x in [\"github\", \"mix\"]]):\n        manager = Manager()\n        shared_result_list = manager.list()\n        pool = Pool(processes=args.num_workers)\n        pool.map(\n            get_versions_from_web,\n            [\n                {\n                    \"data_tasks\": data_task_list,\n                    \"save_path\": f\"{repo_prefix}_versions_{i}.json\"\n                    if args.retrieval_method == \"github\"\n                    else f\"{repo_prefix}_versions_{i}_web.json\",\n                    \"not_found_list\": shared_result_list\n                    if args.retrieval_method == \"mix\"\n                    else None,\n                }\n                for i, data_task_list in enumerate(data_task_lists)\n            ],\n        )\n        pool.close()\n        pool.join()\n\n        if args.retrieval_method == \"github\":\n            # If retrieval method is just GitHub, then merge results and return\n            assert len(data_tasks) == merge_results(\n                args.instances_path, repo_prefix, args.output_dir\n            )\n            return\n        elif args.retrieval_method == \"mix\":\n            # Otherwise, remove instances that were found via GitHub from the list\n            shared_result_list = list(shared_result_list)\n            total_web = len(data_tasks) - len(shared_result_list)\n            logger.info(f\"Retrieved {total_web} versions from web\")\n            data_task_lists = split_instances(shared_result_list, args.num_workers)\n            logger.info(\n                f\"Split instances into {len(data_task_lists)} groups with lengths {[len(x) for x in data_task_lists]} for build\"\n            )\n\n    # Check that all required arguments for installing task instances are present\n    assert any([x == args.retrieval_method for x in [\"build\", \"mix\"]])\n    assert all([x in args for x in [\"testbed\", \"path_conda\", \"conda_env\"]])\n    conda_exec = os.path.join(args.path_conda, \"bin/conda\")\n\n    cwd = os.getcwd()\n    os.chdir(args.testbed)\n    for x in range(0, args.num_workers):\n        # Clone git repo per thread\n        testbed_repo_name = f\"{repo_prefix}__{x}\"\n        if not os.path.exists(testbed_repo_name):\n            logger.info(\n                f\"Creating clone of {data_tasks[0]['repo']} at {testbed_repo_name}\"\n            )\n            cmd_clone = (\n                f\"git clone git@github.com:swe-bench/{repo_prefix} {testbed_repo_name}\"\n            )\n            subprocess.run(cmd_clone, shell=True, check=True, stdout=subprocess.DEVNULL)\n        else:\n            logger.info(\n                f\"Repo for {data_tasks[0]['repo']} exists: {testbed_repo_name}; skipping...\"\n            )\n        # Clone conda environment per thread\n        conda_env_name = f\"{args.conda_env}_clone_{x}\"\n        if not os.path.exists(os.path.join(args.path_conda, \"envs\", conda_env_name)):\n            logger.info(f\"Creating clone of {args.conda_env} at {conda_env_name}\")\n            cmd_clone_env = f\"{conda_exec} create --name {conda_env_name} --clone {args.conda_env} -y\"\n            subprocess.run(\n                cmd_clone_env, shell=True, check=True, stdout=subprocess.DEVNULL\n            )\n        else:\n            logger.info(\n                f\"Conda clone for thread {x} exists: {conda_env_name}; skipping...\"\n            )\n    os.chdir(cwd)\n\n    # Create pool tasks\n    pool_tasks = []\n    for i in range(0, args.num_workers):\n        testbed_repo_name = f\"{repo_prefix}__{i}\"\n        pool_tasks.append(\n            {\n                \"data_tasks\": data_task_lists[i],\n                \"path_repo\": os.path.join(args.testbed, testbed_repo_name),\n                \"conda_env\": f\"{args.conda_env}_clone_{i}\",\n                \"path_conda\": args.path_conda,\n                \"save_path\": os.path.join(cwd, f\"{repo_prefix}_versions_{i}.json\"),\n            }\n        )\n\n    # Parallelized call\n    pool = Pool(processes=args.num_workers)\n    pool.map(get_versions_from_build, pool_tasks)\n    pool.close()\n    pool.join()\n\n    # Check that correct number of instances were versioned\n    if args.retrieval_method == \"mix\":\n        assert (\n            len(data_tasks)\n            == merge_results(args.instances_path, repo_prefix, args.output_dir)\n            + total_web\n        )\n    elif args.retrieval_method == \"build\":\n        assert len(data_tasks) == merge_results(\n            args.instances_path, repo_prefix, args.output_dir\n        )\n\n    # Remove testbed repo and conda environments\n    if args.cleanup:\n        cwd = os.getcwd()\n        os.chdir(args.testbed)\n        for x in range(0, args.num_workers):\n            # Remove git repo\n            testbed_repo_name = f\"{repo_prefix}__{x}\"\n            subprocess.run(f\"rm -rf {testbed_repo_name}\", shell=True, check=True)\n\n            # Remove conda environment\n            cmd_rm_env = (\n                f\"{conda_exec} remove --name {args.conda_env}_clone_{x} --all -y\"\n            )\n            subprocess.run(cmd_rm_env, shell=True, check=True)\n        os.chdir(cwd)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--instances_path\",\n        required=True,\n        type=str,\n        default=None,\n        help=\"Path to task instances\",\n    )\n    parser.add_argument(\n        \"--retrieval_method\",\n        required=True,\n        choices=[\"build\", \"mix\", \"github\"],\n        default=\"github\",\n        help=\"Method to retrieve versions\",\n    )\n    parser.add_argument(\n        \"--cleanup\",\n        action=\"store_true\",\n        help=\"Remove testbed repo and conda environments\",\n    )\n    parser.add_argument(\n        \"--conda_env\", type=str, default=None, help=\"Conda environment to use\"\n    )\n    parser.add_argument(\"--path_conda\", type=str, default=None, help=\"Path to conda\")\n    parser.add_argument(\n        \"--num_workers\", type=int, default=1, help=\"Number of threads to use\"\n    )\n    parser.add_argument(\n        \"--output_dir\", type=str, default=None, help=\"Path to save results\"\n    )\n    parser.add_argument(\n        \"--testbed\", type=str, default=None, help=\"Path to testbed repo\"\n    )\n    args = parser.parse_args()\n    main(args)\n",
      "original_issues": [
        {
          "file": "get_versions.py",
          "line": 237,
          "severity": "LOW",
          "rule_id": "PY203",
          "message": "list.remove() 要求参数为列表中的元素，而非索引。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    },
    {
      "file": "get_versions_xarray.py",
      "path": "fixed_files\\get_versions_xarray.py",
      "fixed_content": "import json\nimport os\nimport re\nimport requests\nimport sys\n\nfrom datetime import datetime\n\nsys.path.append(\"../../harness\")\nfrom utils import get_instances\n\nPATH_TASKS_XARRAY = \"<path to xarray task instances>\"\n\n# Get raw xarray dataset\ndata_tasks = get_instances(PATH_TASKS_XARRAY)\n\n# Get version to date from xarray home page\nresp = requests.get(\"https://docs.xarray.dev/en/stable/whats-new.html\")\npattern = (\n    r'<a class=\"reference internal nav-link( active)?\" href=\"#v(.*)\">v(.*) \\((.*)\\)</a>'\n)\nmatches = re.findall(pattern, resp.text)\nmatches = list(set(matches))\nmatches = [x[1:] for x in matches]\n\n# Get (date, version) pairs\ndate_formats = [\"%B %d %Y\", \"%d %B %Y\"]\nkeep_major_minor = lambda x, sep: \".\".join(x.strip().split(sep)[:2])\n\ntimes = []\nfor match in matches:\n    parts = match[0].split(\"-\")\n    version = keep_major_minor(\".\".join(parts[0:3]), \".\")\n    date_str = \" \".join(parts[3:])\n    \n    for f_ in date_formats:\n        try:\n            date_obj = datetime.strptime(date_str, f_)\n            times.append((date_obj.strftime(\"%Y-%m-%d\"), version))\n            break\n        except ValueError:\n            continue\n\ntimes = sorted(times, key=lambda x: x[0])[::-1]\n\nfor task in data_tasks:\n    created_at = task[\"created_at\"].split(\"T\")[0]\n    found = False\n    for t in times:\n        if t[0] < created_at:\n            task[\"version\"] = t[1]\n            found = True\n            break\n    if not found:\n        task[\"version\"] = None\n\n# Save xarray versioned data to repository\nwith open(\n    os.path.join(PATH_TASKS_XARRAY, \"xarray-task-instances_versions.json\"),\n    \"w\",\n) as f:\n    json.dump(data_tasks, fp=f)\n",
      "original_issues": [
        {
          "file": "get_versions_xarray.py",
          "line": 40,
          "severity": "LOW",
          "rule_id": "PY010",
          "message": "使用裸 except，建议捕获具体异常类型。",
          "priority": "MEDIUM",
          "suggested_fix": "请检查代码逻辑并修复"
        }
      ]
    }
  ],
  "verification": []
}